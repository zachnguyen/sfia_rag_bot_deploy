This episode is brought to by Skillshare.
Utopia is very much in the Eye of the Beholder,
and if that Beholder is Big Brother, Utopia
is probably a society where everyone does
what they are told.
The colder months of the year tend to be a
time of year when I grab a hot drink, turn
on the fireplace and TV, and settle into the
couch for some sci-fi marathons with my cats.
This year I was joined by wife Sarah who is
pretty new to science fiction so I’ve been
exposing her to the classics like Doctor Who
and Star Trek, and one of the episodes we
watched was the classic Star Trek Episode
“The Return of the Archons”, where the
Enterprise arrives at the Planet Beta III
to investigate the century old disappearance
of the USS Archon.
On it they find an idyllic civilization whose
friendly if rather creepy people seem modestly
primitive, perhaps 19th or early 20th century
Earth Analogues, and welcome them in time
for the Festival they are assumed to be travelers
arriving to attend.
The hour dawns for the festival to start and
everyone goes nuts breaking and pillaging
their town and its other inhabitants, then
come the morning, like clockwork, suddenly
start acting normal again, or at least their
normal, which is creepy-friendly, and hailing
Landru, their local savior, king, and god.
No reason is ever given for the violent Festival
beyond it being Landru’s Will, but possibly
from the script being re-worked... the episode
was originally one of the three Roddenbery
offered the studio as a candidate for the
Pilot Episode of Star Trek.
The sudden crazy Purge-riot pops up in scifi
a lot I’ve noticed, often as some sort of
release valve for otherwise peaceful civilizations.
My favorite example was the Parody episode
of Rick & Morty, “Look Who’s Purging Now”,
and we will discuss that notion, of societal
release valves, later in the episode.
This also happens to be one of the four episodes
where Captain Kirk “talks a computer to
death”, in this case a computer programmed
by Landru thousands of years before that had
assumed Landru’s Identity, and is an example
of an artificial intelligence running a civilization.
Its objective is to create a peaceful society,
putting good above evil, and so on, and achieves
this goal through some equivalent of telepathy
and brainwashing.
This is an example of what we, here on SFIA,
call a Post-Discontent Society, a term coined
by one of our editors, Jerry Guern, while
we were working on the script for one of the
episodes in our Post-Scarcity Civilizations
series, and is essentially the antithesis
of a post-scarcity version of Utopia.
Post-Scarcity Civilizations are those that
have no scarcity of resources, though in the
interests of plausibility for discussion inside
a Finite Universe, we define it on the show
as a civilization who has such an abundance
of a given Human Need that getting access
to it causes no serious anxiety in people.
It’s pretty relative and can be specific
to a resource, for instance humans need oxygen
to live but we are essentially post-scarcity
in regard to oxygen, the supply is not infinite
but no one worries about us running out, and
for good reason.
Humans have many needs, including the mental
and emotional not just the physiological,
and we often use Maslow’s Hierarchy of Needs
as our benchmark for saying that a Post-Scarcity
civilization would be one that satisfies all
the basic needs and also many needs higher
on the Pyramid.
The condition is not an infinite supply of
resources, only that acquiring the resources
is not a difficulty and running out is not
a serious concern.
But this is where we have to distinguish between
Post-Scarcity and Post-Discontent civilizations.
Post discontent folks don’t worry about
scarcity even when there is good reason to.
A society where everyone is either programmed
or administered narcotics to make them happy,
docile, productive, and obedient, whether
they live in filth and eat moldy bread or
just live in tiny bare clean boxes.
Overcoming scarcity and not minding it are
very different goals, and they bring about
very different societies.
Our planet of Beta III, ruled over by Landru,
is another example, and indeed one of our
gray cases because it’s portrayal is that
of peace and plenty in a very genuine sense.
We don’t get many details on the planet
but every impression is that – except when
the Festival is going on, for whatever reason
it is going on – there is indeed peace and
plenty.
That’s not really surprising when you think
about it, there are many reasons to object
to any tyranny, let alone one so complete
that even the desire to think about overthrowing
it does not exist, but the odds are it will
tilt to being law-abiding and well-ordered,
so you might need to brainwash folks to submit
to your rule but not into needing to believe
they are safe from criminals or starvation.
On the other hand, a truly abusive regime
that just views its people as cheap labor
it can squeeze for product would presumably
like the brainwashing option, though even
then is likely to maintain things to be pretty
clean and healthy, sick and starving workers
may be a common theme in oppressive empires
in science fiction, but efficiency means you
maintain your workers same as you maintain
your machines, in good function.
Half-starved citizens living in mold covered
shanties is not a recipe for productivity.
Indeed your only motivation for keeping your
workforce that way, unless you simply are
even more sadistic than you are selfish, is
if you’re of the opinion that the more hopeless
their lot, the less likely they are to rebel,
and indeed there is some reason to think that
might be true.
However, it's not the case for a post-discontent
society, because they don’t need fear of
punishment as the principal method of enforcement.
They’re specifically civilizations that
through technology or technique keep their
people content with their lot, rather than
afraid rebelling would get them horribly killed.
Such being the case, there is no motivation
to keep people in squalor where it’s more
expensive to do that.
There is no criminal element trashing their
neighborhoods and there is a motivation to
make each citizen as productive as possible,
which means in good health.
So a Post-Discontent Society is probably a
clean and cheerful place, and is one example
of how they can be easily confused with a
post-scarcity one, indeed it can be a blurry
distinction too since contentment can come
from simply being an aesthetic culture.
On the flipside, a genuine post-scarcity society
can be a pretty bad place full of hedonism
and greed.
Same as there can be a very blurry line between
adopting a culture and indoctrination into
it, if you are meeting everyone’s basic
needs in the name of efficiency, and they
are content, versus meeting everyone’s needs
through abundance, and they are content, the
distinction can be hard to pinpoint and in
some cases might not exist.
There’s another problem though.
Science fiction shows us dreary future cities
with oppressed inhabitants worked to death
because it makes a good setting for stories,
but if you are high-tech you need folks working
12 hours days 7 days a week like you need
a raincoat on a sunny afternoon in the Sahara
desert.
You’ve got robots doing your grunt work.
You don’t need peasants in burlap smocks
hoeing turnips, you need a skilled operator
running a tractor or programming and repairing
the robot who does so.
One might argue you don’t really want smart
and free people wandering around because they
could cause damage to your empire, but uneducated,
sick, and half-starved citizens can do a lot
of damage too, like breaking your complex
machines on accident.
And again, the fear there is that an educated
populace might turn on its masters and figure
out a way to organize a successful rebellion,
the point of a post-discontent society is
that there’s no one looking to rebel, they
are content.
You don’t need thugs in jackboots stepping
on the oppressed or busting into people’s
homes to find their stash of illegal books
full of dangerous ideas.
Though that might be debatable, as your civilization
might be built on some big lie, like you’re
an eternal city that will go on forever while
in secret your supplies of raw materials and
fuel are dwindling every year, and to avoid
folks thinking on that you might ban any book
mentioning the laws of thermodynamics and
entropy.
More common in science fiction is banning
ideological knowledge, like hiding books on
human rights and democracy, but a tyrannic
post-discontent society probably isn’t all
that worried about its folks discussing democracy
and demanding a vote.
Happy citizens have no reason to rebel.
We, ourselves might object, most of us living
in countries with elections and who have had
elections for generations, but none of those
formed because the prior leader right before
that was doing a great job, except in rare
cases where they were and were worried their
successor would not, so set themselves up
to be replaced by elections rather than a
new tyrant.
Revolutions don’t happen in a vacuum.
This raises two big questions.
First, why are they so satisfied?
What is making them post-discontent?
Is it drugs and brainwashing or is it something
else?
We can ignore the case where it is genuine
post-scarcity, that people are content because
they really do have access to the Horn of
Plenty, but there is a big grey region.
So that’s the second question, are the powers-that-be
actually doing a good job?
Humans are innately hierarchal, and odds are
good that many alien civilizations would be
too.
Small groups like packs need leaders, the
chief or alpha male etc, but specialist societies
are very inter-dependent on their members
carrying out various specialized tasks and
that requires coordination and when you get
big enough, folks whose specialty is coordinating
the coordinators and convincing the other
citizens that the coordination is good.
One of the big appeals in science fiction
to have a computer run the show is that it
is logical and without bias, and most of the
arguments against tends to be rather emotional
and strawman, the computer isn’t overthrown
because its a computer, its overthrown because
it was doing a bad job.
We don’t know that a computer would do a
bad job, just that sci fi writers often say
they would, for varying and sometimes contradictory
reasons.
One rather flimsy reason often offered is
that the computer leader just didn’t understand
human nature, either our indomitable spirit
or our capacity to act in unpredictable ways.
That argument might have been more convincing
to early TV audiences, but it’s much less
convincing to modern audiences who’ve seen
how much AIs actually can learn, model, and
predict.
A vastly powerful supercomputer capable of
modeling human brains would fully understand
not only the indomitable human spirit but
the hacks that would allow one to dominate
it or at least to keep it a content and cooperative
citizen.
And even if the leader didn’t have enough
data to predict which citizens would turn
out irredeemably rebellious, it would certainly
know the early indicators of a citizen potentially
on that path and know the optimal preemptive
actions to take.
But in a sense we already live in a society
run by computers.
We have computers capable of predicting the
weather, and future ones may do it far better
and we could place it in charge of saying
when we should schedule flights or ground
them, when we should plant crops or wait a
week more, and most would obey except for
a few stubborn folks we would mostly roll
our eyes at.
Admittedly nobody likes the idea of being
bossed around by a machine, but then we don’t
much like the idea of being bossed around
by human authorities either.
We may be heavily influenced by our biology
toward certain forms of hierarchical leadership,
but we can and do repress our hardwired behaviors
on many things, we keep the concept of someone
in charge because it generally beats the alternative.
In our Star Trek episode we mentioned near
the beginning, the real objection to Landru
would seem to be that the machine is just
brainwashing or psychically dominating folks
to be happy cattle, and in this case we don’t
care if the cage is messy or gilded, if the
bird in it is starving or fat, it’s still
in a cage.
Those people aren’t being allowed to be
people, and it's not the same as a society
that just had harsh punishment for bad behavior,
it's one with no free will.
So we will put the qualifier on a Post-Discontent
Society that their human – or alien – nature
and will is being subverted, repressed, or
removed in some fashion, and far beyond the
sort of basic background indoctrination in
any society.
And in that episode it is apparently from
telepathic domination, and parallels cases
like Hive Minds, such as the Borg from Star
Trek, that snatch and absorb people against
their will.
There are some folks shown to be immune to
the effect too, and we don’t get details
but in some parallel stories people might
begin to develop immunity over time.
If telepathy, they might have folks who are
immune to telepathy develop, if drugs, an
immunity or resistance to that drug, and so
on.
Which makes sense but only on first inspection.
Thousands of generations under some influence
and evolving an immunity to it seems logical,
but that’s not really how evolution works.
A given new trait first has to have some simple
means to emerge and provide a benefit.
Developing an immunity to telepathy would
be a big jump one would think, but also, what
is the actual survival advantage?
If you live in a society that is brainwashed,
from an evolutionary perspective there’s
no great automatic advantage to you or your
descendants in immunity, especially given
that you’re not in nature, you’re in a
civilization run by thinking beings and presumably
ones with a ruthless streak.
They don’t consider your trait an advantage,
to them at least, and having a trait that
makes a powerful being want to hunt you to
extinction is not a survival advantage.
We see this line of reasoning used with a
civilization preyed on by the Wraith in Stargate
Atlantis, who suck the life out of humans
for food.
That civilization, the Hoffan people, created
a drug that killed many of them but left the
remainder of them poisonous to feed on, and
reasoned the Wraith would obviously leave
them alone rather than die trying to feed
on them.
The Wraith did the actual obvious thing, and
wiped them out to make sure no one else got
that drug.
Now we might hypothesize an exception, like
if your masters ate people by luring them
in with telepathy and just ate the first to
come.
Folks with a resistance to that would be less
likely to be eaten, and their descendants
thus more survivable, however it ignores that
people eating an intelligent species probably
aren’t stupid either, and would guess that
would be a long term effect and act accordingly.
Such as periodically luring everyone in, killing
everyone who didn’t show up and eating the
ones who were tardy.
Then the evolutionary advantage isn’t immunity
to telepathy, but greater susceptibility to
it, and indeed many crops are cultivated to
be more tasty and many plants rely on being
eaten to spread their seed.
That’s also a Scifi Trope, the apparent
utopia whose people are like happy cattle
and turn out to be exactly that, like with
the Eloi and Morlocks of H.G. Wells’ classic
novel “The Time Machine”.
It’s a nice story idea, folks who act like
happy cattle and are literally cattle, but
not very logical.
Humans make for an awful form of livestock,
we pretty much have every trait a rancher
or farmer would find disadvantageous in a
food source, not least of which being our
long maturation period.
Assuming they really had a taste for humans
though, technology offers the option of cloning
meat up in tanks, which we’re already getting
pretty good at, or genetically engineering
humans far stupider and more docile with faster
maturation times, especially since our giant
calorie-hungry brains are tied in with those
long maturation times.
That incidentally is another approach to being
a post-discontent society, just make people
too stupid to be discontent with anything
you have difficulty supplying.
As we said, post-scarcity civilizations, to
really qualify as what we mean by post-scarcity,
need to be doing better than just covering
the basic physiological needs at the bottom
of Maslow’s Hierarchy, they need to hit
higher level issues like feelings of security,
belonging, family, etc.
Those are a lot easier to meet if folks are
near-animal intelligence or monomaniacal,
and the very top of the pyramid includes things
like Self-Actualization that we tend to assume
animals don’t even have.
A cow has feelings of security, belonging,
and family too, possibly even more intensely
than a human, it just has very little capacity
to think of the future or remember the past.
People ruminate on past losses, cows ruminate
on their breakfast.
And People wonder why they are being fed that
breakfast for free, cows do not.
Making a civilization dumber is a pretty common
trope in evil science fiction empires too,
but also raises the question of what the point
is?
The valuable part of us is our brains, and
has been long before we had combustion engines
and computers.
If you want raw brute force, you get an ox,
not a human, and if you have technology you
get an engine.
If you want sophistication and adaptation,
you get a human, and if you want the most
bang for your buck, you educate them.
If you’ve got artificial intelligence so
good you don’t need those human attributes,
then you don’t need humans, and they exist
because they control that artificial intelligence
and the purpose its designed and built for
is improving the human condition.
Indeed, that’s what Landru was presumably
made for in Star Trek, and where it messed
up was in bad design, not basic principle.
Humans are the reason you build machines,
they do not exist to act as machines.
They are replaceable, by say a race of rebellious
androids or some alien civilization.
They could be supplemented too, by including
aliens, androids, or uplifted super-intelligent
animals as also people the machines served,
but they exist to be the end user of a production
chain, not just one element of it, there’s
no reason to keep us around for that capacity,
especially as we would be much worse humans
if made stupid.
You wouldn’t want the population of your
Generation Ship arriving at its destination
without reasoning or problem solving skills
because it was easier for the AI.
That might be a better way to look at things
too, as the end user of a production chain.
Normally discussion of having artificial intelligence
as rulers raises the objection that we need
to make our own decisions and decide our own
fate, but that’s not really a leaders job
anyway and we tend to get most resentful of
our leadership when they interfere in those,
it doesn’t really matter if that’s a human
or an AI, except that if you did make a very
good AI it probably would be way better at
its job, like any machine tailor-made to its
purpose, at least when prototyped and tested.
That may also be part of the problem with
them in scifi, it's usually some great act
of desperation, by a collapsing society or
some reckless visionary that led to the machine
overlord’s creation, so presumably didn’t
have time for prototyping and public scrutiny
and revision.
This always assumes the post-discontent society
arose through desperation or deception though,
but remember our weather-predictor example,
it predicts the weather well and issues advice
on how to proceed.
It probably only needs to be advice too, since
that avoids folks disobeying simply for the
sake of disobedience.
Though since we talked about the improbability
of evolving immunity to control earlier, given
that those who followed the machine’s advice
– assuming it was good advice – would
prosper, then a trait for obedience to the
machine would be an evolutionary advantage.
Amusingly if the machine later started to
break down and make bad calls, something also
common of Machine Overlords in scifi, then
those with that trait would start to fare
worse, and the habit of disobedience might
become an evolutionary advantage again.
Your Machine Overlord isn’t necessarily
your president or king, nor singular, you
might have dozens or thousands of different
AI running various fiefdoms, like the AI in
charge of keeping the water supply clean and
another in charge of preventing forest fires,
and they might get into conflicts over that
– see our Machine Rebellion and Paperclip
Maximizer episodes for some of the particularly
peculiar brands of crazy a machine with a
specific end goal might have.
Indeed, if you had all those local controllers,
or advisers, all voluntarily and cheerfully
made, you might end up with a genuine Machine
Overlord – an Overlord over those machines,
human or machine itself, just to coordinate
and arbitrate their areas of conflict.
Critical notion though: A post-discontent
society needs a primary purpose for why its
enforcing post-discontent lives, why it is
basically brainwashing folks to be happy,
same as a machine overlord needs a reason
to keep humans around.
Given that we are not useful for production
if you’ve got intelligent machines, and
not useful for innovation if you have super-intelligent
machines, we are usually limited to either
it being the machine’s created purpose to
provide for mankind or it keeps us as pets,
which is similar.
Either way, it is only keeping us like cattle
and post-discontent if it is badly programmed,
at least if it's universal post-discontent.
Just as we said of post-scarcity, Post-discontent
can be specific to particular Needs.
This gets us to our big one, and a way we
might end up as post-discontent ourselves.
We often say life would be great or peaceful
if only such and such was less common, be
it greed or violence or ignorance or so on.
So a civilization might decide to be post-discontent
about something specific, and again post-discontent
here means twisting the intent of post-scarcity.
Post-scarcity means you have no shortage of
something to fulfill a human need, post-discontent
means people don’t care that there is one.
We need sleep for instance, and might engineer
future humans to lack that need, rather than
cure insomnia and find ways to make sure everyone
could enjoy a full night’s sleep.
They might do that eliminating the desire
for high social status, or greed, or violent
tendencies, or just moderating them in everyone
or moderating them in those with the most
severe cases.
Post-Discontent-Lite, as it were.
Now mind you we already do this, encourage
folks to control or outgrow more excessive
displays of greed, ambition, or aggression,
and indeed we usually consider these healthy
in moderation and when channeled toward good
ends.
Societal opinions on that can shift with time
too, it's not generally acceptable to punch
someone for insulting you, no matter the insult,
nowadays, but even when I was a kid it was
generally felt that there were insults that
merited sending someone to the dentist with
their front teeth in a bag, so a future society
might be even more opposed to it… or less
for that matter too, if your medical technology
is good enough and universally available or
dirt cheap, even stabbing someone in the chest
might just be considered rude.
I mean if your civilization is pretty much
full on cyborg, where even little kids are
full of nanomachines that can repair tissue
damage and mind augmentation that can shut
off pain, then kids might chase each other
around the playground with guns, real ones.
In any event if a civilization feels like
some human trait is hindering it, it might
well decide to go a bit beyond cultural discouragement
to limit it, remove it, or deal with folks
with a surplus of it.
Now not every apparently slippery slope is
slippery, nor do we always slip on them, but
that does seem like the sort of thing that
would get broader with time.
It’s also the sort of thing that doesn’t
have an evil ruling elite forcing it on the
masses, but would generally have the rulers
be just as indoctrinated as everyone else,
so there’s no one to overthrow and probably
no central machine you could smash to shut
the effect off.
Another indication of a brainwashed society
is that if folks shake free from it, they
are quite likely to report themselves, thinking
of it as an illness.
Even the ones who have their eyes opened,
so to speak, might despair being the seeing
man in the world of the blind and pop into
the brain washing facility rather than have
to spend their whole life afraid of being
caught and seeing no hope for convincing others
to spare them, let alone join them.
Remember they are brainwashed, they do not
think they are being cruel by reporting you,
it is a kindness, and they certainly do not
want to be unwashed.
Who wants an unwashed and dirty brain after
all?
Nor is evasion or deception likely to be easy,
scifi often shows those citizens as rather
zombie-like and dumb, but as we’ve seen
today, that’s not the intended goal since
you only keep humans around for their brains
anyway, and there’s no reason to think they
would be blithering blind fools just because
they had some particular type of brainwashing
– though of course curtailing ambition might
make folks lazy, curtailing aggression might
make them docile and non-confrontational,
and so on, the human mind is a complex system
that might be very subject to major side effects
from minor tinkering.
But if we’re working on the premise that
the folks who did it wanted a minimal impact
on humans and were careful and smart about
the process, then they may be brainwashed
but won’t be stupid and thus will tend to
work to perpetuate the system and do so pretty
ably.
Remember that the capacity to brainwash folks
also implies a strong mastery of the mind
and psychology too, the folks doing it are
likely to be good at anticipating and recognizing
undesirable side effects.
So that’s the key thing with Post-Discontent
Societies and Machine Overlords both, and
they might often show up together.
They might not be as bad as they seem in fiction,
and probably are less likely to be extreme
or sneak up on folks, and that’s all a good
thing because if one does get in place, odds
are good it's going to stay in place and be
near impossible to get rid of.
It’s also one of our better Fermi Paradox
Solutions, as to where all the older alien
civilizations are, because if you are ruling
some planet or system this way, it doesn’t
behoove you to spread out and risk losing
control or drawing attention from others.
On the other hand, we keep emphasizing that
these civilizations would not be stupid, and
they probably believe emphatically in what
they do, and they also enjoy the advantage
of being able to throw vast efforts at goals
without their citizens complaining, so they
might go out on crusades to give everyone
else the joy of joining their Post-Discontent
Society, or Else.
A fairly major point today was that machines
can work for you to enhance productivity but
you could end up working for them instead,
and it can already feel that way sometimes
with all the endless apps and tools designed
to improve your workflow that often just seem
to suckup whatever time they hypothetically
save you with all time invested into learning
them or the next new thing.
It’s always good to improve your productivity
but where to focus your time to learn is no
easy task.
If you’re looking for some suggestions and
ideas for either evaluating your productivity
or improving it, I’d recommend Thomas Frank’s
course “Productivity Masterclass: Create
a Custom System that Works” over on Skillshare.
He offers a ton of great suggestions that
are pretty universal, and you can find plenty
more productivity suggestions or courses on
creative work like writing and graphic design
among Skillshare’s catalog of thousands
of classes for creative and curious folks
looking to improve their skills or learn new
ones.
Perhaps you’re trying to adjust to working
in a new environment or just looking to pick
up some new skill or hobby, Skillshare has
a course for it, whether you’re a beginner,
a pro, a dabler, or a master, Skillshare has
thousands of classes on a wide variety of
topics from experts to help you learn.
Skillshare is an online learning community
for creatives, where millions come together
to take the next step in their creative journey,
and Members get unlimited access to thousands
of inspiring classes, with hands-on projects
and feedback from a community of millions.
If you’d like to give it a try the first
1,000 people to click the link in my episode
description will get a free trial of Skillshare
premium so you can explore your creativity.
Act now, and start learning, today.
So this wraps us up for the day but we will
be back this Thursday for a look at Oceanic
Aliens, and how life might evolve and develop
technology without land to dwell on.
Then the week after that we will ask not about
life without land but life without gravity,
as we contemplate civilizations that have
adapted to zero gravity conditions.
Then in two weeks we will close out the Month
of January with our monthly livestream Q&A
on Sunday, January 31st, 4 pm Eastern Time.
If you want alerts when those and other episodes
come out, make sure to subscribe to the channel,
and if you’d like to help support future
episodes, you can donate to us on Patreon,
or our website, IsaacArthur.net, which are
linked in the episode description below, along
with all of our various social media forums
where you can get updates and chat with others
about the concepts in the episodes and many
other futuristic ideas.
You can also follow us iTunes, Soundcloud,
or Spotify to get our audio-only versions
of the show.
Until next time, thanks for watching, and
have a great week!
