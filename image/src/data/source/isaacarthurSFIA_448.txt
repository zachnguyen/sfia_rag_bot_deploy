This video is sponsored by CuriosityStream.
Get access to my streaming video service,
Nebula, when you sign up for CuriosityStream
using the link in the description.
There are so many hurdles in our Universe
keeping intelligence from arising.
Once it has, it seems inevitable that intelligence should pursue technology…
but perhaps it isn’t.
So today we return to our Fermi Paradox Great
Filters series for a fourth installment of
what had been intended just to be a trilogy,
focusing first on what factors of our universe
and galaxy might make life rare, then what
might make life-sustaining worlds like Earth
rare, and finally on what might make the evolution
of intelligence rare.
In Rare Intelligence, we did look briefly
at what might make the rise of technology
once you had intelligence less inevitable
than we might think, but mostly concluded
that once you had a value for technology it
might not be inevitable you’d go down that
path but most would, so it would probably
be a minor filter at most.
Since that episode came out – a little over
2 years ago – I’ve been thinking on the
matter more and I’m no longer as confident
on that assertion, and we’re going to dig
into that today and focus more on some psychological
and sociological phenomena that might present
hurdles.
Since it has been over two years, a brief
refresher is appropriate and you may want
to check out the original trilogy if you haven’t
seen it recently or ever.
Combine all that with our tendency to do long
episodes, especially when discussing the Fermi
Paradox, and you probably want to grab a drink
and a snack before proceeding.
We often abridge what the Fermi Paradox is
when discussing it, since we discuss it so
often and want to save time, and because its
exact meaning is a bit variable.
Fundamentally it’s expressing the apparent
paradox between the vast age and size of our
Universe and why that Universe doesn’t seem
to be swarming with civilizations, especially
in modern times where we can see just how
common stars like our own are and how many
seem to have an abundance of planets in orbit
around them.
Many solutions for explaining it have been
offered, but the focus of this series is just
that there is no paradox because we’re simply
massively overestimating how likely life is
to arise, grow to complexity and diversity,
get smart, get technology, then grow to be
a galaxy spanning civilization we could easily
spot.
Looking for massive civilizations is a critical
notion with the Fermi Paradox too, we couldn’t
see a clone of ourselves even 200 light years
away unless we were staring right at it, and
of course if it were on the same timeline
as us, we’d not see anything anyway because
their first radio signals would still not
have reached us.
Timelines of mere thousands of years mean
very little set against the age of the Universe,
but it’s not the whole Universe that counts
for the Fermi Paradox, since our Universe
is fairly young and it would seem unlikely
anyone could have a headstart on us by several
billion years, so it’s only our relative
neighborhood we can even meaningfully discuss.
The farther out we look, the more universe
we see, but the younger and more primordial
the worlds we see.
Eukaryotic cells, those with a nucleus to
them and what many of us feel was a fairly
important hurdle – or filter – on the
evolution of life, didn’t arise on Earth
until about 1.8 billion years ago by current
best estimates.
If we assumed that no galaxy spanning civilizations
could have arisen before that, then there’s
no chance of finding any farther out than
1.8 billion light years, because the light
from then couldn’t have reached us yet.
There are about a quintillion stars in that
volume, a billion-billion.
That’s a big number on which civilizations
could have arisen from and spread out to the
stars, but none seem to have.
Now there could be a single specific reason,
but we usually assume that there are several
minor and not so minor hurdles along the path.
We categorize these as Lesser, Minor, Major,
and Great filters, where lesser ones are merely
more likely than not to stop advancement,
Minor Filters are uncommon to pass but not
rare, and Major Filters are the kind that
less than a percent succeed in passing.
On the far side, a Great Filter is what we’d
normally consider ‘lottery-odds’, million-in-one
or less, and many are suggested for these
and we often group related filters into an
overall Great Filter too.
One of these on its own might reduce the odds
to one in a quintillion all by itself, and
of course we have some of these we can speak
to with great certainty already, beginning
with that ‘one in a quintillion’ probability,
that’s how many stars there we might hope
to see something emerge from, but it’s really
only how many planets we might expect at most
that could realistically hold life.
We just take for granted it needs to occur
on a planet, and that Earth-like worlds and
large moons around gas giants is where all
that action takes place.
That is already a huge filter, because virtually
none of the mass in our solar system is in
the planets, rocky planets probably make up
way less than a millionth of the mass of our
Universe.
Moreover, only the thin crust of those worlds
would be hospitable for life, generally speaking,
so we’ve already cut the amount of matter
that might be involved in biology down to
around a billionth of the available matter
before we even get out the gate just by focusing
on planets.
We have discussed how valid that assumption
is in other episodes like Panspermia or Void
Ecology, but it’s an assumption that’s
so taken for granted that we usually don’t
even think about it when discussing the Fermi
Paradox.
I like pointing it out though because the
Fermi Paradox is so often phrased in the context
of Drake’s Equation, a fairly straightforward
and popular equation where the variables are
things like how often stars or Earth-like
worlds form, for which we have fairly solid
data and its other terms discussing the probability
of life arising or getting smart or not killing
itself off are great big question marks, and
we tend to naturally assume their values aren’t
going to be too different from the other ones
we know.
There are 7 factors and even if they were
all just 1%, our cutoff line from minor to
major filters, and we know some are much more
probable than that, but you’d still have
around ten thousand galactic empires in our
visible window of time and space, it would
be freakishly improbable that none of those
were close enough to us in space and time
to be currently visible.
For stacking filters, it doesn’t take too
much to lower the odds to next to nothing,
and throughout this series we always emphasize
that it’s a cumulative process, so we’re
not trying to argue today that technology
is so rare that less than one in a quintillion
intelligent species ever develops it, just
that after you’ve winnowed worlds down to
the relative few that make it to intelligence,
it doesn't take much more to winnow it further
on technology.
Same as when we get to the Late Filters next
month, those filters which we still have not
passed but that are needed to make you visible
to us on Modern Earth, we don’t need to
show that those add up to even a major filter.
We don’t know what the odds on most of these
filters are, but if they combine to reduce
it to less than one in a quintillion, then
the Fermi Paradox is no paradox at all.
And I think we’ve more than justified that
as a reasonable hypothesis in the previous
episodes, and this recap has already gone
on long enough, so let’s get to it.
Once a species has cleared all those early
filters and intelligence is in play, psychology
becomes a critical factor in discussions of
the Fermi Paradox.
But speculating about alien psychology is
a lot more of a crapshoot than discussing
astronomical or even evolutionary processes
that affect simpler lifeforms -- which is
why we generally discuss psychological solutions
to the Fermi Paradox in our somewhat tongue-in-cheek
Alien Civilizations series, where the need
for a lot of guessing is the elephant in the
room.
But it’s is educated guessing.
Just as an example, we tend to take as a given
here that the most probable pathway to serious
technology is civilization, via a species
that is both social and curious.
It’s hardly a bad speculation either, you
can’t develop technology until you’re
smart enough, but brains are expensive to
run and shouldn’t just leap massively in
complexity out of the blue.
Such being the case, you start using technology
when you’re just barely smart enough, and
thus you make a lot more progress a lot sooner
and faster if you’re social and can specialize,
meaning Alex can specialize on crafting arrows
while Bob can focus on crafting the bows that
shoot them and Callie can specialize in crafting
traps to keep the caves or huts free of vermin
while Devon learns how to dig holes to dump
disgusting garbage in to not attract them.
Garbage, vermin, and disgust responses are
going to be a major theme for later today
too, as a heads-up for any of you snacking
during this episode, fair warning.
By specializing we can get more done when
we’re not too smart yet, but that’s only
handy if you’re social critters, and so
we can actually list that as a fairly decent
filter.
Early inventions are of less use and represent
a far bigger investment of effort by each
individual if you don’t all cooperate and
in much more varied and vulnerable ways than
simple cooperative hunting or even child-rearing,
where fundamentally everybody is fairly interchangeable
or expendable and a pack doesn’t need that
many members.
However, let me but a caveat on there.
It is good reasoning but it assumes our style
of brain.
You could have the equivalent of neurons be
woven into muscle fibers instead, muscle memory
in a very literal sense, or into the bones,
or some transmission mechanism that could
rapidly speed up due to a minor mutation.
Suddenly a species that had been early-hominid-smart
all bounce north of Einstein on brain power,
and maybe even so much that they don’t need
multiple generations and cooperation for major
advancement, particularly if they are rather
long-lived, and we have no reason to assume
lifespans under different biology would match
up to our own.
So you might have some race of long-lived
geniuses who are anti-social.
This is not a great path to civilization and
star-spanning ones at that.
Still, it would be an example of a caveat
where technology did not arise from a social
species that was just smart enough to acquire
technology through each member specializing.
I think, as we contemplate that scenario,
that it also is an example of an exception
that proves the rule, since ultimately the
Fermi Paradox isn’t about if you get smart
or even get technology, but if you do something
with it that lets us see you very far away.
We use the galaxy-spanning civilization as
our main example because we could see them
very, very far away just by their impact on
their environment as they started engaging
in stellar engineering and those other things
we associate with such civilizations.
See the Kardashev Scale episode, or really
around a third of the episodes on this channel,
for more details on why such civilizations
ought to be nearly impossible not to see.
Regardless, when discussing filters for the
Fermi Paradox, it’s all a probabilities
game and so we’re interested in what is
most probable, not some unlikely scenario
that might explain one anomalous civilization
out of thousands.
In that context, your most probable pathway
would seem to be more or less the one we went
down.
Brains are expensive and need to offer a benefit,
part of that benefit for us is it’s use
for social purposes, which makes it viable
for us to share work and be more productive
at it via specialization.
Related to this is Dunbar’s number, the
cognitive limit of the number of individuals
one can maintain a stable social relationship
with, usually listed as about 150 for humans,
which may also influence specialization.
One can imagine this as a filter, since species
with a lower Dunbar Number might have a very
hard time specializing much, while conversely,
one with a higher one might have a real problem
developing a culture able to function while
exceeding that, because it wasn’t so necessary
even fairly early on.
This socialization and specialization presumably
leads to stationary villages, after the rise
of agricultural over hunting and gathering,
and eventually to the rise of cities.
Long before we had what we think of as nations
we had city-states where thousands of folks
could congregate for specialized tasks, which
they used to trade or raid their less urbanized
and specialized neighbors for food.
And the city is both the root of the word
and the start of what we consider… ‘civilization’.
We already discussed in Rare Intelligence
how important that transition to agriculture
was for increasing your population density
and various ways that might fail to emerge,
indeed some theories suggest it took so long
not because we didn’t really understand
the concept but because we had to wait till
those plants slowly adapted to be more edible
through a long process of us selectively gathering
them until they’d mutated to be more optimized
for us as a food source.
Your basic diet can easily be considered at
least a Lesser Filter since only a more omnivorous
scavenger type is really well-positioned to
pursue that option and indeed our own setup
as a persistence predator, capable of sweating
to cool ourselves and jogging all day long
when needed, something fairly unique to humans,
is probably a pretty big factor in how we
can get away with fueling and cooling our
gigantic brains.
Probably wasn’t a predator thing originally
either, we might easily have combined our
great vision and endurance to let us spot
circling vultures or similar and go charging
off to scavenge that prey.
We’re very opportunistic in our style compared
to other apex predators, we tended to scare
our prey to death or run them to exhaustion
and poke them then.
We certainly did not, in the early days, have
a dozen of us run up close and stab healthy
and fresh mammoths out of the blue with spears,
they’d have mopped the floor with us.
I mention this though mostly because our increasingly
rational brains didn’t just pop out of nowhere
and decide to start making tools.
Our brains are survival focused, and part
of that is for socialization, an important
part of surviving in a pack, another big part
of that is danger sense, which we’ll return
to in a bit, and another is abstraction, what
makes complex speech and invention possible.
Probably not our big brains’ original main
survival purpose though.
To avoid getting killed you need to know something
is a good course of action, and you can do
that by observation or instinct, but you can
also do that by running simulations.
It’s a lot cheaper to imagine what might
happen if you run up to a mammoth than to
observe other tribe members doing that and
getting pasted, let alone waiting generations
and generations for that to evolve into a
specific instinct.
We run scenarios through our heads over and
over and over again imagining how it might
play out, indeed we can get pretty neurotic
about doing that, but that is a massive survival
advantage and it’s also the sort of thing
that can lead to someone thinking “Hey,
if my arm was longer I wouldn’t need to
be so close to the mammoth to stab it, right
now even when we go after an injured one that
can’t move, we’ve got to go poke it where
it can’t react fast enough or at all.
If I stuck my knife on the end of a fake arm,
like a tree branch, then at worst it will
just break my fake arm when it swings its
tusks around.”
And those obviously are some examples of when
a big expensive brain that takes years to
grow can turn out to be a valuable investment.
I should also note that while we often look
with horror or disdain at our ancestors’
habit of sacrificing animals, valuable things,
or even people, that we might think of that
as an early attempt at investment and bargaining
and trade.
Big concept there, unlike most animals, who
at most are just instinctively wired to set
food aside for later like a squirrel, humans
think on the future a lot and are willing
to suffer in the present to reap a bigger
reward down the road.
They were just as smart as us back then, though
way less educated and scientific as it were,
we’re a lot more practical in our present-day
sacrifices to future rewards but it’s probably
the same concept on display.
Our minds can envision many possible futures
and our memories let us replay the past and
ruminate on alternative paths, and we can
realize that a little sacrifice today can
pay off dividends down the road.
That’s not as obvious a thing as you might
think, as the Stanford Marshmallow Experiments
on delayed gratification half a century back
showed.
Little kids have a very hard time waiting
even brief periods to eat a piece of candy
if told they will get even more candy if they
don’t eat it and wait, and that’s just
with kids old enough to clearly understand.
Think about something like agriculture, where
you need to actually understand that you must
put food in the ground, or not kill it and
eat it now, and wait months before you get
more, then actually bring yourself to wait
those months, and with the knowledge that
it will require oversight, maintenance, protection,
and luck to get that final yield.
To us this is natural, and we get better at
it as we age, indeed delayed gratification
is practical synonymous with what we mean
by maturity, but that’s a big and non-obvious
step, and one many critters, even smart ones,
might never make.
And remember that’s just agriculture, one
of the simplest and most fundamental of our
technological steps, and delayed gratification
is a cornerstone of a technological civilization.
Even if they have a capacity for it, it needs
to be a large capacity and one that makes
it profitable in their setup, and which they
believe in.
Often it won’t be.
Creativity is not nearly as valuable to an
individual as we tend to think it is these
days, in a society that runs on that, because
only a very tiny portion of creations, even
useful ones, ever get used enough to support
the creator.
In a smaller society, even a clearly useful
invention or idea represents such a large
investment to dream up and make that it often
might only get invented because you literally
have a parasite class that can sit around
on their butts being non-productive and just
one in thousand of them makes something useful
enough to have justified their daydreaming.
Ironically a society that doesn’t tolerate
such useless layabouts, which is entirely
probable to pop up, might bash their heads
in for being lazy.
But speaking of parasites, I mentioned that
humans evolved a pretty impressive danger
and disgust mechanism to avoid dying.
Do not eat something that looks or smells
off, do not step in something, do not let
a stranger nearby who may have hostile intent
or be carrying a disease.
Do not underestimate how powerful that impulse
is even in a rational mind.
The saliva in your mouth is obviously not
dangerous to you, but If I hand you a clean
cup and tell you to spit in it, then drink
that cup, while that is entirely safe, most
folks won’t do it even after the reminder
about how safe it is.
That thing was ejected from a human body and
is not meant to go back in.
They’ll get violently nauseous about it,
indeed just writing about it makes me a bit
ill, and you can try thinking about it and
seeing how you feel about doing it, even reminded
in advance that it is not even a little dangerous,
using that big brain capable of running simulations
of actions.
Now we only know that’s safe because we
know science, a pre-technological society
does not, and is likely to be terrified about
any possible source of contamination even
if they know that sometimes its beneficial
to risk it, a good reminder of what the expression
“I have a strong stomach” is generally
implying.
I don’t know when or why humans started
thinking of fire as a means of purification
but that’s not a super-obvious connection
and it’s not hard to imagine a species might
be terrified of fire – many are – and
have a disgust feeling associated to it also.
Such being the case, even if you could bring
yourself to use it for warmth and light, there
is no way you’re going to eat food that
was in one, so you never invent cooking.
Indeed, you might not be willing to use anything
forged in a flame either, or at least not
feel comfortable using it for storing food
in, like pottery.
Or you might be especially disgusted by reusing
anything that previously had food on it, because
dangerous rot sets in on that world far faster
and scavengers are a much rarer and speedy
lot.
Maybe a very plentiful fruit turns poisonous
as soon as germination begins to discourage
any animal eating it once it’s started growing,
and will kill off any rival plants competing
for that growing space.
Hardly an improbable adaptation for a plant
to have and hardly an improbable mutation
for animals to get, to avoid eating from any
object or surface we associate to having had
food on it some time back.
Could really mess with your willingness to
store food or reuse storage vessels.
Our early cave paintings and art, and later
our writing, mostly were done with inks that
were food based and a culture with a big fear
of leftover food in any format might be very
unwilling to use such things to decorate their
homes and persons.
If they’re afraid to use ink and skins to
write stuff down, they’ve got a problem,
and for that matter a species with very good
memories bordering on the eidetic, or very
good at crunching numbers in their heads,
might never get into writing stuff down or
inventing the abacus or tally sticks, and
that might actually hinder them on further
development, for the same reason a critter
with sharp claws might never invent stone
knives.
Same, they might be rather horrified at using
bones for tools, and while we call it the
Stone Age, bones played as big a role in our
tools, and you wouldn’t be sewing any clothing
with a rock needle, nor are you likely to
be wearing around the skins of dead animals
if that horrified you, especially if on your
world they rotted or decayed faster or were
just less suitable for clothing, as many hides
are, and it might be a bit of coincidence
that our preferred prey animals happen to
have handy and easily preserved hides.
If we weren’t big-game hunters but just
scavengers or vermin catchers, we might not
have gone that path.
So too, we use animal corpses a lot in early
food and water storage, we probably got yogurt
invented by carrying milk around in some animals
bladder, and sausage is an ancient method
of food storage that’s not terribly pleasant
to think on.
Desperation and necessity are mothers to invention
but often disgust drives can override even
that, and if you’re wondering why I’m
focusing on that, we need to come up with
a reason that would prevent smart critters
able to invent technology from ever doing
so even on timelines of millions of years.
An ingrained disgust instinct toward some
critical foundation technology or the situations
that can spawn it are handy for such a barrier.
Fear or disgust of fire is obviously a great
one, since as we’ve discussed in our looks
at underwater species in Ocean Planets or
Uplifting, there really is no decently plausible
path to technology without fire.
Technology is a stats game, same as the rest
of the Fermi Paradox filters, so anything
that makes you less willing to use a piece
of technology or less likely to be in a situation
that will prompt thinking it up can be enough
to make it a decent filter.
On the flip side, a species with lower disgust
sensitivity might get itself wiped out by
plagues a lot whenever they started congregating
in large enough numbers to support technology.
Storing your food also attracts vermin, a
big enough problem I actually puts our pets,
often involved in vermin control, as one of
our lesser filters last episode.
For that matter, while an anti-social civilization
has a big hurdle to developing technology,
so would one that was a little too friendly
and open.
New things are dangerous, they really are,
we’re just about as desensitized to that
as any humans ever have been, so we sometimes
forget that.
There’s a reason why some wandering stranger
by themselves is by themselves and looking
for you.
Maybe they got kicked out of their tribe for
good cause, and you would be unwise to offer
them a home, maybe their tribe got very sick
and they fled, carrying a disease.
A species with very good immune systems or
where viruses or other pathogens never really
got the same foothold might lack that fear,
easily congregate together, then suddenly
hit critical mass for that to be a problem
and develop a terror of ever putting thousands
of people in a tight area, so they just never
develop much and have little interest in technologies
that let more folks survive.
These are all examples of how a smart species
quite capable of developing technology might
hesitate to do so and keep hesitating indefinitely,
and that’s important to the notion of inevitable
technology.
Many of us, myself included in spite of this,
tend to feel that once they hit a certain
critical mass of seeing technology as useful,
that will keep going, and that since nothing
is really putting a time limit on them, even
if they hesitate to advance once, twice, or
a hundred times they will eventually make
that next step.
After all, we invented fire over a million
years ago, we didn’t use it for all that
much until pottery and metal-working popped
up around ten thousand years ago, our whole
civilization historically fits into only 1%
of that fire using timeline, and our modern
brain has basically been around for about
ten times longer than our civilization has
been too.
So maybe that is an example of us just going
at it till eventually the dam broke, and since
it did we have enjoyed almost constant steady
technological progress.
Most so-called Dark Ages are more myth than
truth, and resulted in very little loss of
knowledge, and indeed many of them also had
technological gains not only globally, far
from the fallen civilization, but actually
in the alleged collapsed area.
I wouldn’t go so far as to say that science
specifically was the cause but more its conceptual
forerunner, thinking things through a lot
and questioning fundamental assumptions, arguably
offshoots of delayed gratification themselves.
You’ve really got to be willing to pick
through an idea to start challenging any sort
of instinctive distaste, and that eventually
leads to gathering and documenting evidence
and then creating falsifiable experiments
to test hypotheses, but once you do that would
seem so clearly beneficial that you’re going
to keep at it, even if you have false starts
and setbacks, unless it leads you to a catastrophe
like getting wiped out by artificial intelligence
or such, which we’ll save for the Late Filters
episode.
So while I feel we could make a decent case
that many intelligent critters do make it
up to basic tool use and invention potential,
or even capability, but never proceed beyond
that, being smart but primitive, and thus
it might be a decent filter, I’m very dubious
about extending that to where you are already
at the city building and writing stuff down
point.
As I said, we really have not had many genuine
collapses and those mostly local and less
severe than often popularly claimed.
Many of those are also thought to have had
environmental causes, and such things don’t
make good fermi paradox filters.
One could argue that they might have a strong
aversion to something like the steam engine,
maybe on a world where geysers were more common
and deadly, but that would not seem something
where we could expect it to be more common
than not.
Or they might have a very extreme case of
Uncanny Valley, or fear of machines or mannequins
that seem very close to their likeness but
not quite right, so they won’t even contemplate
computers or automation that even vaguely
apes their thinking or function, though that
might be so extreme they loathe their neighbors
to a degree of xenophobia unrivaled by even
some of our most vile historical examples.
Heck that might be triggered by something
like a sense of familial smell or visual marker
that is hereditary and makes them uncomfortable
around anyone not closely enough related to
share the full marker.
Or they might be very disgusted by other animals,
okay with eating them but not in keeping them
as livestock or pets or working animals or
even employing their corpses to make tools
or clothing from, but again, possible but
nothing really pushing that to be a common
let alone likely case.
We can potentially have even lower hurdles
than our 50/50 Lesser Filters that could stack
up, Least Filters perhaps, lots of things
where 90% or 99% of the time they got passed
by but there were just so many of them they
added up, and indeed there doubtless are plenty
of those too, wipe outs by asteroids or planetary
collisions and ejections for instance, less
likely than not too happen but many such improbable
filters might do the job enough to make the
already improbable just a little too improbable
for us to see another civilization yet.
But I’m not seeing any of those along our
own path from the nominal dawn of history
from a few thousands years ago onward.
Rate of progress might be slowed but never
seems to stop or reverse except locally and
temporarily and that means nothing on astronomical
timelines.
Plus once you get very into reason, you do
start having the capacity to dissect impulses
like disgust and work to overcome it by exposure
or dilution or modification when you have
solid proof it is both safe and useful.
So it does seem like on balance that once
you get that capacity for abstract thinking
and reasoning you’re going to be on your
way forward to technology except where you’ve
got a strong compulsion to avoid a keystone
technology, and while my gut says that such
aversions are probably no more common than
would offer a lesser or maybe minor filter,
we really just don’t know.
There are a ton of little things that had
we not had or gone in a slightly different
direction, we might have ended our path to
technology but not too many of them seem decisive
roadblocks where another path might not have
gotten there too.
In a way, this filter after intelligence,
if it exists, seems less about technology
itself and more about developing the ability
to contemplate hypothetical future outcomes
and willingness to engage in delayed gratification
or short term suffering or risk to get to
a desired result.
I do happen to think that capacity is a decent
filter though.
But fundamentally, much like our assumptions
that the evolution of a basic brain will tend
to lead to ever more sophisticated ones, there’s
a lot of guesswork and possible bias in those
assumptions.
We got there, so it can’t be too weird,
but we know at least something we think is
likely can’t be that likely or the Great
Filters solution to the Fermi Paradox wouldn’t
work, assuming it is the right solution for
the Fermi Paradox, and that those bigger filters
all lie behind us, not ahead, but we’ll
save that for next month in Late Filters.
Of course the alternative perspective to Rare
Technology is inevitable technology, that
technology will develop, quick or slow but
almost always, if you have a species with
a complex and abstract brain, and I felt like
that notion needed looked at and at the same
time, our poll runner up for our last youtube
poll was the suggested topic “Could Technology
Develop without Fire?”, so I decided to
do a companion episode looking at that other
extreme and I just released that over on Nebula,
to discuss if technology might still develop
even on worlds where that most basic technology,
fire, is denied to them.
If you’d like to catch that video on Nebula,
or our other recent exclusive, “Me, Myself,
and I: Cloning and Duplicants, you can get
full access to Nebula for free when you sign
up for CuriosityStream.
So in addition to being able to see their
thousands of top-notch documentaries and non-fiction
titles, you can now also catch all of the
Nebula-exclusive content I and other education-focused
channels have been making, if you sign up
for a year subscription of CuriosityStream.
A year of CuriosityStream is just $19.99,
and it gets you access thousands of documentaries,
as well as complimentary access to Nebula
for as long as you're a subscriber, and use
the link in this episode’s description,
curiositystream.com/isaacarthur.
We started Nebula up as a way for education-focused
independent creators to try out new content
that might not work too well on Youtube, where
algorithms might not be too kind to some topics
or demonetize certain ones entirely and I’m
very glad that we’re partnering up with
CuriosityStream as we get ready to invite
in more creators and bring more content to
Nebula.
So now in addition all of CuriosityStream’s
great educational content, you’ll be able
see videos from independent creators like
CGP Grey, MinutePhysics, Wendover, and of
course, myself, just remember to use the link
in the video description when signing up.
As I mentioned, that topic, “Could Technology
Develop without Fire?”, was the runner up
in our last poll, and we do have another one
up this last week for you to vote in, over
on our community tab, and it will be open
a few more days if you haven’t already voted
in it, and we often do one or more of the
runners up too.
The polls we run for episodes here on youtube’s
community tab usually get sourced from our
Facebook Group, Science and Futurism with
Isaac Arthur, where the polling method let’s
folks add their own suggestions and we take
the top 5 and put them here to get voted on.
I’m generally trying to do one of those
every month or two so if you’d like to suggest
future topics the next time we do a poll,
or just enjoy discussing our show’s topics
with other folks, you can join that group.
It’s linked in the video description along
with all of our other social media.
Next week we’ll be looking at some of the
challenges with security on social media and
the modern internet, in Cybersecurity.
While that will be one of our more near-term
and practical episodes, we will also look
at some of problems we might expect to develop
further ahead in the future.
The week after that, we’ll be back into
the far future to look at spaceship design,
from interplanetary ship considerations to
intergalactic vessels moving at ultra-relativistic
speeds.
For alerts when those and other episodes come
out, make sure to subscribe to the channel.
Until next time, thanks for watching, and
have a great week!
