This episode is sponsored by ExpressVPN.
We live in an era where technology improves
constantly
and every day brings new marvels,
but what if we reached a wall,
beyond which technology could no longer improve?
Not a day goes by where we don’t see new
improvements in our knowledge and technology,
and while we often fear that civilization
might collapse and remove our technology,
as we looked at in Post-Apocalyptic Civilizations
or Techno-Primitivism, we rarely contemplate
the notion that progress would simply stop.
In some ways the idea of technological progress
grinding to a halt is even more unthinkable
than it falling backwards.
We can believe humans might mess up and wreck
society, but we’re very predisposed by our
culture to think knowledge is a thing which
is infinite and that there is always a new
stone to turn over.
Yet this not only may not be true, but realistically
almost certainly can’t be, at least where
science and technology are concerned.
The Universe has rules it follows which are
presumably finite and we should eventually
discover them all - or discover all those
that aren’t physically impossible to infer
- at which point technology would continue
to improve for a time, quite probably many
generations at least, but would have to plateau
out.
Perhaps not, perhaps the rules of the Universe
are infinite or shifting in time, perhaps
there are an infinite number of other places
and realities or layers which we may hurl
our curiosity toward eternally, things that
seem beyond our understanding now.
Additionally, a civilization need not hit
such a scientific brick wall to technologically
stagnate either.
Indeed it might voluntarily choose to halt
further scientific and technological inquiry.
Today we’ll examine what might cause civilizations
to do this and what the implications would
be for such societies.
Now, it is easy to imagine folks turning from
technology in part, after all many of us do
to some degree.
Indeed I’ve noted a tendency for those of
us heavily involved in technology to often
hide ourselves from it a bit, even if just
to decorate our homes with a vintage or antique
theme.
There is a certain stress to the constant
chaos of technological disruption I suspect
most viewers here can well appreciate, either
from being on the cutting edge or from feeling
constantly left behind by that edge.
I doubt it’s a coincidence that so many
of us view getting away from stress as getting
away from technology, and go off the grid
for vacation and often more than simply muting
our phone and not checking our email.
Against that, we have to acknowledge that
our passion for technology is at least in
large part composed of a desire to make life
better.
We wish to cure the sick, to make life healthier
and longer, to take away tasks which are unpleasant
or dangerous, to bring prosperity to all.
These are admirable motives but not necessarily
perpetual ones.
What drives us to further innovation when
Utopia has already arrived?
Now of course Utopia is a relative thing and
not a thing we’d really expect to reach,
but technological progress is not made by
casual labor.
Science and technology are almost entirely
the product of a small minority of the population
that is obsessed.
Reasons for that obsession vary but for many
it is that drive to make life better.
That’s also what drives the funding for
such improvements and what makes scientists
and engineers work together, neither group
being terribly well known for its love of
teamwork.
It also tends to be true that the more you
discover the more effort is needed for each
new discovery.
Long past are the days where the majority
of scientific endeavors uncovering new frontiers
could be done in a dusty lab or garage by
one lone innovator on a shoestring budget,
especially in physics, the foundational field
for exploring new laws of science, where billion
dollar labs must often be commissioned just
to make one tiny little step forward.
Also long past are the days where a true polymath,
an expert on all things, could exist.
Now even a great expert is only going to know
a small area of their own field.
As the saying goes: An expert is someone who
knows more and more about less and less, until
they know everything about nothing.
This will only increase with our knowledge
and so too will the effort needed just to
get sufficient education to be able to advance
that field, even with the help of Expert Systems.
In a utopian or post-scarcity civilization,
where you personally have all you might want,
what drives you to devote decades to study?
Could technological progress simply peter
out from that combination of things?
Each new step takes more effort, while fewer
folks are willing to invest ever more time
into learning just the basics when they could
sit at home in magnificent health and wealth
tended to hand and foot by robots.
Now that might seem to imply an inevitable
end to technology but let’s add two caveats.
First, if we’re being honest, what drives
most scientists, especially the very best
of them, is often an utter fascination with
the topic to the point of obsession.
While many do passionately believe their work
will aid their fellow man, it’s not really
what keeps them chained to their desks burning
the midnight oil.
And while I suggested that funding for innovation
might dry up when the public sees less need
for it, such a drop in need implies a massive
level of prosperity.
If the average person is phenomenally wealthy,
it’s a lot easier to get funding for projects,
and self-funding might be viable too.
Post-scarcity societies might not have a deep
need for further technological improvement,
but they are pretty much by definition not
driven to be tight-fisted and frugal in their
efforts either.
Second, while we’d expect to see a rise
in the amount of knowledge needed to become
an expert in something, in order to further
press the boundaries of that field, we do
need to keep in mind that some of those fields
are things like neuroscience, cybernetics,
and education.
If you’re vastly better at teaching folks
or can outright augment the human mind, you
presumably can field a lot more experts as
they can learn more and quicker.
A civilization where everyone is a genius
due to technology probably doesn’t have
to worry about hitting technological walls
as quickly.
At least not from losing interest, of course
if there are a finite number of scientific
rules and useful technologies, than having
more and better scientists means you’d reach
that wall sooner.
And that is at least a partial rebuttal to
folks who fear post-scarcity civilizations
will inevitably end with most people being
basically stupid, lazy, hedonists wallowing
in their own affluence and decadence.
The same neurological and psychological super-technology
that let you improve people’s intelligence
also lets you instill in them an intense focus
and sense of motivation.
Of course some people might not agree with
that characterization about lazy hedonism,
and might be right to do so, but I choose
that language because it’s probably exactly
what folks would be saying if things began
getting very prosperous and they worried civilization
would collapse under its own success.
And if most folks feel life is pretty good
as-is, they might be much more receptive to
putting the brakes on further improvements
that make life easier.
We’d also tend to assume that while the
older generation might frown on the younger
generation as lazy, then you’d just have
to wait for them to die off.
This after all is hardly a new accusation,
justified or not, why back in my day we didn’t
have smartphones and you had to walk all the
way down to the kitchen to answer a phone
call.
However, this one too might be something technology
does away with.
One of the technologies we’re likely to
press harder and harder on in the not-too-distant
future is life extension and that could easily
end in effective immortality.
Many customs and traditions change as the
new are born and the old die off, but the
equation changes a bit if the old folks just
keep getting older while maintaining all their
health and vigor and probably growing in power,
wealth, knowledge, and influence.
This has its pros and cons.
Resisting change and new ideas from extended
lifespans might tend to prevent decay into
hedonism but might also act to slow positive
changes too.
Then we have one more reason to halt technological
progress… survival itself.
Technology is dangerous, very dangerous, very,
very, very dangerous.
As it improves, since the whole point of the
stuff is to allow a person to do far more
with far less, you have to worry about people
being able to make weapons of mass destruction
in their own basement.
The major way you get around that is with
technologies that let you essentially limit
people and spy on them, and some might say
that at a certain level of prosperity, they’d
prefer to put a halt on further technological
progress in order to maintain personal freedom
and privacy without needing to worry some
lunatic will end the world.
How big a mansion do you need, after all,
to feel like the risk of dying at the hand
of a lone psychopath or living under the watchful
eye of Big Brother is not worth it?
Now let’s restate that rebuttal.
The lone lunatic problem assumes not only
that such technologies are possible, that
would enable them to kill everyone without
us being able to stop it, but also that we
haven’t improved in neurology and psychology,
merely the material sciences.
An advanced civilization might not have lunatics
any more than it has plagues or garbage in
the streets.
They figured out how to fix that problem.
It’s a common theme in science fiction for
future technological advancements to often
ignore other major changes and impacts to
society that might happen, like ignoring what
massive energy abundance does to an economy
besides allowing fast spaceships.
Also overlooking the psychological and neurological
changes tends to be rather common.
Most settings tend to assume all the same
normal human vices and virtues, and in the
same quantities as nowadays, that we haven’t
figured out how to detect and treat a lot
of the problems that lead to criminal behavior.
It’s interesting though that many sci-fi
settings often display technological stagnation,
particularly space opera or anything dealing
with very ancient civilizations encountered
by humanity as we spread out.
Where you do get technological advancement
in those, it is often driven by very large
settings with many books, episodes, or writers
who want to bring something new into the setting.
Star Wars is a pretty good example, especially
if we take into account the old no-longer-canon
lore, where we do see some improvement over
time but mostly the technology isn’t much
different in the modern era from what we’d
see in the lore from the Knights of the Old
Republic era set thousands of years before
we ever encounter any folks named Skywalker
dwelling on a desert planet.
Even Star Trek is pretty guilty of this, having
ancient empires that never seem to spread
out much and whose technology, while better
than what Starfleet has, doesn’t really
seem that much better, for folks thousands
of years more advanced.
We see the same out of Doctor Who or Babylon
5 or Stargate or a ton of other franchises.
Ancient civilizations or glimpses into the
future often show more advanced technology,
but really not that much more advanced, when
we compare it to modern times contrasted against
a few centuries back.
Writers can be forgiven for not being able
to come up with a vast array of new technologies
every time they need a new book or episode,
but it often gives the impression of technological
stagnation.
On the non-fiction side of things, eventual
technological stagnation is practically a
prerequisite of any solution to the Fermi
Paradox, the big question of where all the
aliens are.
If technology is a constantly improving thing,
where anything is possible, you have to wonder
if some civilization a few million years old
would have Time Travel, Faster Than Light
Travel, and a million others super-technologies,
what we call Clarketech, technologies so advanced
they are indistinguishable from magic.
We’ve discussed in other episodes some of
the truly enormous civilizations and structures
possible just under known science, ones that
would seem to make those civilizations obvious
to anyone around them, and the sorts of things
possible with most science-fiction technologies
or Clarketech go far beyond that, making any
Fermi Paradox Solution that doesn’t rely
on either their not existing or being passionately
opposed to contact with us just not make any
sense.
This sort of thing is particularly bad under
any sort of accelerating model for science
and technology, such as Technological Singularities,
where progress keeps speeding up as you make
more and more progress.
Such a thing either needs to hit a wall, stagnate,
or you basically end up with something that
can only usefully be defined as a god.
Which is a common notion in sci-fi too, lots
of species that ascend to higher planes or
similar, but also doesn’t make a good Fermi
paradox solution, see our episode Aloof Aliens
for further discussion of that.
Now science fiction is exactly that, fiction,
and is limited by both the author’s vision
and often a need to make a compelling story,
which is tricky if you are living in some
actual utopia where everyone is genuinely
smart and enlightened.
It tends to make for boring stories if the
good guys are totally without physical limits
or psychological flaws, the regular populace
in the background are similar, and there are
no real bad guys to cause problems or conflict,
and the whole plot is just a spectacular display
of teamwork.
A highly advanced civilization would probably
tend to look more like that than our usual
fictional settings, even the fairly utopians
ones like Star Trek.
So what would technological stagnation actually
look like?
Well, it does of course depend on where that
stagnation took place and why it did.
We saw a number of reasons it might earlier,
and stagnation from hitting a true wall of
nothing new to learn is a very different place
than one in which you actively stopped progress
out of fear of ruin at the hand of advanced
technologies, and both quite different from
one where folks just stop putting much effort
into it.
Let’s consider a cyclic example.
As we mentioned in Cyclic Apocalypses, those
require civilizations fall into ruin after
they reach a certain point and hit the reset
button entirely.
Apocalypses recur over and over because they
keep making the same mistake and somehow fail
to leave their successors any clue about that
mistake.
We see that in discussion of a lot of doomsdays
that have been suggested down the years as
inevitable, and while I often agree about
the threat, I tend to think it strange, or
really arrogant, that folks suggesting them
as inevitable never seem to think it’s possible
everyone else will see the same danger they
did and take action.
I say arrogant because the implicit assumption
of that doomsday’s inevitability always
seem contingent on most other people being
stupid, blind idiots.
Now, that could occur with technological stagnation
too, for the type where they are stopping
for fear of a danger.
We’d tend to think a ban on Artificial Intelligence
and related technologies it might spring from
might be unenforceable as people would tend
to forget the reasons for the ban or dismiss
the danger, after enough time.
It’s certainly possible but I’ve never
really seen the justification for assuming
civilizations would forget things.
We did way back in the past because we had
to rely on oral traditional and accuracy of
memory, that’s why we know virtually nothing
about the history of any places before they
got writing.
However we tend to have much better records
after that even in eras where everything had
to be manually copied each time to some medium
like paper that was very prone to fire or
decay.
We’re a bit fixated on the notion that history
gets lost, but that’s not really been the
case in more recent centuries even before
computers, especially for major events.
Digital mediums and computers really alter
that equation.
There are no non-apocalyptic scenarios for
us losing track of major events or concepts
anymore.
We wouldn’t lose film of the moon landing
or a chronology of major world events or major
scientific and philosophical concepts, barring
earth-shattering doomsdays, unless we decided
they were not important anymore.
Now the obvious rebuttal is that the whole
notion is based on us deciding it wasn’t
important, but that reasoning puts the cart
before the horse.
If we have some events or reasoning that leads
us to believe something is incredibly dangerous,
we won’t forget that unless we decide the
reasoning was flawed and it doesn’t need
preserving.
But losing track of the idea or event is contingent
on first assuming we don’t care anymore.
Step 1, bad thing happens, Step 2, figure
out not to do it again and record why, Step
3 Forgot why it matters, Step 4, stop recording
why it matters so we forget.
That doesn’t actually work, and waving it
around as a simple result of long periods
of time only makes sense if we’re assuming
the record decays and gets badly re-recorded.
That doesn’t really fit into digital medium
and ways we have for maintaining accurate
and backed up material.
We’re not going to lose something that important
anymore than we’d lose a concept like Newton’s
Laws or arithmetic, you can lose those but
not simply as a result of lots of time passing.
What is the plausible scenario for a civilization
deciding that it doesn’t need to keep around
a few megabytes of summary material for why
Artificial Intelligence is bad to develop?
Such being the case, technological stagnation
that results from fear of further development
would probably work just fine even over many
thousands of years, or at least so long as
the reasoning for the bans was actually reasonable.
We can make jokes about humanity’s reckless
nature especially where curiosity is concerned
but that’s all they really are, jokes, by
and large people do not engage in overtly
suicidal behavior for the sake of curiosity
and will not be driven to push a button on
a box that says “Warning, this box contains
explosives, do not push the button”, especially
if they can actually inspect it and see that
yes, indeed, those are explosives and the
button is a trigger.
So “Warning, this technology if developed
will almost certainly end civilization”
is probably an enforceable ban assuming someone
bothered to include the full documentation
and reasoning for that conclusion and that
the reasoning is actually sound.
I’d hardly call this a guarantee but again
if the reasoning is very sound, it should
be just as compelling tomorrow as today, and
still be as compelling a million years from
now, and if that’s compelling it’s not
likely, everyone is going to decide at some
point it isn’t worth copying that warning
and double-checking each copy is accurate,
and maintain plenty of redundant backups to
compare against for transcription errors.
It takes a special kind of stupid for an advanced
civilization to fail to do so, considering
how little resources are required to maintain
that warning.
So this type of technological stagnation at
least seems plausible.
Civilizations decide a certain level of technology
is as much as they can safely have and stop,
and they document their reasoning to insure
future generations observe their ban on this
specific tech.
I have a harder time seeing it happen where
folks were simply deciding anymore tech was
unhealthy.
We might indeed see lots of folks, individually
or as groups, saying “This is good enough,
life is good enough, more technology might
make us fall apart”.
However you pretty much need to be willing
and able to exterminate anyone who disagrees
to make that stick for the civilization-at-large
and that’s usually rather tricky where advancements
to technology are concerned since those with
more technology than you will usually have
a lot more money and military hardware too.
So the threat has to be to your personal survival
and in a way that most folks believe.
It is one thing to say advanced virtual reality
is unhealthy, most folks would find that plausible,
it’s another to say that simply having the
technology and anyone using it will end the
world and must be militantly suppressed.
Absent that, folks might abandon it personally
but wouldn’t be likely to demand an eternal
ban on it and all associated technologies,
let alone all new technology.
I don’t think a tendency to hedonism that
would be the presumed threat of virtual reality
would generate the militant response, simply
because that would tend to be self-correcting
if it was a true threat.
Those prone to getting lost in virtual utopias
to the point of being utterly detached from
society either need a way to support themselves
or they’ll die, and after it’s been going
on for a while there’d still be plenty of
folks who had never used it who could point
to those who had and tell their kids “Yes,
this is what happens when you abuse this”,
and the more incidents and more generations
of it, the more compelling that warning would
be if it was actually valid.
Alternatively, if it wasn’t hyper-addictive
and prone to rendering people into lazy slugs
or if it was but someone found a remedy, then
there’s no problem and no resulting stagnation.
One also has to remember that the whole notion
there revolves around wanting to escape to
a better life, so would only ever apply to
those looking for that, and only to the parts
they wanted to escape.
An obsessive scientist or inventor probably
doesn’t lose that urge, since it’s an
obsession, and obviously not one satisfied
by having virtual and fictitious scientific
achievements or inventions.
We already discussed the case for technology
stagnating simply from more effort for each
new step and less apparent desire for it.
What about if we did just hit a true wall
though?
No new science?
That’s a hard one because it’s also a
very probable one.
Again, even though we’re all pretty wired
to scoff at the very notion of discovering
everything, there probably really is a finite
amount of science governing how this Universe
works.
And knowing of phenomena and why they happen
doesn’t necessarily mean you can produce
awesome new technology from it simply by throwing
effort that way.
It might be that technologies like compact
artificial fusion or faster than light travel
are genuinely impossible, indeed I for one
firmly believe the latter is indeed impossible
along with travel in time or to other dimensions
or realities or anything that would violate
the second law of thermodynamics.
I do tend to think that wall is a long way
off and further than what we’d need for
a post-scarcity society or reasonably practical
interstellar travel and colonization, but
we can’t rule out that even starting tomorrow
not a single new breakthrough would ever be
made.
I don’t believe that any more than any of
you do, but that’s arguably more a matter
of faith than based on sound reasoning.
The sun rose yesterday and every day before
and we believe it will every day in the future
too, but of course we know neither is true,
there was a time when the Sun didn’t exist
and will be a time again the future when it
does not.
There was a time when we had no inkling how
the Universe works and had no technology,
there will probably be a time when we do know
how the Universe works and there’s no new
technology to discover, and that might be
tomorrow or a trillion years from now, but
I’d tend to bet it would be in this millennium,
either a full brick wall or the one where
effective progress slows to a crawl because
we’re just left with a few minor but stubborn
things to work out and after generations of
little to no new progress folks just stop
investing the time to become experts on the
matter.
Indeed, even those with effective immortality
who already had the expertise probably can
only pound away on a problem so long without
making some progress before deciding to call
it quits.
Such being the case, what would that civilization
look like?
Well of course it would depend a lot on where
the tech-freeze happened but if it’s after
we have enough tech to keep our civilization
running robustly and sustainably, especially
if that also meant we could do so on other
planets too, and around alien suns, probably
not too bad.
It might be rather depressing for some, initially
anyway, to cope with an end to new science
and technology but there’d still be other
frontiers to explore and the sum of human
knowledge is not just science and technology.
There’s often a worry that technological
stagnation could only ever be temporary because
we’d collapse after a few generations from
the despair of realizing there were no new
scientific frontiers to conquer.
That the stagnation would end by falling backwards
and entering into eternal cycles of learning
all there was to know, then losing it and
re-learning it.
However, while it’s very integral to modern
civilization, most of human history was not
a time where folks really thought much on
new tech nor despaired of running out of new
things to learn or invent, so some of the
more terrifying scenarios for civilization
collapsing under despair seem implausible.
Society arguably would collapse, since it’s
a very different civilization than what we
have now where our civilization is so entwined
with technological progress, but probably
only in the slow cultural change type of collapse
which is always ongoing.
Those ancient civilizations often were fairly
stagnant in technology, but they were never
stagnant in culture, which is always shifting.
So it’s a good thing to remember, that even
if one day our technology stagnates, it doesn’t
mean we have stagnated.
We mentioned today that Technological Stagnation
might come from either security fears or alternatively
privacy concerns that arose either from new
technology or from the monitoring needed to
protect folks from such technologies.
Of course we already have a lot of privacy
and security concerns and that’s only amplified
at the moment as so many folks are adjusting
to doing a lot more online work and shopping.
When you’re working remotely, be it from
home or some public wifi space, you have some
extra data vulnerabilities and it’s very
handy to add an extra layer of protection
in by using a virtual private network, or
VPN, and that’s where ExpressVPN can help.
You’re often transmitting everything you
do unencrypted or where whoever controls that
public wifi can access it, so it’s important
to use something that creates a secure tunnel
for your device and information.
It’s like putting your data in an envelope,
like a letter, so those handling it can’t
see inside, only they can’t just rip it
open and see the content.
ExpressVPN offers you that option, as well
as letting you change your location so you
can watch those pesky videos that sometimes
aren’t visible from your country of origin
or other geographic limitations, and avoids
letting your ISP see what you’re doing and
sell your data to ad companies.
It’s an extra layer of privacy and security
and one I personally take advantage of all
the time, and ExpressVPN offers the fastest
speeds by using only premium servers, and
is very easy to use but has 24/7 Live Chat
customer support to ensure if you do need
a hand, you can get it anywhere and anytime.
ExpressVPN is the #1 rated VPN by TechRadar,
CNET, the Verge and many more, and you can
find out how to get 3 months free by clicking
in the link in the episode description box
below, ExpressVPN.com/isaacarthur
Next week we’ll be taking a look at alien
life to contemplate the notion of life that
isn’t based on organic carbon-based chemistry,
and we’ll see what sort of strange life
might be possible and what sort of strange
places it might emerge.
The week after that we’ll be exploring how
economies of the future might look.
If you want alerts when those and other episodes
come out, make sure to subscribe to the channel,
and if you’d like to help support future
episodes, you can visit our website, IsaacArthur.net,
to donate to the channel, check out our catalog
of episodes or book recommendations, or buy
some awesome SFIA merchandise.
Until next time, thanks for watching,
and have a great week!
