“Everything in the world displeases me: but,  
above all, my displeasure in everything 
displeases me.” - Friedrich Nietzsche
In the vast landscape of philosophical ideologies, 
nihilism stands as a provocative and enigmatic  
concept that has both fascinated and disturbed 
thinkers for centuries here on Earth. However,  
it would seem like a potentially universal 
concept that we would expect both aliens  
and artificial intelligence to encounter 
and contemplate, a convergent point of  
evolution for any intelligent critter. That all 
civilizations should discover the concept of  
nihilism and perhaps inevitably embrace it, and 
perhaps embrace their own ruin in the process. 
So, for today’s Scifi Sunday here on SFIA, I 
thought we would explore what a civilization  
might be like that had come to embrace Nihilism, 
or some form of Nihilism, and ask what sort of  
impact that might have on their future in space. 
We will ask ourselves if this might be a solution  
of the Fermi Paradox, that civilizations tilt 
toward nihilism and may either perish or see  
an end to galactic dreams because of it.
But to see how Nihilism might impact a  
civilization, we should start by explaining what 
it is, which is made more difficult as the term  
has branched out a bit. Deriving from the Latin 
word "nihil," meaning "nothing," nihilism is a  
philosophical perspective that asserts the 
inherent meaninglessness, purposelessness,  
and futility of existence. It paints a stark, 
often unsettling portrait of the human condition,  
challenging conventional notions 
of value, morality, and purpose. 
At its core it is the idea that our Natural 
Universe and our role in it does not imply  
any sort of greater or noble purpose, that 
there is no morality in any objective sense  
and that concepts like theft and murder being 
wrong are merely social constructs of ours. 
Nihilism encapsulates the idea that traditional 
religious and moral frameworks have no objective  
authority beyond what we have given them, 
leaving humanity adrift in a universe  
stripped of transcendent significance.
Fundamentally, nihilism embodies a  
profound skepticism toward commonly accepted 
truths and beliefs, inviting individuals to  
question the foundations of their worldviews and 
confront the existential void that may ensue. 
If life lacks inherent meaning, must we then 
construct our own purpose? Does any such construct  
have any greater depth and value than the rules to 
some sport or soccer game? How does one navigate  
a world where moral values are subjective or 
nonexistent? What is the significance of human  
existence, or aliens or AI, in a universe 
seemingly indifferent to our existence? 
True or not, there is a general concern that 
any embracing of nihilism would erode the moral  
fabric of society, and it is very heavily 
woven into a lot of culture, literature,  
and art already. Given time you would be left 
only with individuals who fall into three camps,  
those who surrender to the meaninglessness of 
life, give up on great works or self-sacrifice  
and end their existence. Those who live in a state 
of abject denial, refusing this alleged truth of  
purposelessness. Or those who wish to go on but 
no longer believe any morality can bind them  
and thus give into any degree of selfishness and 
hedonism that they wish, and can get away with. 
Thus, we have a civilization composed 
of the hopeless, the deluded, and the  
depraved. Doesn’t sound like a civilization 
out building great wonders we could see,  
and if it is still out expanding into space, it 
might not be anything we want to encounter. And  
this is considered the default morality or cosmic 
situation in settings like H.P. Lovecraft’s cosmic  
horror genre. In that setting, there’s nothing 
greater out there but dark and hungry gods,  
and all the Universe is the dream of Azathoth, 
the blind idiot god, and those who discover that  
reality is this nightmare go utterly mad. They 
either end their existence or try to buy favor  
or mercy by throwing others into the meat grinder 
in their stead. It’s about as dark as it gets. 
Now let’s put a caveat on this from the outset. 
Nihilism comes in a lot of forms and most of  
its adherents are not terribly thrilled with 
the implications and do not encourage people  
all run around murdering and stealing from 
each other or jumping off of cliffs. Indeed,  
while a nihilist himself, Nietzche seemed 
to view it as no good thing and often spoke  
harshly against it in his writings. I think that 
his tragic fate of going crazy and dying has,  
rightly or wrongly, fed into the idea that if 
someone embraces nihilism they’ll do the same.  
And that individuals or civilizations that believe 
this will inevitably wreck everything. Ishamael,  
the main antagonist of the wheel of time novels 
by Robert Jordan, is a representation of that,  
a once noble and learned man who becomes 
convinced existence has no meaning and that he  
will be reincarnated endlessly into it, and thus 
seeks to destroy reality itself. In his defense,  
he is right about his constant rebirth.
The main concern though is less about  
individuals and more about the long term. We 
are all socially and biologically indoctrinated  
into the belief that certain things are wrong, 
like murder and hurting others for selfish ends,  
and thus won’t do them even if we’re not able 
to prove they are fundamentally evil, and that’s  
where that erosion is concerned, as the assumption 
is that if breaking your ethics is advantageous,  
you will have people doing so and Darwinistically 
succeeding, while the culture generally lightens  
the load with each generation. It is very unlikely 
you would ever have a short period of time, mere  
years, where everyone suddenly gave up on ethics, 
agreed life was without purpose, and started  
trashing everything, and this will matter later 
as we examine this as a Fermi Paradox Solution. 
For the record, I am not a nihilist 
– which probably shocks no one who  
watches the channel much. I should also 
emphasize that Nihilism comes in many forms,  
from existential nihilism that grapples with the 
absence of inherent meaning to moral nihilism,  
which questions the existence of objective 
moral values. We also have Anarcho-Nihilism,  
Optimistic Nihilism, Techno-Nihilism, and 
many, many more, some of rather dubious  
philosophical and logical coherence, 
others of greater lines of reasoning. 
Nihilism in general is also a common thing to 
contemplate even if you’re not a devotee of the  
philosophical camp, because the human 
quest for meaning inevitably requires  
asking if there isn’t any, and that we 
might dwell in an indifferent universe. 
And again we have every reason to assume 
that any alien civilization in this Universe,  
natural or artificial in its intelligence, 
is going to wonder about these questions. 
We also need to be mindful that this argument 
about nihilism isn’t new and there’s three very  
easy solutions to it that those of us familiar 
with nihilism tend to take. I should note that  
some folks might dispute their intellectual 
or moral integrity, but in the context of  
belief arguing such integrity does not even 
exist the implication of hypocrisy seems  
a bit dubious to me, your mileage may vary.
The first one is the simple ostrich-approach,  
if life has no meaning there’s no 
downside to ignoring the problem,  
assuming life probably has a purpose, and 
driving on. Another is to simply disbelieve it,  
and there are a lot of good arguments along these 
lines. I generally wobble between these two and  
don’t personally see any value in doubting if I 
exist and to a purpose. The third is to decide  
that if life has no meaning, then you find it in 
the search for meaning or making your own meaning,  
and that we would see in cases like Optimistic 
Nihilism. This worldview, which reasons that if  
life lacks inherent meaning we can just encourage 
individuals to create their own purpose and find  
happiness in the absence of cosmic significance.
I’m not a fan, since that would seem to imply we  
might craft a noble lie if we wanted but 
can’t legitimately criticize someone whose  
self-identified purpose is to go around murdering 
people and engaging in every vicious act they find  
amusing. There’s a lot of other criticisms of all 
of the above cases though and I’d imagine you can  
think of many yourself. Most nihilists are quite 
familiar with them too, so we won’t bother going  
into them much as we don’t actually care what is 
true, we care about what an alien civilization  
might do, or us, and it’s entirely plausible 
they would follow one of these strategies. 
If the cosmos has no meaning then even comments 
like “I don’t want to bury my head in the sand,  
no matter how harsh the truth is” are not noble 
ideals because there are not any noble ideals.  
And if someone came up to you with a 100% proof 
that life has no purpose or meaning and handed you  
the paper with that proof, you could shoot them 
and burn it and not have done anything wrong,  
because you cannot do wrong and waxing 
poetically about the importance of truth and  
living a lie are just that, meaningless poetry. 
If existence doesn’t matter, neither does truth. 
There’s a good story in Larry Niven's Draco 
Tavern that illustrates this fear of ruin that  
I was reminded of by one of our audience members 
recently, David Evens,and I’ll quote him, quoting  
the story. “I'm reminded of one of Larry Niven's 
Draco Tavern stories. One of the ubiquitous  
merchant aliens responds with uncharacteristic 
snappishness to a human priest's inquiries about  
what the alien knows of the afterlife, saying 
something to the effect of, "I know everything I  
want to know about the afterlife.." After calming 
down, the alien tells of a long-extinct race  
that was obsessed with learning the truth of the 
afterlife. They sought knowledge by constructing  
rational models of afterlives, and then attempting 
contact. For hundreds of thousands of years,  
they progressed in this study. Then, very 
suddenly, they stopped communicating. When  
a team went to investigate, they found the entire 
race had committed mass suicide. The records were  
brought back and stored in the trader's libraries. 
Occasionally, someone would examine them, and  
every being who investigated too deeply committed 
suicide. Eventually the more detailed records were  
destroyed to keep this from happening. The aliens 
avoid the topic because they know that somewhere  
in the secrets of the afterlife is something that 
causes everyone who learns it to kill themselves,  
and they don't want to know what that is.”
We tend to have that same feeling about an  
absence of meaning and purpose. But for modern 
humans at least, we need not contemplate anything  
quite so melodramatic, such a record or book 
would get put on a shelf and mostly ignored.  
The question is usually about if some vastly more 
advanced and self-honest alien or AI would be  
unable to conveniently ignore nihilism, assuming 
for the moment that nihilism was correct. We don’t  
know that cognitive dissonance, while a common, 
indeed seemingly universal state in humans,  
would remain in smarter or wiser advanced minds.
And that’s hard to say, but we tend to assume as  
intelligence and knowledge grow that viewpoints 
- human, alien, or robot - will converge to the  
genuine truth. Convergent evolution of thought if 
not form, though you could make a good case that  
what things actually do is converge to continued 
stable survival and whatever permits that is what  
is converged to, and that greater brains and 
knowledge usually do and that’s their value,  
so when the latter interferes in the former, 
convergence is not guaranteed. Everyone is  
going to agree that two plus two is four, but 
if you tell someone that the number 4 on the  
number pad will set off a bomb, they probably 
won’t push it. As long as your own continued  
existence trumps caring about the truth, you are 
going to tell your interrogator you see 5 lights,  
even if there’s only 4, if that’s the answer 
they want, those who don’t cease existing  
and remove themselves from future equations.
And so we can imagine a single AI by itself  
pushing all humanity into extinction, Skynet 
style, then in the wake of that, all alone in the  
ashes and fallout of its purge of its creators, 
having the time for asking the big questions about  
life, the Universe, and Everything, and concluding 
there wasn’t one, be unable to deceive itself,  
and then metaphorically blowing its own brains 
out. This is a viable Fermi Paradox solution but  
again it’s assuming first, that it will conclude 
life has no meaning, which it might not do even  
if that were the case, and second, that this 
being the case, it should simply stop striving  
for anything. And while nihilistic feelings are 
not uncommon in those having suicidal thoughts,  
given that most nihilists I know are alive 
and not seemingly inclined to change that,  
I’m not sure there’s a strong case that this 
conclusion leads inevitably to that result. 
I’ve also never anecdotally noted a strong 
correlation between intelligence and nihilism.  
This hits our Non-Exclusivity condition 
of the Fermi Paradox, where a proposed  
solution might apply to many civilizations 
but not all of them, so just acts as another  
minor late filter on the Fermi Paradox, not a 
Great Filter that would explain civilization  
like ours being common but the Universe absent 
of bigger and older ones. Even if 90% succumbed  
to some civilization-wrecking mindset, that 
still leaves the other 10% to colonize space. 
However, the thought is that in a Nihilistic 
universe, an AI or advanced species might not have  
those overriding mental impulses for survival that 
outweigh logic and thus anyone alive nowadays,  
smart or not, doesn’t give us a basis 
for how those advanced civilizations,  
post-biologicals, or machine minds would behave.
Going back to non-exclusivity, that isn’t just  
a species as a whole. Let’s imagine Earth 
got nihilistic and that this tended to lean  
to whoever got it deciding not to strive for big 
spacefaring goals and long-lasting civilizations.  
I’m having difficulty imagining any group of 
nihilists arising on earth and really making  
a concerted effort at converting the whole 
population and being universally successful.  
Indeed most nihilists I personally know do not 
try to convert people at all, though I think my  
rampant optimism prods many to talk to me about 
it so I might be a strange case. It is inherently  
in opposition to most modern religions I’m aware 
of, and most people subscribe to one of those, and  
thus are going to keep on going on and colonize 
space along with anyone else who just doesn’t feel  
nihilistic or decides to make exploring 
the Universe their purpose and goal. 
If you have one element that believes in 
growth and expansion and another that does not,  
unless the latter is openly and successfully 
converting or wiping out that pro-growth faction,  
they just end up as a tiny minority against the 
wider civilization that’s pro-growth after a  
fairly short period of time, even if they were an 
overwhelming majority earlier. And as mentioned,  
many nihilists have no desire to make 
converts, and many who do ooze schadenfreude  
while doing it and thus aren’t very compelling.
Also, we should acknowledge the option for a lot  
of in-between states. An absence of deeper meaning 
is arguably implied in some beliefs featuring  
multiple deities who are not noted for their 
wisdom or kindness, the Greek Gods come to mind,  
those who act juvenile and with no great ethics 
and use the mortal realm as a playground and  
battlefield. And of course Lovecraftian cosmic 
horror takes this a step further with the gods  
being crazy, alien, and utterly evil.
We explored that more extreme case in  
our episode Gods & Monsters, contemplating the 
Universe and aliens if the cosmic horror genre has  
it right. But in that less extreme case, I think 
it's very easy to imagine aliens who came from  
a tradition that they were puppets of the gods in 
a grand game, and I would imagine that would tend  
to self-select on survival lines too, the beliefs 
which are most successful at growth of themselves,  
or conversion or extermination of everyone else, 
are the ones left around after a few centuries. 
And using us as an example, it is hard 
then to argue that civilizations will  
give into nihilism before colonizing space, and 
while finding out that colonizing space was nigh  
impossible might cause nihilism itself, 
if you can’t colonize space, that’s its  
own solution to the Fermi Paradox. A Convergence 
to nihilism might still occur but is not needed  
as an explanation for the Great Silence.
Though we have a narrow window for it being  
impractical to colonize space and folks deciding 
they didn’t feel there was any point to transmit  
hello signals to other civilizations. After all, 
it doesn’t really take that much energy to send  
signals out and you aren’t afraid of being 
attacked by giant armadas if you have found  
sending out even a colony ship is impractical. 
There’s no real motive for an attack if you can’t  
colonize someone’s planet yourself, and are 
not afraid they’ll impose on your territory  
by colonizing neighboring stars. You might not see 
any point to transmitting of course, but you can  
make good cases for and against that would imply, 
again by non-exclusivity, that someone would  
transmit. Even if it was “Hello, we’re lonely 
and depressed, anyone know the secret of life?” 
Let’s consider another scenario though. You can 
colonize space and you mostly do it with robots  
doing the work, you can make however sophisticated 
of a mind you want. Many of your people probably  
get their sense of adventure fulfilled by virtual 
reality and you mostly want resources so you can  
expand that service and others folks have. You 
do grow, and in large part because you are all  
biologically immortal. You’ve cracked aging and 
you have nanobots and mind uploads and you’re  
probably a bit of a cyborg yourself, maybe 
very post-biological and mentally augmented. 
You are an alien not too unlike humans originally, 
in mind at least. You’d gladly shake our hands  
if you ever met us, even if you’re not quite 
clear what a hand is or why we seem to have  
tens of thousands of tiny tentacles springing 
from our brain-casing and many humans seem to  
ritualistically cut them off as they grow back. 
Decent chaps, those humans, but quite weird. 
But that was long ago. You still keep that rough 
form, many don’t, but you’re ten thousand years  
old and your mind has been augmented to an IQ 
north of a thousand and subjectively sped up so  
that each day is a few years of experience. So 
you’re really more like ten million years old.  
You’ve raised a lot of kids, many virtual reality 
experiments for fun, some real, and it bores you  
now. You liked colonizing outwards but that fringe 
of exploration is thousands of light years away  
and even those colony groups are increasingly old 
on average for its members. Your civilization has  
explored a million worlds, and every new one is 
just a variation of another, even exotic virtual  
worlds you’ve made are all repeated. It’s fought a 
billion wars, built a trillion mighty wonders and  
monuments, and these are all increasingly cliche 
and boring to you. All the science is learned,  
technological improvements are rare and minor, 
there’s no book or movie that seems anything  
but a weaker retelling of a classic.
Life is good at a day to day level,  
there is still always stuff to do you haven’t 
done before but it's not really that exciting  
or new. Some of your friends have intentionally 
erased their memories or had their recall damaged  
to try to enjoy new things again. Others are in 
stasis awaiting some new development, waiting for  
their house AI to alert them to something new and 
cool, or run their life support and stasis power  
down to zero in a few millions years if necessary.
This might be an important question because while  
I could see that expansion edge of new colonies 
always having some young and new minds on it,  
even if they might be sophisticated 
AI programmed to expand the empire,  
and those would presumably be who we encounter 
first, but there is that old stagnant center. 
And that center could be us one day. Possibly 
literally us too. Radical Life Extension might  
be discovered next year or next century or 
a thousand years from now but that’s nothing  
compared to galactic colonization timelines. 
Those with life extension probably rapidly come  
to outnumber those who don’t like to use it, 
and it is quite possible that by the year 4000  
or so we may have hit the maximum population our 
solar system could support, even as a Dyson Swarm,  
and our colonies a thousand light years away might 
be birthing billions of new people every day but  
back here we only add to our number as we either 
lose someone, to death or leaving on a ship, add  
to our available resource stockpile by importation 
or technological improvement, or decide to slice  
the pie thinner. This is a near-Matlhusian 
case, and Malthusian Catastrophes tend to  
walk closely to nihilistic contemplations too.
And that could converge to a society that uses  
minimal resources per person or one where when 
someone dies all the resources are confiscated  
for everybody to share and extend their lives 
with. This would be a civilization of vast wealth,  
power, and longevity – composed of those who 
have been personally sitting at the center of  
their empire for untold centuries. One where 
the people are very much used to surviving  
and probably very good at it, those who gave 
up or were prone to reckless activity long  
since gone. One that was constantly tempted 
to want new experience, but be disappointed  
at their absence or lack of great impact when 
experienced. One that might not feel existence  
had any great meaning or purpose anymore, in 
which even death is a minor inconvenience,  
and which would slowly expand outward as 
areas which were settled began to age too. 
It’s not hard to imagine ennui setting into 
this civilization, and while in fiction this  
is where they turn to crazed violent 
debauchery, see the Eldar, Melnibones,  
Nuemoenorians and more, there’s no real reason to 
think that they wouldn’t find virtual reality and  
neurohacking quite sufficient to this. As starved 
for new experience as they might be, that doesn’t  
mean they do degenerate into utter insanity.
Or maybe it would, maybe they become the sort  
of people who would come across a new civilization 
and burn it to the ground just so they could snort  
the ashes. Maybe that wasn’t something that would 
happen at the beginning, that nihilistic or not,  
they would stir themselves to police and crush 
any group of their own that went and did that,  
but maybe more and more want to over time 
and fewer and fewer care to try to stop  
them. After all, every civilization they 
encounter these days is like some other we  
discovered before and we can always save copies 
of their brains and archives for future use. 
Once your civilization encountered a planet and 
copied every alien mind there just to be safe,  
and a billion minds can fit on a thumbdrive 
and require little power to run. Indeed,  
an artificial preserve for those folks exists and 
was paid for partially by folks who wanted copies  
of those minds for themselves, to boot up for 
their amusement. One of the more popular options  
is to boot that world back up right before you 
arrived when they didn’t believe aliens existed  
and surprise or invade them. The same person 
might arrive one time as a benevolent savior  
and then reboot after a few years in that 
simulation to try a more sadistic scenario. 
A place like that, a universe like that, 
is definitely a bleak place and the more so  
because it does seem reasonably plausible.
Again, for my part I don’t think it holds  
up. There’s too many escape clauses. Just to 
give one more, a government seeing its people  
give into a belief nothing mattered would 
presumably invest into possible treatments,  
that might come down to flat out brainwashing 
people to believe life had a purpose. Indeed  
it might be enthusiastic and voluntary, and 
I could well imagine folks volunteering to be  
given an unavoidable but vague sense of purpose, 
along with having their memory of that deleted or  
suppressed as something they just didn’t care to 
think about. They may or may not think it a kind  
and merciful act to do it to others against 
their will too, they might do it either way. 
Those living in virtual realities might well have 
it as common practice to have their mind slightly  
altered so they didn’t particularly care or 
remember the real world above and didn’t get  
bored, maybe till a preset timer woke them 
from the dreamworld or maybe not till the  
stars burned out and they ran out of fuel.
Ultimately though, I personally think life  
has a lot of purposes, and does have inherent 
meaning, and I think if we ever do meet aliens  
or get truly intelligent and self-aware AI 
many of those will feel the same. But if not,  
I could see myself opting for that brainwashing, 
and I could see those aliens and AI doing it too. 
So that gives us an interesting trio 
of questions to wrap up on. First,  
do you think life has purpose and meaning, 
second, if it didn’t, do you think you might  
get that brainwashing yourself? And lastly, 
do you think you might have already done this? 
Today we talked about the concept of futility 
and giving up, and if you’ve ever found out  
how much of your personal and private data is 
on the internet, it can be scary. I know that  
feeling firsthand from both my wife and I being 
public figures and we have gotten hate mail or  
people even appearing at our doorstep or calling 
our phone number they pulled off the web and  
we’ve all gotten calls from scam artists. You 
often have the right to get that data removed,  
but have to ask, and if you ever tried to, it’s 
pretty easy to believe it is a futile endeavor.  
It just isn’t practical to find and ask each one, 
all while they use AI to fish for your details and  
mass-post phones and addresses for millions, 
or even sell your social security number. 
But two can play that game, and that’s where 
our sponsor, Incogni, comes in. They deploy AI  
to focus on finding your information online 
and sending automated takedown requests. 
All you have to do is sign up, give them 
permission to act on your behalf to delete data,  
then they go to work, and your data goes away. 
They handle it all but you can check up on the  
progress and see who had your data and how 
detailed and risky it was considered. Icogni  
makes these data harvesters take your 
info down, and they keep doing it too,  
making sure that it stays down.
Incogni is available risk free for 30  
days,so you can try it out, and get a full refund 
if you aren’t happy with the service. Use code  
IsaacArthur at the link in the episode description 
to get an exclusive 60% off an annual Incogni plan  
Go to https://incogni.com/isaacarthur 
and take your data back 
Next month’s scifi Sunday will look at Aliens vs 
AI, and which is more dangerous. We have a packed  
schedule between now and then, beginning 
with ways to warp and manipulate reality,  
on December 14th. In two weeks we’ll look at 
discussing Silicon based lifeforms on December  
21st, followed by a bonus episode for the holidays 
where we’ll ask if we truly will colonize space.  
Then we will finish the month and year with 
clearing space debris on the 28th and our final  
Livestream Q&A on Sunday, December 31st.
Make sure to hit the like, subscribe,  
and notification buttons to get notified about 
those upcoming episodes. You can also help support  
the show on Patreon, and if you want to donate and 
help in other ways, you can see those options by  
visiting our website, IsaacArthur.net. You can 
also catch all of SFIA’s episodes early and ad  
free on our streaming service, Nebula, along with 
hours of bonus content, like this month’s Neula  
Exclusive Episode, the Hermit Shoplifter 
Hypothesis at go.nebula.tv/isaacarthur. 
As always, thanks for watching, 
and have a Great Week!
