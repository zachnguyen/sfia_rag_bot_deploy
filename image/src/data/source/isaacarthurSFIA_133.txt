Challenge and adversity can lead to greatness,
and help forge better people,
 but is the reverse also true?
Could a better future make less of us and
our descendants?
To this day there’s still a lot of mysteries
about how evolution works, especially how
it applies to intelligent life, which can
be aware of the process and actively intervene
in it.
We know adversity can foster strength, that
often evolution is fueled by a competitive
cycle between predator and prey.
Yet, can we extrapolate from this to say that
in a paradise, we run the risk of becoming
subhuman without as many of those tests and
efforts?
It’s a tricky topic, not to mention a touchy
one, and one popular in science fiction.
Indeed the idea even predates literary classics
like H.G. Wells' The Time Machine or even
Darwin publishing his Theory of Evolution,
a term he apparently disliked.
We’ll be looking at several hypothetical
cases today, such as the Morlocks from The
Time Machine and the C.H.U.D.s from that film,
and seeing if this might be something that
could happen here on Earth or one of our future
space colonies.
We’ll ask how it could happen and what it
might look like.
Whether it might be a natural occurrence or
even something engineered, like some evil
galactic empire needing whole planets to feed
its capital world, and populating its farming
planets or Agri-worlds with those bred or
engineered for servility or simple-mindedness.
Now to begin, the modern notion of evolution
is not exactly compatible with the idea of
Devolution.
Evolution isn’t supposed to have goals so
there’s no ladder or hill we’re climbing,
there’s no up so there can't be a down.
But the word itself is associated with progress
and Darwin himself only used the word once
in his book specifically because the term
had come to imply biological progress and
he objected to that, preferring the term “descent
with modification”.
Given that descent means to go lower this
would probably have been just as bad a term
to use, since it would imply the reverse of
progress, but of course Darwin meant descent
in the sense of descending down a family tree.
Nonetheless humanity has often viewed descent
in this sense as also meaning growing weaker.
The idea of humanity growing more corrupted
and inferior over time is common not just
in many religions but is a common attitude
even among generations comparing themselves
to their disappointing children or heroic
forefathers.
That they’re softer or weaker or less ethical
or hardworking.
That civilizations having golden ages then
inevitably rot and decay.
This sort of degeneracy, in human perspective,
usually comes under 3 general cases.
The First is that we are inherently degenerating
– such as implied in biblical lifespans
decreasing from Adam in the Garden of Eden
to Noah’s era and beyond.
Sometimes this is specific to humans, sometimes
nature at large, that the whole Universe is
running down, perhaps cyclically, running
down from a more metaphysical and spiritual
decay of which entropy is but one manifestation.
The Second case is that something triggered
that decay, an event or location, like with
C.H.U.D.s.
This is definitely a case of triggered of
degeneracy, originating from the 1984 film
of the same name, the C.H.U.D., or Cannibalistic
Humanoid Underground Dwellers, are once-human
monsters dwelling in the sewers under New
York City that were mutated by exposure to
radioactive and toxic waste.
This may or may not be hereditary too but
can happen to a healthy individual, turning
them into a freak and monster.
The reason for this change is that the city
had secretly been disposing of its toxic waste
in abandoned subway tunnels under Manhattan
marked as Contamination Hazard Urban Disposal,
or also C.H.U.D., CHUD.
The mutants of those tunnels lurk under the
streets and feed on homeless people.
The C.H.U.D.
film is forgettable enough, and its 1989 sequel
Bud the Chud more so, but the idea got some
cult status and gets referenced in the Simpsons,
where I first heard it, Rick and Morty, Archer,
Futurama, Agents of S.H.I.E.L.D. and many
more.
The concept is common in stories beyond this
one too, those individually corrupted or polluted,
and a fairly common origin of monsters in
our stories, rather than slowly degenerating
over a longer time period of many generations.
It’s a common theme in Lovecraft-inspired
works of cosmic horror.
The film also features an attempt to exterminate
the mutants no matter the cost, and erase
any witnesses of them, by opening up the gas
lines and asphyxiating them.
And that’s a common thread in a lot of fiction
too, someone so driven to wipe out the corrupted
mistake that they themselves become a villain.
The classic novel, I am Legend, which featured
mutant vampires who replaced humanity, but
ironically spawned the Zombie Apocalypse genre,
has been made into a film several times now,
and not one of those adaptations has the book’s
ending, where our protagonist has become the
nightmare monster to this new emerging civilization
of vampires he has hunted for years, who have
now hunted him down, and closes the books
by having him utter the titular line, “I
am legend”, as he also realizes that these
mutant descendants of humanity are no longer
just degenerate crazed mutants, zombie-like,
but now a civilization if a primitive and
violent one, and in his zeal he couldn’t
see the transition.
The Inquisition of Warhammer 40,000 often
takes this approach by burning out whole planets
that have been infected with corruption, called
Exterminatus.
Though in that setting’s case, this is genuine
crazy-evil corruption.
There, and in many other tales, just engaging
in an activity, like cannibalism, is seen
to devolve one, and tilt you toward other
crazed or degenerate acts, from which there
is no recovery once begun.
Note that word, degenerate.
We might see this with some crazed Cthulhu-cult
infecting an area, or some other local cause,
though it could also be something non-obvious
like a beautiful paradise or golden age of
civilization being the actual cause of the
degeneration.
This case can also overlap with our first
case.
Maybe you listened to that snake and ate that
apple, you wrecked that ozone layer, you paved
everything over and replaced every forest
with landfills and toxic waste dumps.
So case one is inherent degeneracy, of people
or the universe in general, while case two
has corruption being caused by something more
local or infectious.
Our third case though is that intelligence
itself is not lost to corruption or degeneracy,
but rather is a negative trait in a technological
society, or viewed as such, and we breed it
out.
And that one usually points to ideas like
ignorance being bliss, which data and science
say is not true, incidentally.
Or that intelligence of parents is inversely
linked to how many kids they have, which is
more debatable.
And while we are confident IQ is based on
both nature and nurture at this point, how
much of each and in what ways remains a big
question, making any definitive answer impossible
for now.
All three of these options - inherent degeneracy,
triggered, or slowly bred for in certain conditions
- tend to invite a lot of non-scientific discussion
in, and often fairly mean-spirited or openly
bigoted commentary slides in, of one flavor
or another.
Devolution as a term is basically implying
dehumanization too, so let’s be careful
in our contemplation of it.
I should also note that while the mainstream
view of Biological Evolution is that it has
no goals and makes no progress, I think we
can contemplate Devolution anyway just so
long as we keep that in mind, that something
growing less intelligent or more impulsive
is backward in our eyes but not meaningful
in Darwinian Evolution specifically, same
as being kind or just isn’t, and yet both
are desirable to us, and valuable to us.
And to be fair, not every theory of evolution
takes this perspective either.
Orthogenesis and some other models that permit
evolution to have a direction or flow can
contemplate something going backwards, but
in the modern scientific theory, it should
be a rare coincidence.
Some trait evolves, it helps the species thrive
and catches on, but many of that critters'
descendants are born without it anyway, the
occasional mutant, and when circumstances
render that trait less useful, those mutants
without it now thrive.
Circumstances do change.
As best we can tell, the whale evolved into
the ocean, back onto land, and back into the
ocean.
That’s not a step backwards anymore than
putting on a winter coat then taking it off
for the summer is.
It would seem strange then that intelligence,
the one trait that seems most universally
useful, could ever be on that chopping block.
I don’t think I need to elaborate much on
how intelligence is useful, but as we’ve
discussed with things like AI, sometimes general
intelligence can be a hindrance for survival,
slowing reaction times, and is where subconscious
reflexes are vital, even though they often
make you pursue imperfect strategies.
Too much curiosity can also potentially doom
a species, the Pandora’s Box fear is one
we in a technological era know all too well
and know is a true danger, possibly an extinction-level
threat, though it is still hard to see how
that would make less brains a better trait.
Of course what we mean by brains is a little
tricky to define, and may not be the same
as IQ.
The idea is problematic for many reasons we’ll
discuss today.
But let’s consider the Idiocracy case next.
This is from the 2006 sci-fi comedy film by
Mike Judge where our protagonist pulls a Buck
Rogers, or Philip J. Fry, and awakens from
hibernation centuries later in a dystopian
future populated by a satirical stupid humanity
turned gluttonous and dumb.
He is determined to have the highest IQ and
is made the Secretary of the Interior, and
discovers that they have major agricultural
and ecological issues because they’ve been
watering their planets with a sports drink
instead of water.
The film ends by having him become president,
marrying and having 3 smart kids, and noting
that his vice-president married 8 women and
fathered 32 stupid kids.
It is satire and we won’t waste time over-analyzing
it but the two key concepts in there are that
a technological society can get away with
a lot of dumb and wasteful people or activities
because of its sheer technological might,
they don’t live on the margins of survival,
and that smart people have less kids than
dumb people.
I’ve joked about the former in our post-scarcity
episodes many times, that one neat thing about
post-scarcity tech is it lets you settle a
vast galaxy of countless worlds while also
allowing virtually any system of culture or
government to successfully operate in relative
isolation, simply because the reduced pressure
of neighbors and vast resources gives you
an environment in which you have a lot of
room not to run your show optimally and make
mistakes, and from which people, or entire
mobile space habitats, can easily migrate
if they dislike it, and probably more easily
than rebelling.
As a result, we might see some truly incompetent
and crazy civilizations manage to endure for
surprising periods out among the galaxy, though
hopefully as a small minority of cases.
As to smarter people having fewer kids, I
hesitate to call that a myth but it is certainly
exaggerated.
Currently humans have a relatively short fertile
period during which they can have kids and
the sooner you start, all things being equal,
the more kids you have.
But it’s often seen as beneficial to wait
to start, and so as a statistical process
we tend to see folks having kids earlier who
weren’t as good at controlling impulsive
behavior.
Unsurprisingly there is a pretty decent correlation
between delayed self-gratification and IQ,
and both with overall life success, as judged
by most common metrics.
I’d imagine there are many other variables
involved there and some may be cultural rather
than cross cultural over space and time.
For instance, in the past when folks worked
their farms and mostly with their descendants
as labor, many of whom died before maturing,
you could argue that starting families early,
even though they initially drained your meager
resources and energy, was more like compound
interest in a savings account, best started
early and aggressively.
So too, a civilization that is post-scarcity
may not have this delayed start advantage
we currently have either, or may have technology
that easily extends both lifespan and fertile
period, which derails the issue too.
For my part I would guess that’s most of
the cause there though, that currently it’s
generally advantageous to wait on having kids
to educate and establish oneself, so those
statistically more likely to pull that off
have fewer kids by starting later, on average.
There are tons of people who are very smart
or self-controlled but started family’s
young, and vice-versa, but it’s a statistical
effect.
And a parent with an IQ of 145 who started
having kids at age 20 while their twin had
them at age 30, has probably matured to greater
self-control and education by then, but both
still have the same DNA to pass on.
Beyond that, this tends to be a sensitive
and contentious topic, and one where science
still has a lot of work to do investigating
the matter, so we’ll leave it there with
the assumption that nothing inherent about
intelligence makes you have less kids, but
that certain circumstances in your environment
might make it intelligent to pursue that path.
And also that the genetic aspect of intelligence
is made of various discrete heritable traits
you either did or did not get, you don’t
get 99% of a trait and your kid 98%, so that
cousins by parents who were twins, one who
was smarter than the other by nurture and
education, probably have the same genetics
for inheritance anyway.
Which is probably important to establish since
if it were true, that IQ was a strong factor
in how many kids we had, and that each generation
had a slightly lower IQ than the one before
it, when did it become so?
And in what prior era of a presumably stupider
or simpler humanity did intelligent people
have more kids than other people of lower
IQ?
And while science speaks very unclearly on
how intelligence and fertility rate match
up cross-culturally, it is very clear on how
intelligence and happiness link.
While everyone knows ignorance is bliss and
intelligence doesn’t lead to happiness,
science firmly establishes that the opposite
is true, that people self-reporting their
happiness level ranked by intelligence are
overwhelmingly happier when smarter and less
happy when less intelligent.
Many things can cause unhappiness of course,
and a smart young person might be depressed
about problems they see and others don’t,
or feel they have potential that is unrealized
and respect not yet given to them that they
believe they merit.
This would tend to indicate that civilizations
do not tend to avoid intelligence for the
sake of happiness, though that merely implies
people aren’t voluntarily and actively trading
intelligence for happiness, or at least aren’t
succeeding with this exchange.
In Dennis E. Taylor’s novel Heaven’s River,
which I had the pleasure of being an alpha
reader on, we encounter an alien species living
in a Topopolis, a very long and skinny megastructure
habitat - see the Megastructure Compendium
or that book for details - and their technology
has given them prosperity and their general
attitude has encouraged them to relax and
enjoy it, and the book explores this concept
of intelligence not being of great benefit
in a technological civilization that’s very
automated.
It’s a great novel and still fairly new
so I won’t further spoil it, especially
as its sequel is coming out later this year.
However we could imagine this situation easily
enough.
We build a space habitat or terraform a planet
and let automation or ritual or both handle
maintenance of it.
You don’t really need to be too clever to
fix something standardized with training,
even ignoring options for AI or self-growing
and repairing mechanisms.
You do need to be rather inquisitive and curious
to poke at such mechanisms as an adult and
damage them, brains are dangerous, and I could
see that being a strongly discouraged behavior.
But we might be over-generalizing to assume
encouraging people not to poke at the fundamental
architecture of their world is also discouraging
any other curiosity or brains.
Or that they should throw out their technical
manuals and not keep copies around.
As we noted in our Post-Science Civilizations
episode, where we contemplated cultures who
had either discovered all core science or
hit a wall or abandoned further research,
that is hardly an indicator a civilization
will fall into nihilistic decay.
Until a few centuries ago virtually no one
did science and people tended to lead happy
and often curious and educated lives without
pursuing new universal principles and physics.
Just because someone solved a puzzle before,
doesn’t mean you can't enjoy solving it
yourself, one of my favorite hobbies is doing
crosswords and sudoku puzzles with my wife
and neither of us thinks we’re doing anything
unique and helpful there.
A high-tech civilization also may have the
science to eliminate mutation of DNA, or be
a post-human civilization on digital substrates,
or have mastered psychology and boredom.
They may be nigh-immortal and so those great
experts of prior generations are still around
and even wiser with the centuries…
though they may be even worse about spoiling
their grandkids.
And there’s little incentive to become an
expert when Albert Einstein is still around
and famous, and as sharp as in his youth,
so impossible to catch up on in your eyes,
might as well enjoy post-scarcity utopia instead.
Nor is it hard to imagine a space habitat
parallel to the Amish, or even that groups
of Amish might commission big space habitats,
people often have rather murky and naive understandings
of how Amish attitudes on technology are structured,
or how diverse those attitudes are.
I expect we’ll see new variations spring
from that or others feeling they want to get
off the technology train.
Nonetheless we can contemplate a group of
settlers commissioning a space habitat for
their personal vision of pastoral bliss.
And they might have chosen folks who sacrifice
some of that bliss to learn to maintain the
habitat or are a subculture hired for that
role, or what they do with kids who are too
inquisitive.
Now if you’re watching this show odds are
good you would qualify as the latter, and
I’m guessing that you don’t have a desire
to abandon all your friends and family who
are less technological inquisitive and curious
to found a new civilization without them.
So we shouldn’t assume this is an unstable
civilization prone to turning into some caste
system and eventually sub-species, anymore
than we have castes of Electricians and Mechanics
and Chemists who feel a need to become a separate
society, rather than just having clubs or
groups to hang out in for appreciating that
topic.
Also, I suspect near-instant communication
and virtual communities won’t be common
as things civilizations give up when creating
their ideal anachronistic version of techno-primitivism.
They might look like they live in the 16th
century but still have limited internet and
cell phones.
Of course such a civilization might have that
built in as some sort of Technological Telepathy
- see that episode or Hive Minds for more
discussion of such concepts, but maybe they
just have a group mind akin to the Unimind
from Marvel Comics’ Eternals, that they
can briefly form for the mental equivalent
of Voltron and problems that require that.
Alternatively we can’t rule out stratification
genetically, two groups of humans with major
diversification by mutation or genetic engineering
and still living near each other or interdependently.
This can also result in speciation at this
point, one group retains or reclaims a trait
and the other doesn’t.
This relationship might be symbiotic, or it
might be parasitic.
The fictional Morlocks and Eloi from H.G.
Wells’ The Time Machine are both weaker
and dumber versions of modern humanity set
in the 800th millennium, the Morlocks being
nasty underground dwellers who eat the cattle-like
friendly Eloi.
The Morlocks and Eloi were both human descendant
sub-species, and both pretty stupid, and the
Eloi were only likable because they were childlike
- and in the positive and cute sense of childlike.
They both fit into the more classic pre-Darwinian
outlook that humans were greater in the past
and have been degenerating since, and in our
case 1 sense of inherent degeneracy of the
species.
And of the world more generally, I’d say.
In the novel we see our protagonist travel
further ahead in time, 30 million years, and
there he encounters a race of butterfly-like
creatures preyed upon by a race of crab monsters
and a world of simple lichen vegetation, and
further travels show a slowly dying Earth.
In the authorized sequel to the novel by the
great Stephen Baxter, our time traveler speculated
about those crab and butterfly-like creatures
being descendants of the Morlocks and Eloi.
Here you might get back the brains that humanity
lost to become the Eloi and Morlocks, or lost
further perhaps to become the crab-things
and butterflies, because you’ve introduced
a predator prey cycle that can presumably
weed-out weaker specimens, and in truth there’s
no obvious reason why they lost it, beyond
that inherent degeneracy notion which seems
at odds with our current scientific understanding.
Of course, brains are very expensive, we use
a lot of our diet and effort supporting ours,
and the idea goes that absent predators or
dangerous environments that need goes away,
but a predator prey cycle could also lead
to ultra-specialized low intelligence adaptations
too.
Especially in a dying world with less overall
energy and biomass density in its ecosystem.
More over, you could also have other scenarios
where this was intentional, people made dumb,
and we should note that intelligent lifeforms
can override or interfere with evolution.
In Brave New World, they determine intelligence
for kids and from the perspective that they
only need so many smart folks.
They have Alphas, bred to lead, and also Betas,
Gammas, Deltas, and finally Epsilons, bred
for menial labor.
Those lower three castes are for menial and
low-thought labor and are grown in tanks and
intentionally subjected to oxygen deprivation
to make them dull and obedient, especially
the epsilons.
It wouldn’t be very likely humanity would
naturally evolve into a system like that,
but the technology already exists to do that
if we wanted and I think a lot of people would
cheerfully embrace that, so long as they figured
it left them on top.
We could imagine someone deliberately introducing
some genes that controlled intelligence that
each popped up with a certain statistical
reliability and showed an external sign.
Maybe you're born with purple eyes or hair
if you’re a genius, blue if you’re very
smart, and down the line to orange and red
for very dumb.
Or some other trait, like social skills.
We’re not fond of caste societies nowadays,
but they have been common enough in human
history and often did result in stable societies,
which might be appealing to many.
Brave New World is also the setting that gives
us Soma, the super drug that keeps the masses
happy, and we can definitely imagine civilizations
running on that option.
Let’s imagine somebody genetically tailored
a plant to produce that drug in its leaves
and be hardy enough to survive in most environments.
Now you no longer even need technology to
produce your drug, and how resistant to addiction
or to the negative effects you were might
be the control on who is running a society.
Or alternatively, the trait that gets you
weeded out.
Now, option 2 is our case where something
went wrong, and turned people into mutants,
freaks, idiots, cannibals, or what have you.
And something like a retrovirus for extending
life spans or some superdrug being bred into
a hardy plant could definitely qualify as
that event, but so could nuclear wars or a
ton of other options that fiction has suggested
over the years.
Just as a general reminder though, as popular
as it is in sci-fi for gaining superpowers,
in reality, radiation and toxic waste aren’t
likely to help you unlock any new abilities
besides rapid tumor growth.
We also aren’t necessarily talking about
narcotics.
The Spice Melange from Dune, which grants
extended lifespans, better health, and prescient
foresight, is definitely treated as a society-changing
substance that gives with one hand and takes
with the other, for all that it has only positive
benefits.
At least if we ignore its tendency to turn
extremely heavy users into mutant starship
navigators.
A society that has access to a limited supply
of some drug that makes its users healthier,
sharper, and longer lived is one that is going
to end up succeeding in a lot of colonization
and expansion and having a population larger
than that limited supply can support, thus
haves and have-nots.
The game is very different if you can expand
that supply to everyone, but then you also
have cultural shifts when the average person
is living in great health to age 300 and your
rulers can literally see the future.
In Isaac Asimov’s classic novel the End
of Eternity, which would seem to draw a lot
of inspiration from H.G. Wells’ Time Machine,
we have a group of people called the Eternals
with access to time travel to any point in
time after they invented it, and they use
it to constantly do little shifts and improvements
to the timeline.
In the end they observe that they’ve unintentionally
been breeding risk-taking and expansionist
behavior out of humanity, who never risk colonizing
other solar systems and are never having much
real mutation either.
It’s a stagnant, disaster-free civilization
that sprawls over 10 million years, then much
like in Time Machine, we’re shown an eventual
dead and abandoned Earth absent of intelligent
life, then absent of any life at all.
And that’s a good segue back into our third
and final case, which is the idea that intelligence
itself might be that negative trait we want
to get rid of.
Particularly what we might call exceptional
intelligence.
Sharpen the curve around IQ 100 so you have
fewer outliers, maybe there’s more people
at 110 or 120 but virtually no one over 130,
or maybe the average goes down to what we
would score as 90.
Not because we let it happen by accident,
but because we invent virtually every useful
tech, and we are noticing that each new one
is bringing little real gain to humanity but
a larger risk of physical or existential danger.
Simple version, an AI is handy, but one too
smart can kill us off, and we don’t really
need AI that will reduce our workload to nothing.
Honestly very few of us even think that is
a desirable goal.
You get a civilization with automation just
a little better than we have now, with some
interfaces a bit more socially graceful than
ChatGPT, and some sort of renewable power
supply allowing equal or better energy prices
than now, and you are a post-scarcity civilization.
As we’ve discussed in our episodes on that,
those come in varying levels and flavors,
and are not necessarily permanent, you can
exit out of one by over breeding or blowing
yourself to pieces.
It is not that hard to imagine a civilization
in which most folks live for over a century
and with good health, in something like a
modern mansion, and work some job they like
for the equivalent of part-time, saying no
to a lot of additional life conveniences and
the research funding them.
Better technology definitely has a flavor
of pyrrhic victories when we think about societies
that get too reliant or spoiled by it.
Moreover, nobody is building a doomsday weapon
if you don’t have anyone smart enough to
design or manufacture it.
Truthfully, they’re not likely to whip one
up in the lab even with an old design without
a lot of specialized and trackable equipment.
But if your geniuses keep inventing ever better
options like a Star Trek Style Replicator,
weapons proliferation gets really tricky to
limit.
There are a lot of reasons a society might
decide it doesn’t need the risk of ultra-high
intelligence around, especially when they
already have huge archives of science, literature,
and art beyond what any hundred people could
absorb in a dozen lifetimes.
After Isaac Asimov passed on, a trio of some
of my favorite sci-fi writers, Greg Benford,
Greg Bear, and David Brin wrote a commemorative
‘second foundation’ trilogy exploring
that universe more, and one of the neater
suggestions was that they made or adapted
some disease like chickenpox that virtually
everybody got as a child and that most barely
noticed but that a lot of cleverer kids had
far worse.
Essentially it was causing a little brain
damage to the smartest.
And this resulted in a stable empire that
endured galaxy wide for thousands of years,
but was also very rough on innovation.
Of course, if life is already very nice, further
innovation isn’t necessarily a great thing,
again it’s not really saving many lives
or improving them at a certain point, one
might argue, just adding in more potential
doomsday vectors.
I will also note that Greg Bear wrote the
Forerunner Halo Novels where we see ancient
humans being devolved by the Forerunners after
a war.
And so this case strikes me as far more likely,
a civilization that actively seeks to curb
its outliers to minimize risks because they
think those are now exceeding gains.
Emphasis on ‘they think’, they may be
right too but what matters is what that society
believes is true.
And this is decently probable because one
of the answers for the Fermi Paradox people
most favor is that societies get too clever
and blow themselves up, or replace themselves
with AI.
We usually say that isn’t a good solution
but there’s a tendency to assume AI just
keeps getting smarter, when it might just
as easily get dumber over future iterations
– dumber is faster to act for instance – and
again we have a bias to assume evolution has
some end goal and that it’s big brains.
These days there’s an increasing worry that
it’s not the smart AI we really have to
worry about killing us off – not because
they aren’t a threat but rather because
something dumber than humans might do the
job and occur sooner.
Peter Watts’ novel Blindsight works with
this scenario, and without spoiling it too
much, aliens around the galaxy tend to have
very high-speed brains but are sub-sapient,
and basically go wipe out people sending messages
around the galaxy because they view it like
a massive spambot sending irrelevant and non-productive
nonsense out as an attack like a virus.
Watts is a Marine Biologist, and he takes
us on some interesting science on the topic
of how brains aren’t always that awesome.
It’s a great sci-fi book with a lot of good
science in it too, which is rarer than I’d
like.
But to close out on, for one final point in
favor of why intelligence might might be lost
intentionally, for those of us who like our
sci-fi, there’s a tendency to assume an
onrushing acceleration of intelligence and
technology, a technological singularity or
an ascension to some higher existence, that’s
almost like a car crash and happens almost
instantly over some centuries in comparison
to galactic timelines of billions of years.
There are no big sprawling mega civilizations
because they all go to the singularity like
a quick explosion going off once they learn
to do science.
We tend to almost take this future as a given,
in some form or another, but it doesn’t
seem like it’s all that popular, even among
us techy and geeky types.
But if it is such an obvious future path and
so clearly disastrous, at least from a certain
perspective, why wouldn’t civilizations
put a halt to it?
We talk about the unstoppable forward progress
of technology and civilization but that’s
just rhetoric, we expend insane amounts of
resources to keep that progress moving forward
and it would grind to halt pretty quickly
if most folks decided they were done funding
it and stopped encouraging their kids to go
into it and stopped praising those who do.
I’m not sure if devolution is particularly
probable, let alone if it involves some pathway
to primitive underground cannibals, but as
to coming to a halt and putting brakes on
ourselves to not progress further, that I
think has a stronger case supporting it.
For good or ill, our society has always been
nervous about our excess curiosity and Pandora’s
Box and knows we flirt with disaster every
time we open it, so it is possible we might
go ahead and slam it shut and break off the
key in the lock.
And it may turn out the Galaxy is made up
of isolated worlds that abandoned that box,
or the remnants of those who never learned
to curb their curiosity before their cleverness
opened the doors to their own inevitable destruction.
Today’s topic was definitely one that emphasized
the importance of learning, and I would emphasize
that I think we’re also learning more about
how learning happens.
As channel regulars have often heard me say,
the best kind of learning is interactive,
and focusing on engaging content and visuals.
And our new partner, Imprint, focuses on animated
visual explanations, and most of their lessons
are bite-sized and take about 2 minutes to
complete.
They help you understand complex topics quickly
with content designed to help you stay focused
and engaged, so you can learn more about science,
technology, history, psychology, philosophy,
self-help, business, finance, wellness, and
more.
Join the millions of users learning on Imprint
and their expansive library of top-notch material,
interactive content from Best-selling authors,
Harvard Professors, and many other experts.
Instead of doomscrolling through social media,
enjoy your screen time learning something
new.
Try Imprint out and start learning today with
their 7-day Free Trial, by going to Imprintapp.com/isaacarthur,
and the first 200 subscribers will get 20%
off an annual subscription.
So that will wrap us up for today but not
for August.
We’ll close out the month with our Livestream
Q&A, Sunday August 27th at 4pm Eastern Time,
and then Thursday, August 31st, with a look
at near term space colonization.
Then it’s into September for Living in Space,
on September 7th.
On the 14th we’ll ask about the infrastructure
we need to build in our solar system to colonize
it, and then we’ll jump into Scifi Sunday
on September 17th to celebrate the SFIA’s
9th birthday with the Fermi Paradox: Fallen
Empires.
And if you missed this weekend’s sci fi
Sunday, Cyborg Armies, you can check it out
now.
If you’d like to get alerts when those and
other episodes come out, make sure to hit
the like, subscribe, and notification buttons.
You can also help support the show on Patreon,
and if you want to donate and help in other
ways, you can see those options by visiting
our website, IsaacArthur.net.
You can also catch all of SFIA’s episodes
early and ad free on our streaming service,
Nebula, along with hours of bonus content,
at go.nebula.tv/isaacarthur.
As always, thanks for watching, and have a
Great Week!
