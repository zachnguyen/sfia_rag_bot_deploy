This episode is brought to you by Brilliant!
Long before we knew what stars above truly
were, we contemplated them as the home to
immensely powerful beings, that may turn out
to still be the case.
35 Years ago, the Star Trek franchise opened
a new chapter with the premiere of Star Trek:
The Next Generation, and the episode “Encounter
at Farpoint” and the studio wanted a two-hour
first episode, so they padded the script with
things like a really long docking sequence
and an additional encounter with a strange
and powerful alien known only as Q, played
by John De Lancie.
This addition to fill out the runtime resulted
in Q becoming a recurring character throughout
Next Generation, and appearing in Deep Space
Nine and Voyager and will be in Picard Season
2, which will have premiered by the time this
episode comes out.
Q is probably the most famous godlike alien
we see in science fiction, though hardly the
only one, Stagrgate is full of them as is
the MCU.
We even see more in Star Trek, and Q definitely
has a flavor of the capricious, the arrogant,
and the cruel we so often see with deities
out of Greek and Roman Mythology.
Again though, he’s not the only godlike
alien we meet, indeed in the original Star
Trek, the crew outright meets the Greek god
Apollo, and fights him.
As is often the case in scifi, his power comes
from something technological.
He’s really just impersonating a deity,
or was an alien that folks came to see as
one.
However, that’s not the case with Q and
we see a mix of such things in other franchises.
Probably mostly notably in recent years with
the Marvel MCU, where we get Thor and Odin
and Loki and whatever they’re planning to
do with the Eternals and Celestials in upcoming
films.
So our topic today is to discuss what godlike
aliens might actually be like if we end up
encountering them in our real universe – or
our simulated or created universe perhaps
– and we will be drawing on a lot of science
fiction for conceptual reference points and
comparisons.
Now in fiction they can come in a lot of flavors,
indeed even the same character can depend
on portrayal.
Q for instance can seem diabolic, petty, mischievous,
or even the stern teacher varying by the case.
One moment he’s a petulant child who is
easily wound up or tricked, another episode
he’s almost pleading with the crew and audience
to take the hard high road to greater exploration
and enlightenment.
And in this regard he very much matches what
we often see in other fictional and mythological
divine cases, a mixed and varying perspective
on the motives and actions of godlike individuals,
as well as groups of them.
As is often the case in our alien civilization
series, we’ll draw on these examples to
help examine the topic, but here we need to
start by acknowledging that the necessity
for a good story tends to limit the accuracy
of such characters.
For instance, it’s a very boring story if
you encounter a hyper advanced and intelligent
species who really are very kind and enlightened,
and also willing to actively help you.
Folks are living and dying and often fighting
some dread evil that these aliens could help
out against but they won’t.
When asked, the aliens will usually give a
fairly stock response about us not being ready
or it being immoral to force their will on
others even to prevent genocide and how we
just don’t understand.
Now philosophically this is legitimate enough,
it’s essentially the age-old Problem of
Evil, popularized by David Hume and attributed
to Epicurus to sometime in the 3rd or 4th
century BC but probably a lot older.
You’ve probably heard it phrased as “Why
does an all powerful and all good God allow
evil or bad things to happen?”
but it's probably better phrased today as
“If something is really evil, it can not
be necessary, and if it is really necessary,
it can not be evil”.
For the moment what matters though is that
most writers aren’t using this philosophical
debate as their reason for standoffish super-aliens,
but rather because the story gets boring real
quick if they get involved.
It's sort of like if in the Star Wars prequel
trilogies the 20,000 Jedi knights said to
exist actually sent a few dozen Jedi knights
to deal with the crisis on Naboo, rather than
just one Jedi and a padawan.
They could have also sent a dozen Jedi Knights
to arrest the Chancellor or sent more than
a handful of Jedi in a ton of other situations.
That’s the First Rule of Warfare after all,
there’s no such thing as overkill.
From a fictional perspective though, the story
would get boring.
Unfortunately, its repetition in the ongoing
plot makes people unwilling to accept it as
a constant and repetitive coincidence.
Now that sort of situation, also popular in
scifi, is a reminder of the First Rule of
Warfare, always keep some reserves for dealing
with unexpected emergencies, but both notions
are hard to handle properly in writing stories
because invincible, active and reliable allies
or proper measured responses with available
resources rarely make for good films and TV.
They do often make for better books and it's
pretty common for a TV adaptation of a book
character not only to be played by a younger
actor in the show than the character is in
the books and for them to seem to act a lot
younger too.
The Jim Holden of the TV show, The Expanse,
seems a lot younger and more reckless than
his book version for instance, who generally
makes decisions based on a calm head and reasoned
argument shared with the reader, not brash
and often crazy-sounding ones.
The same is true for Frodo from Tolkien’s
classic, Lord of the Rings.
Frodo is 51 years old when he flees the Shire
with the Ring, 17 years after he got it, and
he takes his sweet time in an attempt to quietly
disappear.
He’s not young or immature and he’s viewed
as the wiser older brother or boss by his
fellow Hobbits, and he often comes off this
way in the novels.
Of course those novels also show us a lot
of mysterious behavior by divine agents that
results in stuff like the Eagles showing up
when it’s convenient.
This is exactly what they are doing, they’re
implied to be divine agencies, and something
similar applies to Gandalf, who isn’t human,
and those various elves like Glorifindel,
who also fought a Balrog and was resurrected
like Gandalf.
But these folks are necessarily sidelined
a lot in the stories because they’re too
powerful.
This is a common tool in fiction.
In story the reasoning would tend to be that
some power above wants them all minimally
in play just to intercede to keep the test
or game fair and let the normal people decide
their own fate.
Now alien civilizations make an interesting
addition to this mix for a of couple reasons.
First, we know what technology can do to make
one group overwhelmingly invincible to another,
both our civilization versus more technologically
primitive ones and a human group compared
to animal cousins.
So folks find it easy enough to believe that
if there are aliens out there, some of them
have millenia of technological advantage over
us.
See our episode on Clarketech for some examples
of that.
For show regulars this is even worse, because
while fiction sometimes gestures in the direction
of advanced evolution or ascendancy to a higher
state of being, we know what some of the technological
implications of transhumanism and posthumans
are.
It gives you folks who are still finite and
mortal, not the All-powerful and infinite
God with a Capital-G, but they’re not impersonating
gods, lowercase, any more than Superman, Thor,
or Hercules were.
Indeed a lot less so, as we’ll get to in
a moment.
The Second reason why alien civilization makes
an interesting addition is because of the
Fermi Paradox, the apparent absence of aliens
in our Universe, at least in any active and
open role.
Many of us, myself included, tend to assume
intelligent aliens are just so ultra-rare,
and the law of physics and causality so ultra-rigid,
that we have simply not encountered any yet.
For others, these aliens either act semi-covertly
here on Earth, based on all the sightings
– and indeed often mythological figures
will be suggested to be examples of early
sightings and alien visitation – or they
hide from us and don’t involve themselves
for some reason.
Needless to say, both those cases, intentionally
unseen by us and here but quietly involved,
fit the mysterious advanced godlike alien
trope pretty well, as does the slightly snobby
version who doesn’t deign to contact us.
And we see this a lot with the space elves
tropes and also with the good-hearted wanderer
or misanthrope style character we often see
in folks like Gandalf, though I often feel
the tendency to be touchy and anti-social
is a narrative excuse for why they don’t
answer questions and people don’t press
them, and thus spoil the story or mystery
or expose a plothole.
They often seem like Diogenes the Cynic, a
smart man who eschews all comforts and trappings
of wealth and power, and often in some parallel
quest to his own; of seeking to find an Honest
Man.
Personally I’ve never liked that flavor
of character but then I never really agreed
with or liked Diogenes, who I generally think
had such problems finding an honest or admirable
person because he was neither, and thus wouldn’t
recognize either.
Incidentally, Gandalf is a Maiar in Tolkien
Mythology, not human, as are Sauron and Saruman,
and Radaghast and all the Balrogs, and they’re
basically a second-tier angel underneath the
nominal archangels or Valar of the setting,
and they are supposed to be very superhuman
and portrayals again will vary, as would overall
power and competence, much as with humans.
I said a moment ago that if we’re talking
about genuine transhumans or posthumans, or
post-aliens as it were, that they’re not
impersonating gods any more than Superman
and such folks are, and we should take a moment
to explain that.
If you’ve seen last week’s technological
singularity episode or any of our episodes
on cyborgs, transhumans, posthumans, post-scarcity
civilizations, Kardashev-2 civilizations or
smart matter, then you probably already have
a good idea how big the power upgrade can
be with one of these folks.
They’re not some modern human stepping out
of a time machine to the days of yore with
a STEM background and backpack full of modern
gadgets.
Imagine a creature that could stand in the
wilderness and hear a pin drop a mile away.
Imagine a being who could stand in a packed
football stadium and pick out any conversation
going on.
One that can see any frequency of light and
probably has enough on board scanners and
processing power to see through walls or access
any local Bluetooth or wifi.
Imagine they could not only pick out any conversation
in that stadium but could probably simultaneously
hear and comprehend them all.
Good luck sneaking up on this person.
Now they might be bulletproof.
They might be able to dodge machine gun fire.
They might not need superhuman speed or toughness
due to their reflexes and predictive capabilities.
They might be coordinated enough that when
you went to shoot them, they kicked a piece
of gravel right into your gun barrel or right
between your eyes.
They probably still obey the known laws of
physics so they’re not doing Superman or
Thor or Hulk-style over-powered stuff, but
they would flat out murder any one of those
gentleman because they already know all the
million little tricks to overcome superpowers,
and optimize the use of theirs in tandem.
It’s not just that they’re more intelligent
and inventive than a Reed Richards or Doctor
Doom or Lex Luthor, it’s that they could
probably talk Doom or Luthor into giving up
their evil megalomaniacal ways through sheer
charm and psychology – and if that failed,
by infecting them with nanobots that could
brainwash them or restructure their brain.
There’s a common tendency for alien ambassadors
to come to Earth in scifi and get a portrayal
very akin to a messenger from God, whereupon
we often end up killing them, most notably
in the classic film, The Day the Earth Stood
Still.
This usually results in awesome retribution
and even that’s pretty minimal compared
to what a real interstellar civilization could
do.
Realistic aliens have warships that could
sterilize our planet all by themselves and
they potentially have trillions of them.
And so killing their ambassador violates the
First Rule of Warfare, never pick on anyone
bigger than you are, or ideally, even the
same size.
But in the post-human context, shooting the
alien ambassador isn’t just a bad idea because
his civilization will avenge him if they find
out, rather it’s because he is gonna ROFL-stomp
you all by himself.
Kill the alien ambassador by blowing his head
clean off and he might stand up a few seconds
later to cheerfully inform you that such awesome
regenerative technologies and medicines will
be freely available to all as soon as our
civilization joins their empire, which we
should do right now.
Or a copy of him might step off his ship looking
irritable about what you did to his android
avatar he’d been remote controlling.
Or his green alien blood might soak into the
ground infecting everything with nanobots
that start spewing out war machines, nerve
agents, and viruses that look like Covid and
Ebola had a kid.
All while also probably infecting your entire
cyber and digital infrastructure and creating
deep fakes so good your own folks are sending
command codes to fire your ICBMs at some place
he tricked you into sending them.
And remember, this guy’s not special, he’s
just sporting the usual augmentation that
everyone in his culture has, no more divine
in their eyes than our smartphones makes us
in each other’s.
There’s probably nobody acting as a waiter
or flight steward on his ship, but if there
were, that fellow would be similarly terrifying
and unstoppable.
Heck, the robot butler actually playing steward
might come rolling out of the ship firing
gatling guns running on antimatter, so that
every bullet out of the tube was a modest-sized
nuclear bomb.
And all of this is just inside the zone of
known physics, we’re not even talking about
critters who can bend or reverse time, ignore
entropy, adjust physical constants, play with
gravity or probability, or just fundamentally
screw with the programming of reality itself.
Godlike is fairly relative, and how awesomely
powerful they would be is more of a limitation
of our imagination than real physical constraints.
To be honest, that earlier contemplation of
the typical post-biological alien ambassador
is my best fumbling guess at what the typical
‘human’ is going to be like in a millennia
or two, maybe sooner.
And of course we don’t really know what
their powers would be, but in reality that’s
very secondary to what their motivations are.
To the ant, it doesn’t matter if it’s
a mouse or human or an alien armada of super-beings
that want it dead, all that really matters
is that all 3 can kill them easily, and via
many methods.
And so all that really matters is what the
motives of the godlike critter in question
is.
Now we can pair that up with asking about
their ethics or maturity as well, childlike
super-entities are popular concepts in fiction
and mythology too, but the motivations question
seems to mean more.
For an alien focused on navel-gazing to enlightenment,
I’m not sure they have any motive beyond
personal survival, but while in fiction we
sometimes see these sorts of folks quietly
meditating and unwilling to take any action
to defend themselves, preemptively or even
when directly attacked, I’m not really clear
on why this is viewed as enlightened so I
assume it does not apply universally.
I don’t think you’ve got vast ancient
alien minds or empires that just ignore threats
or ignore them till the last minute.
There may be deeper purposes to existence,
I like to think so, but the one programmed
in by nature is survival, and I can't see
any lifeform casually discarding that as a
major priority, even if it becomes secondary
to others goals, so being smarter and more
powerful should make them even better at survival
and preparation.
Now intelligence by itself doesn’t necessarily
mean its possessor is good at predicting problems
and predisposed to do so.
But generally in a complex and long-lived
civilization, a capability to anticipate problems
and willingness to delay self-gratification
to manage them are valued traits that are
encouraged.
And it's hard to imagine a creature capable
and determined to spend millennia or eons
in isolated deep contemplations is not also
of that sort of mindset.
So if there’s a big threat out there that
they’re not getting off their butt to handle,
it's either because it’s not a threat to
them and they genuinely don’t care if it’s
a threat to others, or because they already
did handle it.
It's not that that alien civilization thinks
interfering with more primitive civilizations
even to save them from being wiped out is
ethical, it's just that they don’t care
if we think they do, or they even prefer that
we think they won’t help us, because they
actually did help, they just didn’t want
us to know and thereby incorrectly assume
that we will always have a big brother watching
our back for us, as this might make us careless.
We see something like this with the superhuman
members of the Second Foundation in Isaac
Asimov’s classic Foundation Trilogy, they
are hidden but expose themselves to fix a
major crisis, then have to work to restore
initiative in those they rescued before faking
their own obliteration.
In cases like this, where a benevolent alien
might help but pretend not to, we get to one
of those predictive impasses, because if the
supersmart and powerful aliens are benevolent
but don’t want us to know they are, then
they have the brains and capability to create
that illusion plausibly.
Same for if they’re aiming for ambiguity.
If a godlike entity wants you to go through
life uncertain about their involvement and
intent, because they think that ambiguity
is healthier for growth and free will than
being certain they do or don’t exist or
act, then while that’s going to require
an impressive balancing act, you are presumably
talking about someone who finds that juggling
chainsaws while walking a tightrope in a hurricane
a rather boringly simple effort.
And that’s one of the problems with godlike
aliens, even if they’re acting like selfish
morons you don’t know that you aren’t
responding to them exactly as they intended.
It should be absurdly easy for them to convince
you they’re the nicest and best person you’ve
ever met, even if they were absolutely selfish
and diabolical.
Indeed even one of them apparently murdering
and torturing someone in an apparent moment
of sadistic and childish spite can’t be
ruled out, as it is probably in their capability
to have - for some reason unknown to us - transferred
that person’s brain directly to a virtual
paradise while puppeting their body to look
and say convincingly tormented things, in
order to achieve some desired effect in their
audience.
This is one of the problems when dealing with
something like Simulation Hypothesis, when
we ask if we might be living in a simulation,
because since we know it takes way less processing
power to reasonably fake a human than emulate
one properly, we can’t look at the world
around us and see other people’s suffering,
especially folks we don’t know intimately,
and assume that the world can’t be a simulation
because no one would make such a cruel virtual
reality.
Quite to the contrary, a civilization more
advanced than ours, worrying about moral decay
from all their advanced tech making life a
little too easy, has a very good motivation
to raise its kids in fake realities with hardship,
what we usually call a Nursery Simulation,
and that does not require that most ‘apparent’
people in that simulation, be fully sapient
and sentient.
So an individual can only judge the likelihood
of themselves being in a simulated universe,
where that judgment might hinge on ethical
treatment of the folks inside it, based on
their own personal experiences.
It doesn’t matter how many people you’ve
heard about having awful lives or experiences
far away, you don’t know they are real,
indeed even those people of your personal
acquaintance might be fake.
However, even your own personal experience
is not enough to rule out such simulation,
since advanced technology and techniques imply
the ability to not only delete or dampen traumatic
memories from someone, once woken from the
simulation, but also possess really good psychological
counseling capabilities.
So they might not view you falling into the
hands of a sadistic psychopath for a degrading
and slow death to be unethical, because it's
not irrevocable.
You will be awakened into a higher reality
for a life far better and longer than the
one you endured.
Obviously, that one sounds an awful lot like
many-a-religion and as often gets noted, the
difference between simulated realities, simulator
realities, and programmers with higher and
lower planes of existence, heavens, and God
or gods is pretty semantic.
Especially given that the entire idea the
simulation is running on a computer relies
on the notion that the lower simulated reality
has the same physical laws and properties
as the layer above.
They might not have semiconductors to make
computers like ours, indeed they might not
even have the same math.
And when we were talking earlier about what
a posthuman or alien might be like, we were
still working at the fairly lower scale.
We weren’t talking about something like
a Matrioshka Brain.
If you’re not familiar with a Matrioshka
Brain, the name has to do with it being a
multi-layered spherical construct, but the
short form is, it’s a mega-computer running
on the entire power output of a star, that
power output is about trillion-trillion times
more than what your typical high-end gaming
PC draws when its running heavy and hot, so
the assumption is that even if we never improved
our computer chips or solar panels beyond
what they are right now, you can have something
pretty terrifyingly potent if you’re willing
to convert a whole star to that purpose.
Given that there’s hundreds of billions
of stars in our galaxy that seem not to be
doing much of anything with the majority of
their power output, the assumption is that
any alien species that could travel to our
star could also have traveled to others and
built these.
Truth be told, building nothing but computer
chips and solar panels is not something we
would think of as a very hard job for some
self-replicating robots, they already are
the ones building our current chips and panels,
and thus probably requiring less brains and
processing power than your phone or PC or
tablet has.
And mind you, that trillion-trillion figure
is assuming their computers are no better
than ours, which seems improbable.
What’s more, the human brain runs on similar
power levels in between what modern PC’s
and smartphones do, and while we might not
have true AI yet, I think the loose consensus
of researchers in that field is that our current
best supercomputers – which run on under
a megawatt – are probably already sufficient
to run something human-level in intelligence
once the software catches up, so to speak.
Nobody is really thinking we need a thousand
times the power or processing to get that
job done anymore.
This episode isn’t about super-intelligent
AI, but it is about the idea of entities which
would either match that, exceed that, or could
build and control that.
And keeping in mind that even a computer that
needed a full megawatt to mimic a human intellect
would still leave enough sunlight for 40 billion-billion
siblings, or 40 billion versions of itself
a billion times smarter than a person, we’re
not really talking about some singular entity
that’s godlike but more an entire species,
and one that probably outnumbers us.
So yes, simulating an entire Universe is well
within the capability of something like a
Matrioshka Brain, and in this sort of case,
all that can matter is motivation because
capability is simply irrelevant.
If we’re encountering one who shares our
Universe with us, then it holds every single
card except those being held by fellow or
rival minds of similar scope.
It is not right to think of it as regarding
us as we would regard an ant or even an amoeba,
because it is not us.
It has enough brain power to simultaneously
carry on a meaningful conversation with every
human who ever lived simultaneously and still
be using only the tiniest fraction of its
mind for that.
We’re not distracting it from some weird
quest to calculate every digit of Pi or something
like that, by asking it a couple questions,
indeed it wouldn’t be distracted even by
scanning our brains, making copies of them,
running a billion simulated realities trying
out different results of possible answers,
and a millisecond later giving an answer well-designed
to get us to do whatever it wants… which
might be to go away and not bother it till
we’re building our own Matrioshka Brain
to help in the sacred task of calculating
Pi.
But what would help even more would have been
to cannibalize the whole galaxy into computers
for calculating that, not just one star, and
that clearly isn’t being done to our galaxy,
so either one doesn't exist yet or doesn’t
find those kind of tasks interesting or enlightening,
and maybe would find us more interesting then
some folks assume.
Personally I find humans much more interesting
than Pi, mathematical or flavorful.
If we are in its simulation though, it has
utter control of its reality if it's simulating
it and you’re inside it, and that includes
being able to erase your memories or rewrite
them or predict your actions or even build
in flags and alerts for if you start getting
suspicious of how real things are or are not.
You don’t notice glitches in the Matrix
and when you do, it gets a notification and
suddenly you think it's irrelevant or forgot.
You don’t believe you’re not real and
it can ensure you don’t.
Assuming the term ‘real’ matters in this
context.
As I often say in regard to the Simulation
Hypothesis and the question of if we live
in a simulation or not, the better question
is probably to ask if it actually matters.
We can hypothesize advanced civilizations
built on morality and personal discipline,
slowly degrading into petulant spoiled children,
though still possess godlike powers, but we
can’t casually overlook that they should
have a lot of resources for preventing that,
like advanced psychology and simulated nurseries
and so on.
They’re likely to be functionally immortal
too, so the wise and composed founders of
their enlightened civilization didn’t go
anywhere, dying to be replaced by increasingly
degenerate descendants, each just a little
more degraded than the last.
They’re still there, and what’s more,
spoiled kids are not an inevitability of a
civilization.
A quick and incomplete list of signs a child
is spoiled include that they don’t express
gratitude, they hate being told no, they don’t
play well with peers or share, nor volunteer
to help, they throw tantrums and lash out,
do not compromise or show empathy, nor care
if they inconvenience others, and are often
bullies, manipulative, and demand special
treatment.
When you contemplate that list, it reminds
me a lot of many of the fears expressed about
interacting with a given powerful alien.
So on the one hand it seems a very legitimate
worry.
Problem is that it is ignoring that their
improvements in technology probably also apply
to psychology and child development, and such
behaviors are at least as detrimental to their
own civilization as foreign ones.
I’m not sure I go so far as to say that
civilizations have a predisposition to eliminate
anti-social behavior, but it probably is fair
to say that societies would tend to want to
seek to curb anti-social behavior.
And thus we wrap around again to the concept
of motivation, what the alien actually wants,
because realistically we won’t be able to
tell much simply by its behavior.
Now that alien might just want to be entertained
but unless we are assuming actual and total
access to infinite resources, it probably
does not bother fully simulating an entire
civilization of actual sapient minds, and
yet it should seek virtual reality as an alternative
to being entertained by actual living creatures
in its own universe where that would be difficult
or risk angering other parties who could act
against it.
It’s presumably smart enough to know how
much extra risk and effort it's expending
to little gain, and it’s also presumably
smart enough to notice signs of pathological
or addictive behavior in itself.
It may come from a civilization where that’s
as easily and quickly treatable as a minor
cut and it may come from a civilization that
gives people something akin to an immune system
for their minds.
As with many fundamental behaviors we might
describe to a godlike alien that we wouldn’t
like, we can ask ourselves why we think it
is bad and odds are the critter in question
or their civilization are aware of why it
might be objectionable, assuming they don’t
agree.
We would not suggest someone create an entire
virtual reality full of actual thinking and
feeling creatures just for their entertainment,
or curiosity or lab experiment either.
We would also not suggest they travel to islands
or worlds inhabited by primitive peoples,
to play at god and satisfy their urges for
entertainment or curiosity without restriction.
Emphasis on ‘without restriction’ because
I don’t think we’re saying it's immoral
to be entertained or curious, just that you
would do these without restraint and if you
do have peers, you don’t want them thinking
you would either, because they’re in a position
to restrain you and now you’ve given them
a motive to consider doing so.
What other motives are there, that would fit
what we see?
Well, as we discussed some years back in our
episode Gods & Monsters, we can’t rule out
that we really do live in a Universe created
by various inhuman, insane, predatory, and/
or sadistic godlike entities against which
we are utterly helpless and which would drive
us mad merely to look upon.
We discussed why that would seem counter-indicated
by the apparent universe we live in.
But this does not mean we can just assume
a godlike alien has motivations like ours.
We’re not going through them all because
not only are there plenty of examples, but
it’s also rather one-dimensional to assume
such an entity has one principal motivation
that is all it cares about, which we often
see with AI computer minds in scifi too.
That’s another common habit in fiction,
to portray godlike entities as somehow more
simplistic than us too.
Which is possible but to me usually just indicates
bad writing.
We can’t examine all the various combinations
of how powerful-aliens would act with human
motives, let alone alien versions of those.
Nonetheless we can assume that these will
tend to be pursued effectively, because whatever
their goals are, they presumably want to achieve
most of those successfully or for the least
effort, and that implies a use of logic and
familiarity and skill with contemplating scenarios
and outcomes and alternatives.
So when we go on and propose a scenario like
“These aliens don’t interfere with us
because they think it’s wrong” we can
ask why they think it is, for instance if
they think specifically that they would be
hurting us by doing so, and with that motive
in mind – that they don’t want to hurt
us – we can then review their presumed capabilities
and ask what alternatives they have.
One alternative would be hiding from us while
carefully sneaking us in technologies and
knowledge that minimized our problems – as
they saw them – as quickly as they thought
safe.
That’s essentially what we try to do in
these discussions of hypothetical and unseen
aliens, figure out goals and motives from
the apparent universe around us and then ask
how they might better pursue that goal and
if the universe we seem to see would still
apply.
If they view us as primitives wrecking our
ecology, rather than hiding only to show up
when a lot of damage is already done with
a stern lecture, they could just show up,
explain what could have happened, and offer
us technological alternatives like clean fusion.
If that’s their motive, preserving natural
ecologies as they emerge in our Universe,
that method would seem better.
And they’re important contemplations too
because we have to remember, while fiction
likes to have us meet folks who are on our
level or maybe a few millenia ahead or behind,
all of human civilization amounts to only
a few millionths of the time that life has
existed on this planet or in this galaxy and
transhuman and posthuman existences seem a
lot sooner on the horizon than us learning
to make fire and chat around it is behind
us.
So almost every new encounter we have with
an alien mind should either be one so primitive,
it's not even at the chimp or dolphin stage,
or so advanced it could be considered godlike.
The upside we have is that for the latter
case, the responsibility of that first contact
situation really isn’t on us.
The older, smarter, stronger, and hopefully
wiser alien civilization presumably has the
ability and common sense to have done their
prepwork on learning our language and customs
and minimizing the chances for misunderstandings.
If one walks down a ramp from its ship threateningly
while waving a gun and gets shot by some nervous
soldier or police officer, and their companion
starts going on about how violent we are and
how foolish to assume harm was meant, I think
we have a right to turn around and ask how
they could possibly have not realized that
would provoke us.
Of course the problem with a godlike alien
is, they might not care if we pointed that
out and just opt to crush us, and maybe more
enthusiastically for having gotten uppity
and pointed out their bad logic.
It’s a thing to keep in mind as we head
to the stars, as they do seem empty of ancient
and godlike civilizations thus far, that we
might be the first one on the scene and might
be the ones walking down the ramp from our
spaceship to say we come in peace and want
to speak with their leader, and hopefully
we or our scouts and vanguards will act with
ethics and consequences in mind.
We will examine the alternate side of all
this, primitive aliens rather than godlike
ones, later this summer.
I often get asked by folks who want to share
knowledge on some topic for advice on getting
started on youtube or podcasting, or if to
do it and someone asked me recently what I
liked the most about using video as a format
for discussing topics and material.
I said I liked that it let me prepare a topic
in a well-scripted way then use a mix of visuals
and audio to enhance that presentation over
people just reading a blog or listening to
my voice only.
The follow up was “what do you most miss
having that video doesn’t permit?” and
I said I missed the hands-on interactivity
and back and forth with students I got when
teaching labs back in college or when I was
instructing or tutoring on this or that in
the Army where I often instructed on use of
weapons and other equipment and various toipics.
Nothing ever beats interactive learning, it
is simply the best way to learn,and that’s
something our longtime show-sponsor Brilliant
understands all too well.
I remember several years back when I first
saw their courses on Math, Science, and Computer
Science being impressed and wishing I had
them as a student and in those years of working
with them as a show sponsor I’ve been equally
impressed at how they’ve focused on production
and constant improvement of visual stimulating,
fun, challenging, hands-on, and interactive
content.
For instance, Brilliant’s new Everyday Math
course takes you through foundational subjects
with their trademark interactivity.
A lot of people have struggled with fractions,
but when you approach them in a visual way,
they make a lot more sense.
With Brilliant, you can learn at your own
pace, learn on the go, and learn something
new.
To get started for free, visit brilliant.org/IsaacArthur
or click on the link in the description, and
the first 200 people will get 20% off Brilliant's
annual premium subscription.
So we’re into May now and we have a lot
of episodes ahead.
As a reminder, this month’s Livestream Q&A
will instead be held at the International
Space Development Conference, and will broadcast
my talk there, though at our usual time, Sunday
May 29th, at 4pm Eastern, and I hope you can
join us then, on the livestream or in person
in Arlington, Virginia.
I will also be a Keynote Speaker at this year’s
Biocene at the Ohio Aerospace Institute in
Cleveland, May 18-20, and I will be talking
Friday Morning, May 20, I’ll leave a link
to register in person or virtually for both
events in our episode description.
Before then we’ve got some episodes and
next week we’ll ask about how we might keep
an atmosphere on Mars by making a Magnetosphere
for Mars.
After that we have our Scifi Sunday episode,
Lost Space Colonies, and what would happen
on them, then we’ll be launching into new
miniseries looking at finding and exploring
distant worlds, Surveying for Habitable Interstellar
Star Systems, on Thursday May 19th.
Then we’ll close out the month with a look
at Dark Sky Stationa, Stratospheric Satellites,
and Ultra-Low Orbital Infrastructure.
Now if you want alerts when those and other
episodes come out, make sure to subscribe
to the Channel and hit the notifications bell,
and if you enjoyed this episode, please hit
the like button, share it with others, and
leave a comment below.
You can also join in the conversation on any
of our social media forums, find our audio-only
versions of the show, or donate to help support
future episodes, and all those options and
more are listed in the links in the episode
description.
Until next time, thanks for watching, and
have a great week!
