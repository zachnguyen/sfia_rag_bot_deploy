Living in a technological civilization, it
is rather hard to think of a bigger brain
as a disadvantage, but as we’ll see today,
that is often the case.
So today we will be wrapping up our look at
Great Filters of the Fermi Paradox, those
conditions that are thought to act as major
hurdles to technological civilizations arising
in the Universe.
Previously we’ve looked at those conditions
for the planet that might make intelligence
uncommon, but today we want to look more at
the evolutionary steps to get to human level
intelligence and also the hurdles you need
to pass once you have that to get to true
technology.
Now for our purposes today, when I say intelligence
I am principally referring to human level.
We often use the terms sentience or sapience
to further subdivide levels of intelligence,
but the definition of sentience is terribly
vague and can be interpreted to include pretty
much anything with sensory apparatus and a
basic brain, whereas sapience is not really
in the common lexicon and essentially means
wisdom.
Since wisdom is trait often lacking in some
humans, and also a trait not necessarily required
for technology, I’m disinclined to use that
either.
So we’ll be sticking with human-level intelligence
and I think context will make it fairly obvious
when I mean any intelligence at all or human
level.
As always with the Fermi Paradox, since it
is the question of why we can’t see or hear
any aliens, it is also important to remember
that at the moment that only means aliens
with modern technology or better.
Our brains are more or less identical to the
folks who first figured out agriculture and
metal working, but we could not detect such
a civilization ourselves right now so if it
turned out going beyond that point was very
uncommon, you’ve got your answer to the
Fermi Paradox right there.
And it might be uncommon, we’ll spend the
last section of the episode discussing that
and challenging our general assumption that
once you have tool and fire use and sufficient
brains you inevitably transition to high technology.
But before that, let’s consider some key
steps of evolution needed to get to more or
less modern man.
There are quite a few of them, and even those
which have happened more than once so that
we cannot view them as a fluke, often took
a lot of time, which is another key point
of the Fermi Paradox.
The Universe is young, and the period in which
life could have plausibly existed is shorter
than that.
The odds of a given solar system having life
should generally tend to increase with time
too, except where changing conditions could
make a planet uninhabitable, such as the sun
it is around growing hotter over time and
sterilizing it.
A key aspect of the Great Filters approach
of the Fermi Paradox is that it is not about
if a planet might eventually support a technological
civilization, it’s about whether or not
they already do, and currently do, for a given
value of current since light and signals takes
a long time to travel.
So as an example, over a long enough period
of time, any given planet that had basically
identical initial conditions as Earth ought
to produce life, but we do not know what those
conditions are or what the mechanism is, in
any rigorous sense.
If we assume it is underwater thermal vents,
a planet with less of them should take longer
on average to produce that first abiogenesis
event.
And yet we do not have a good fix on when
life began on Earth.
The most optimistic model is 4.28 billion
years ago, while the oldest undisputed life
is at 3.5 billion years.
That is between 130 million years and a full
billion years for life to arise after we had
oceans, and for my part I have to raise an
eyebrow at some people who refer to that time
duration as ‘almost instantaneous’.
We are also making a big assumption to think
that is an average.
That is justified by the mediocrity principle,
which tells us that when we only have one
example of something, or even just a few,
we should assume that example is fairly normal.
But that’s just a generalized approach to
take in ignorance.
If you land on an isolated island and the
first person who greets you is wearing a hat
and carrying a pair of binoculars, it’s
a good idea to assume that is normal here
until you meet other folks.
Except that the binoculars probably are the
reason that person was the first one to greet
you.
Nonetheless the Mediocrity Principle is usually
a good first approach.
Not, however, when you are dealing with a
circumstance that has the word Paradox in
it.
We label stuff that way when the available
evidence makes the situation seem impossible
or freakishly improbable.
At that point you want to challenge any circumstances
where you haven’t got a lot of data and
are making assumptions.
We already know abiogenesis is improbable,
horribly improbable, because the requisite
chemicals and conditions existed in the trillions,
interacting constantly, and still took a long
time to go from that to alive.
A man who wins the lottery on his tenth ticket,
with no other data, thinks that is normal
enough and will by the Mediocrity Principle
assume most folks win after about that many,
and if winning the lottery comes with having
to go someplace to pick up the prize, most
folks he meets there will be big outliers
themselves too.
It’s only when you actually know the number
of winning and non-winning tickets that you
truly understand the odds.
Before that it’s just guessing.
So the question is really just:
“Is this abiogenesis event so freakishly
improbable it takes countless quintillions
of atoms a hundred million years to produce
a basic lifeform, or just a bit more freakishly
improbable so that it would normally take
that sample a trillion years to cough up a
lifeform but we lucked out early?”
Up until the moment we can model the probabilities
for a given solution producing a basic lifeform
we can’t say, and there are probably many
thousands of valid most basic life form configurations
and a wide spectrum of specific environments
they can emerge from.
We haven’t got a clue if abiogenesis happens
on short timelines in virtually any plausible
chemical soup or was a one in a million event
to have occurred here that fast and should
be a great filter all on its own.
I will categorize it as a possible Great Filter,
but we will otherwise bypass it today.
One other thing to keep in mind though, is
that while we have a window for life to have
emerged that’s about 800 million years wide,
from 3.5 to 4.28 billion years ago, if life
did arise on the early end of that, it means
the next big steps took a lot longer, making
them much better filters.
Unicellular life, initially in the form of
bacteria and archaea and later joined by the
Eukaryotes, ruled alone over the Earth for
billions of years before multicellular life
came about 900 million years ago, but even
that immense timespan does not do justice
to the sheer generational scales involved.
Some bacteria can multiply once every 20 minutes
in ideal conditions, but let’s be conservative.
Say they would have multiplied only once every
5 days.
That is still 2 trillion generations to the
dawn of multicellular life, which is comfortably
more than the 1.5 trillion stars in our local
group of galaxies!
That doesn’t even count the number of actual
organisms, only the number of generations.
Mammals multiply considerably slower, in the
order of months at the quickest and a decade
or more at the slowest, and we have only had
320 million years since our early Synapsid
ancestors began to multiply.
Looking at generations alone, mammals are
effectively nothing more than a blink of the
eye when compared to the unicellular realm.
We are dwarfed into obscurity when we further
compare the sheer population sizes involved.
So even though multi-cellular organisms appear
to have evolved separately on many occasions
- leading us to reasonably believe this is
not a particularly improbable event - it’s
worth remembering that still was less probable,
in terms of raw generations and population,
than every other mutation mammals have experienced
combined.
Some mutations did result in revolutions,
even amongst the unicellular organisms, like
the development of photosynthesis in cyanobacteria
2.1-2.7 billion years ago that ultimately
changed our atmosphere to become Oxygen-rich.
This provided a vaster energy source serving
as the bottom of the food chain, and a much
bigger total population.
And that speeds up mutation by allowing more
events.
Another big one was being able to share mutations
through viruses and plasmids allowing for
the sharing and swapping of genetic material.
When organisms can’t swap DNA then you can
have billions of mutations going on but only
in series.
Another big step forward was sexual reproduction
about 1.2 billion years ago, that sped things
up too.
In a way, we can think of that as when evolution
really kicked into high gear: two critters
of fairly similar DNA classified as the same
species, rather than every organism simply
self-dividing and diverging from those around
it, and that took about 2 to 3 billion years.
Had it taken even just 4 billion, our own
Sun, which is constantly getting warmer, might
have rendered the Earth increasingly barren
and eventually uninhabitable before we arrived.
So this entire sequence of events could be
seen as a pretty strong filter too.
Yet it doesn’t particularly interest us
today either.
Our focus is more on intelligence.
That can be a fairly arbitrary term, and to
make things worse we also have good reason
to believe muscles, neurons, and even brains,
for a given value of brain, have evolved separately
more than once too, it’s not something limited
to vertebrae.
Indeed, since many plants demonstrably react
to their environments, the only reason we
can say plants won’t evolve brains is because
they simply provide too much cost for too
little benefit to them.
That though, is a big thing to remember.
Most tiny animals have way more generations
than we do connecting them back to our common
ancestor, and in that sense can be seen as
more evolved.
They reproduce faster and in larger numbers,
both in terms of litter size and often total
population.
Your cat is more evolved than you are; indeed,
chickens, rats, and rascally rabbits even
more than they.
Yet they’re not that smart and, very generally,
the faster and more numerous a species reproduces,
the dumber it is.
You nod now, brains are big energy investments,
take a long time to grow, and that is true
and important, but at the moment think of
it in the sense of catching up.
Some species evolved a cool new trait that
makes it breed slower and in fewer numbers,
and all its rival species have a lot of room
to narrow that gap.
It’s been around a thousand human generations
since our mutual ancestors started keeping
cats and dogs around, but for them it’s
been more like ten thousand generations.
Add to that, we have been bootstrapping at
least dog evolution during that time and often
breeding for intelligence.
Chimpanzees at least - one of our closest
relatives and competitors for intelligence
- do take a long time to reproduce, pretty
parallel to humans, and again that comes from
the long development time for brains, and
most of the other critters that are demonstrably
smarter than cats or dogs have generations
much longer than a year too.
That’s one of those first markers about
intelligence, it is an expensive investment,
not just to run a big brain, but to grow one
in the first place.
It takes a long time while the young critter
in question is highly vulnerable and realistically
cannot fend for itself.
We can’t rule out that some alien might
be human-level intelligent yet use the strategy
of laying thousands of eggs and leaving them
to fend for themselves, but it does seem quite
unlikely.
More important than that is recognizing that
higher intelligence is not, as we usually
think of it, automatically beneficial.
Quite to the contrary, even ignoring the upkeep
cost in growing and maintaining a big brain,
it has some big disadvantages.
I can toss you a ball and you can catch it;
so can your dog.
Whether you realize it or not, it took an
insane amount of brainpower to pull that off.
What we think of as the conscious mind is
a tiny little iceberg tip poking out from
a massive supercomputer below the surface.
And in many ways it’s less of a peak than
several, acting a lot like a committee.
A basic reactionary brain is very helpful,
it reacts fast and gets stuff done.
Your conscious mind is more like a committee
discussing everything.
Picture someone feeling thirsty and grabbing
a sip of water, versus some huge committee
meeting to discuss water safety standards
and a year later releasing a 300 page report.
That big brain is wonderful for developing
complex and abstract strategies, and thus
science and technology and poetry.
But it’s not great for dealing with a lion
jumping out of the bushes to eat you.
Simple fast action is typically the best,
and a big brain that likes to stop and ponder
stuff can get you killed - and in fact, it
did get us killed a lot back in the day.
We did not evolve as an apex predator and
if you told just about anyone from pre-modern
times that we should be worried about lions
or wolves going extinct, that notion would
be so bizarre to them they’d probably assume
you meant to say we should be worried about
it not happening fast enough.
Now it would be silly to say, on a planet
dominated by human technology, that bigger
brains don’t help with survival, but there
is a threshold, and probably a fairly narrow
maze to navigate in evolving a brain capable
of complex abstraction and problem solving
without it becoming a survival hindrance.
Tons of critters have big brains, most of
them have had them for more generations than
we’ve had our human or near-human level
one, so either the next couple key steps requires
a lot of improbable flukes or most of the
time any improvement isn’t an actual improvement
from a survival perspective.
We still know so little about intelligence,
human or animal, that it is impossible to
call this transition zone an improbable one,
but it is my own best guess for the biggest
filter on going from animal to human intelligence.
Relatively large brains have been around a
long time, and in species that have had many
generations, so simply getting a bigger brain
itself is no problem.
It’s getting one that doesn’t become a
survival threat, and when you consider the
sheer amount of resources we have to pour
into a kid, or that chimps or dolphins or
elephants do, compared to even a rat let alone
an insect, we can see how that happens.
High intelligence and conscious thought are
often going to represent a fatal disadvantage
to a creature and a species, not an advantage,
and breeding slowly with huge inputs of resources
didn’t advantage humans much until we had
it for a long while.
There are so many occasions in the last couple
millions years where we barely clung on, rather
than dominating the ecosystem as now, keep
in mind most of the other folks in our genus
aren’t around anymore, and there’s no
consensus that we did any of them in, let
alone every species of them.
There’s a scifi novel by biologist Peter
Watts called Blindsight that explores this
in more detail.
He makes some very strong arguments about
how valuable intelligence and consciousness
really are in there, and I strongly recommend
it.
I don’t want to spoil it, since it is also
our SFIA August Book of the Month, sponsored
by Audible, and is essentially a mystery so
it’s hard to discuss without spoilers.
But if you didn’t find my arguments about
higher intelligence to be universally good
or particularly compelling, I’m pretty sure
his will do the job.
It definitely shakes up the conventional view
of intelligence and offers an interesting
solution to the Fermi Paradox.
Regardless, species have survival strategies,
and the big brain route requires committing
to a few: small litters, long upbringing time,
long lives, and heavy interdependence.
Lone wolf species are not well suited to benefit
from giant brains, too likely to die before
reaching maturity without protection, too
hard to benefit from specialization when you
need to be jack of all trades.
But just because you’ve broken that barrier
into a reasonably human-level brain doesn’t
mean the job is complete.
Once you’ve made that leap, something only
we have really done, doesn’t mean the job
is done.
In the two or three million years we’ve
been around, our crawl to technology has been
abysmally slow till maybe the last 10 or 20,000
years.
We got fire, very handy, but it took us a
long time to apply that to making ceramics
or metals.
In all that time before then, we had it used
it to stay warm, to keep predators away, to
fire-sharpen sticks, and to cook meat.
So imagine a species that had sharp claws,
thick fur, was an apex predator, and could
digest raw meat better than we can.
Fire doesn’t help that much, and the stuff
is terribly dangerous.
They will probably never invent metals or
ceramics because even if they do invent fire,
it is a dangerous device of little value to
them.
We evolved during a series of ice ages when
the planet was generally cooler than normal
and we ourselves came from a warm part of
it and don’t particularly have warm fur,
even when we were hairier.
Odds are pretty good that most species that
get to the big brain zone don’t really need
that, and that is the main reason you hang
around by a fire for protracted periods and
might ponder it and its other uses.
We think fire was invented possibly as far
back a two million years ago, but 600,000
years is the loose consensus for definite
regular use.
Definitive use for cooking only goes back
200,000 years, but it’s hard to say if that
might not go back a lot further.
Cooking food helped us digest it.
We actually have an awful digestive track
for an omnivore and we should assume that
is abnormal.
Digesting food you have already ingested and
not maximizing what you can get out of it
is a bit of weird oversight, possibly a very
fortunate one for us though, since it not
only meant we need fire to help with that,
but it might have been a big factor in agriculture.
More on that in a moment, but our crappy digestive
system might have been very fortunate.
So we already need a few unrelated mutations
– longer lives, longer maturation, bigger
brains, and a preference for tribes or clans
– to be able to truly take advantage of
high intelligence, and again the big point
of evidence for it otherwise being disadvantageous
is how many other critters have had decently
large brains as long or longer than us, more
generations evolve to catch up in the brain
race, and still have not done so.
It’s probably not that hard a mutation,
just typically not handy.
The octopus is an intelligent creature in
that it is good at problem-solving and can
learn and apply that knowledge.
Recent genetic evidence says that their intelligence
evolved around 400 million years ago.
Why then are they not the dominant species
having had such a long evolutionary head-start
on us?
Perhaps it comes down to them lacking those
traits I mentioned.
They are solitary, live in an ocean where
fire is not an option and have short lives.
Now we have the issue that most of our early
technology just isn’t that handy, particularly
if you don’t have hands.
A lion doesn’t really need anything sharper
than its claws for survival but would still
benefit from being able to hit a deer at range
with a sharp stick or get leverage by swinging
an axe.
But holding and swinging something is quite
hard without the right anatomy and actually
aiming to hit something at range with a stone
or spear is much harder.
It took us a very long time to make and improve
such things, and if they weren’t as beneficial
to us, even if they were somewhat beneficial,
it probably would have taken longer and maybe
never.
Someone might invent a paperclip in the absence
of paper, but it’s not exactly a device
that will awe the tribe and get passed onto
future generations.
Our tribes were not that big, they couldn’t
be, and couldn’t afford specializations
or knowledge retention that didn’t help
the tribe in an obvious way.
We have found that a lot of critters do prefer
cooked food over raw food, apes will usually
pick a baked potato over a raw one for instance,
when offered, so we don’t want to assume
you have to gain a huge benefit from cooked
food to do it, and it also helps you store
food.
Still, storing food is a pretty abstract concept,
most critters don’t do it and the ones who
do are not engaging in a learned behavior
that involves conscious thought, so it’s
not like a squirrel is going to think about
cooking food to store it like he does nuts,
and for that matter such critters usually
store foods that last longer without being
cooked.
The other thing about fire of course is that
it keeps predators away.
Not all predators, and alien predators might
be different.
What’s more, alien planets are often not
going to be well set up for fire.
I don’t mean because they lack a decently
dense oxygen atmosphere either, we covered
that in the Rare Earth Hypothesis conditions
last time.
You need an environment where stuff can get
dry, and a lot of planets might be way more
humid or rain more often too, or have much
faster plant decay.
Decent odds are one of our ancestors was sitting
on a nice soft bed of dry grass to be comfortable
while relentlessly banging some rocks together
to sharpen them and got fire that way, odds
are also good they didn’t have an epiphany
about its uses and this had to happen a tons
of times before anyone thought to use it.
Anyway, if you can make fires reasonably easily,
you can probably also use them to keep at
least some predators at bay.
Which is handy if you have predators who eat
you.
It’s awful though if you are a big apex
predator with great nocturnal senses.
Predators tend to fall into two camps, ambush
predators and pursuit predators.
A spider is an ambush predator, it waits till
something falls into its web.
Cougars are usually ambush predators too.
Humans are pursuit predators, we chase our
prey, and we are a sub-type of it called a
persistence hunter.
Your cat is a pursuit predator too; it will
stalk something then leap out and chase it
if it tries to flee, but not for long.
Humans keep chasing, we literally used to
chase our prey till it got exhausted and then
go kill it, that is how we could take out
giant wooly mammoths.
Something bigger than an elephant, which also
travels in packs, and is not terribly afraid
of sharp sticks.
We’re also the only primate that does persistence
hunting; we’re very good at it.
Humans are excellent at long jogging for hours
and we can get rid of heat fast, part of why
we can both support a giant brain, which gives
off a ton of heat, and benefit from fire to
stay warm.
We’d go startle a pack of animals and give
chase, they’d usually outrun us, we’d
catch up and scare them into running again,
we can do this all day.
We can make frightening noises, communicate
over a large distance by speech, set fire
to things to scare our prey more, and just
keep jogging after them till one breaks a
leg or literally runs itself to death.
And yes, lots of animals can do that, they
just keep going until they stroke out, humans
don’t, we pace ourselves and can literally
jog all day if in good shape.
Of course dogs helped a lot too.
Fire scares, but dogs warn.
They were good at alerting us when some predator
was nearby so it didn’t come in and eat
us, and they are pursuit predators too.
They’re good at finding smaller critters,
an extra source food, at tracking critters,
at scaring them away in the night, and also
handy for both harassing animals we are chasing
and transporting the carcasses.
Yes we used dogs as one of our original beast
of burden.
It’s even hypothesized that since humans
use eye contact followed by moving our gaze
as one of our most basic silent communication
tricks, and dogs are one of the few critters
that understand that trick, that it could
have helped a lot with our hunting.
Animal domestication is rightly considered
one of our big steps to civilization and that
did start with dogs, presumably those brave
enough to approach us, or let us approach,
but not so aggressive as to attack.
Keep in mind that’s fairly peculiar behavior
too, a lot of animals don’t even like to
come near their own species, let alone another
they’re not planning to eat.
Why did humans keep animals around and alive?
How many other species who also shared our
other characteristics would?
Would we have gotten civilization without
that?
Now of course to get civilization we needed
agriculture which means settling down in one
place, cats were very handy then since they
eat the vermin that were attracted to our
food stores and garbage.
It’s been suggested that a lot of the foods
we ate, and to put it bluntly, did not entirely
digest, grew in our waste, and we harvested
these when we’d come back to a campsite
the next year.
It also has been suggested that thousands
of years of gathering the things we got more
food value out of selectively bred them to
be easier to digest; a lot of those early
cereal crops weren’t very easy to eat nor
terribly nutritious.
Of course we also have fire-stick farming,
we are a bit of pyromaniac species and we
used that for hunting, but we probably also
noticed that when we torched a forest it tended
to come back as savannah grass plains that
a lot of grazing animals thrived better in.
So some places we did forest gardening and
others we torched the place and grew us grass-eating
herbivores.
Presumably at some point we figured out that
we could cut out the middleman and eat some
of those cereal grasses ourselves.
Many uncertainties remain, but needless to
say we eventually started hunting less in
favor of keep our meat animals around and
growing crops for them and us to eat.
This allowed permanent settlements and more
people, both of which are handy since the
latter allows more specialization and the
former means you don’t have to limit all
your possessions to that which you can carry.
I said early it took us a long time to go
from fire to ceramics and metal working, but
it is worth remembering that it is kind of
hard to drag an anvil or kiln with you every
day and the work you can do without those
is fairly limited and inferior.
So you get cities and specialists and eventually
writing so that you can pass knowledge on
to people who aren’t physically present
at the time and don’t have to remember things
our brains aren’t well designed for, like
exact numbers of how many cows Bob brought
into town last year and if he paid his taxes
on them, which is probably what most early
writing was interested in, not technology,
personal journals or literature.
At this stage we think of technology as fairly
inevitable, people clearly can pass technology
over great distances in both space and time,
and also clearly know its value.
Twinned to that, most talks of dark ages and
lost technology are 90% malarkey, the European
Dark Age is mostly a romantic myth made up
during later periods and what little truth
to it there is still ignores that chunk of
the planet is not the entire planet or even
a particularly large chunk of it.
It has happened of course, there was some
loss in the Dark Age and we’ve got examples
like the Indus Valley Civilization that clearly
got quite advanced, then just fell to pieces.
Yet by and large useful technology doesn’t
get lost, it gets lost because it isn’t
useful to people who have it at the moment.
Aqueducts didn’t get casually forgotten,
they just aren’t that useful in a lot of
places and circumstances, ditto giant buildings
composed of arches are a bit of niche application.
So we don’t want to assume civilizations
can’t lose technology and that once you
have it you become totally invested in improving
it.
Only maybe the last 10-20 billion humans alive,
out of maybe 100 billion who ever lived, have
been of the technology-addiction mindset,
and even that is probably being generous.
They knew technology was handy for all of
human history at least, that being defined
as the times and places we kept written records,
which did not include most of the planet until
relatively recently even compared to tiny
period of 4 or 5,000 years we had it at all.
Many of them just didn’t think on it much,
they had what they had and no one was going
around inventing new things constantly, but
some outright rejected it.
After Rome burned down, or one of the times
anyway, the one Nero may or may not have caused,
an engineer approached the Emperor Vespasian
with some devices that would make transporting
construction materials much cheaper.
Vespasian – who mind you was generally considered
one of the saner emperors – rejected it,
saying he needed to feed his commoners.
They needed work to eat.
Now this is coming from a Roman Emperor, guys
not generally noted for being concerned about
the common people and also coming from one
of the more engineering-oriented civilizations.
In that light, we probably shouldn’t assume
advanced technology was inevitable for humans,
or that every civilization with the talent
for it will pursue it to modern levels either.
Similarly, the Fermi Paradox is not actually
about detecting modern civilizations, but
ones that have gotten advanced further than
us.
We would have problems detecting ourselves
more than maybe 100 light years away, and
could miss ourselves even closer.
So we have to advance further ourselves and
of course we might abandon that path our destroy
ourselves first.
If most alien civilizations destroy themselves
at at our level of development, or shrug and
say they have enough technology, or if they
actually hit a brick wall on development,
then there’s no Fermi Paradox.
We would simply not see those civilizations
when we peer through our telescopes at them
unless they were right next door.
Now I’ve discussed before all the doomsday
options in one of the first episodes on the
channel, Apocalypse How, and we may revisit
them in more detail in the future, but we
usually bypass any consideration that we would
stop progressing technologically, if we were
alive.
None of us believe science is done yet, but
there it a bit of an article of faith implied
there.
If I said we’d know all we could learn of
science in another generation or two, everyone
would laugh and I’d join them, but we want
to avoid assuming there is always another
mystery and that every answer brings two more
questions, thinking that itself is a terribly
unscientific viewpoint.
We can hypothesize a time where we have learned
everything, or hit a brick wall on the further
development, and that could be inside the
next couple of centuries.
However, that doesn’t matter to the Fermi
Paradox unless that knowledge includes learning
some things we think are in reach really are
not.
No fusion power, no self-replicating machines
or nanotechnology, no extending people’s
lives or freezing them and waking them up.
Fundamentally if you’ve got those, even
just some of those, you can do interstellar
travel and shoot for Kardashev 2 civilization
status, and that does make the Fermi Paradox
real.
If not, if technology does hit a brick wall,
there is no paradox.
And I can say it, but I don’t believe it,
so the Paradox is real for me.
Now the last option there is that just about
everyone gives up on advancing technology.
That’s hard for me to accept too, and I
think for most of my audience as well, for
me, for us, the notion of turning away from
the technological path is something so hideous
that I can only regard it as essentially heresy.
Unthinkable.
Morally Bankrupt.
Cowardly.
Even Evil.
It would be the most absolute rejection of
so many of the ideals we hold as underlying
everything our modern civilization stands
for.
And yet, when I think of folks worried about
automation taking jobs, a concern I myself
share, I do think of Emperor Vespasian rejecting
a cheaper means of mechanical transport to
feed his people instead.
The obsolescence of occupations, such as took
place during the industrial revolution, and
is happening now with self-driving vehicles
and general automation, can also lead to disenfranchisement
of people, which has and probably will lead
to pitchfork riots.
If people associate technology with a negative,
they can intentionally turn from it.
There is also that other nagging background
concern when we talk about automation too,
that we might get automation so good it thinks
for itself and is smarter than us, and either
eliminates and replaces us or even if benevolent
just reduces us to overfed happy useless pets.
We’ll talk about artificial intelligence
and such concerns more next month, but I could
see a lot of civilizations looking at their
level of technology, whose fundamental purpose
is to make their lives better, safer, and
more convenient, and just saying “Enough
is enough, anything more sticks us too close
to a precipice someone might push us over.
I’d rather be inconvenienced than irrelevant
or redundant”.
I don’t see that happening often and have
difficulty imagine it happens every time,
that every civilization abandons technological
advancement and does do before getting off
their own home planet, but I think that argument
probably does happen every time and pretty
much has to happen at about this technological
level.
We shouldn’t rule that out; as it approaches,
folks, even those who are otherwise very pro-technology,
grow cooler and more hostile to further advancements
and decide to stop short of Artificial Intelligence
and any technologies that would make it too
easy for someone to make one, or make a tailored
virus or swarm of grey goo nanorobots or homemade
nukes.
I cannot see wiping oneself out as a Great
Filter, with the sole exception of some sort
of Suicide Pact technology that looks amazing,
is easy to develop once noticed, and invariably
kills everyone.
I also can’t see artificial intelligence
as any sort of filter, since it simply replaces
a species, same as we replaced Neanderthal.
But while I don’t find it likely, I could
see intentionally shutting down further tech
advancement as a possible last Great Filter.
Again I don’t think so though.
No, for my part, to summarize both this episode
and the two before it, I tend to think we
have an awful lot of hurdles and filters to
getting where we are now, and that almost
nobody ever has, and probably no one in this
galaxy or its nearest neighbors, maybe even
the whole supercluster.
I think the filters are done and probably
have been since we first started settling
down into those first towns that became cities.
I don’t think it was any one thing, but
I tend to suspect the two big ones are the
conditions for a planet to be plausibly able
to support civilizations arising, and that
final jump from smart ape to proto-human,
and having it happen to a species that was
improbably biologically configured to benefit
most from basic technology, where many others
would not.
Those are the only two genuinely unique things
we have, unless abiogenesis really does turn
out to be a super-improbable fluke.
A Planet with the right size and conditions
and location in time and space to nurture
massive biodiversity over very long times,
and critters capable of genuine abstract thought
in bodies and social structure very suited
to benefit from it.
We simply don’t know enough to say, and
perhaps that’s part of the appeal to the
Great Filter and Rare Earth approach for me,
it is the camp I subscribe to, but while there
are a lot of uncertainties and shaky reasoning,
it doesn’t seem fatally flawed in any way,
whereas pretty much every other solution I’ve
ever heard tends to seem that way.
We covered the rest of those in the Fermi
Paradox Compendium and we’ll look at more
of them in more detail down the road, and
we will try to give them a fair shake, but
to me the Great Filters seems the best candidate,
and if does not to you, then I hope by now
you can at least see why it appeals to a lot
of us when contemplating this topic.
Next week, we will be taking a look at interplanetary
civilizations with follow up on the Space
Warfare episode, Interplanetary warfare.
For alerts when that and other episodes come
out, make sure to subscribe to the channel.
If you enjoyed this episode, hit the like
button, share it with others, and try out
some of the other Fermi Paradox or Alien Civilization
series episodes, and don’t forget to check
out Peter Watts’ Blindsight, our Audible
book of the month.
Until next time, thanks for watching, and
have a great week!
