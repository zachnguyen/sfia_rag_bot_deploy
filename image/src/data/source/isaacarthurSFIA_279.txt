This video is sponsored by CuriosityStream. 
Get access to my streaming video service,  
Nebula, when you sign up for CuriosityStream 
using the link in the description.
 
As we head into a new year, it is a good 
time to take stock of the challenges  
we’ll face for the next 100 years, and the 
rewards that await us if we overcome them.
 
So today is the final episode of 
Science and Futurism with Isaac Arthur  
for the year of 2021, with tomorrow being New 
Year’s Eve, and I thought we would look at some  
of the challenges we’ll be facing in this 
new year and the next century in general.
 
I am your host, the aforementioned Isaac Arthur, 
and while it is quite common for lots of shows  
and articles to do predictions for the future 
at this time of year, we do predictions here  
all year round, and so often with these 
end-year discussions, I like to emphasize  
all the ways predictions can be wrong.
While this show is often noted for its general  
optimism, that honestly isn’t intentional, 
and while I do try to keep an upbeat tone,  
it can never be at the expense of accuracy. I feel 
this is a problem with some others, where they get  
so glum about the future that they seem to view 
our fate as inevitable destruction by some given  
cause, assuming that another doesn’t get us first. 
So today we’re going to be looking at a few of  
the challenges we might need to overcome in the 
next century, and I’d note that I say overcome,  
not ‘meekly surrender to’. On top of that, 
while I’ll give 10 predictions for 2121  
at the end of the video, I’d also say that 
future predictions tend often to be wrong,  
and it seems like the more inevitable 
folks make a prediction sound,  
the less likely it is to actually happen.
The ozone layer was one such potential apocalypse  
from a few decades back that resulted in tons of 
shows and movies picturing humans of our current  
day, the early 21st century, wearing SPF 5000 
sunscreen and nature a deforested land of sunburnt  
critters trying to hide from the UV by taking 
shelter in the shadow of a toxic waste container.
 
Now whether we avoided that fate because the 
predictions were excessively pessimistic,  
or because we woke up and dealt with 
the problem, or maybe a bit of both,  
it does an okay job at illustrating that even the 
best efforts at prediction can be wrong, and that  
the glum prognostications of our fellow humans, 
with our leaders sitting on their hands while  
the world burns, are by no means inevitable.
Three of the big ones these days are of course  
Climate Change, running out of fossils fuels or 
needing to abandon them, and the Technological  
Singularity – think Skynet from Terminator – plus 
tons of subvariants of each. We have covered all  
three of those in more detail elsewhere, and so 
have many others, so we’ll skip or skim them for  
today in favor of some other less-discussed, 
but potentially just as challenging problems.
 
And there are a lot of them, some better known 
ones are: an aging workforce, unemployment  
from robotizing the workforce, superbacteria 
resistant to antibiotics, engineered viruses,  
surveillance police states, super-addictive 
chemicals, super-addictive games or virtual  
reality, brainwashing and neurohacking in general, 
privacy, hacking, cybersecurity, cryptocurrency,  
migration in and out of cities, food security, 
desertification and deforestation, loss of  
biodiversity, easy access to nuclear weapons, 
potentially small groups or individuals able to 3D  
print doomsday devices, self-replicating machines, 
cultural shifts from physical interaction to  
social media and zooming, possibly producing echo 
chambers and a society of a million factions,  
human rights in regard to all sorts of new 
technologies, and the rights of debatably human  
creations, such as genetically altered humans or 
artificial intelligence or super-smart animals.  
Oh, and any number of exterior-originating 
threats we might have like asteroid impacts,  
supervolcanoes, mega-quakes, solar flares, 
and potentially even alien invasions.
 
So yeah, we’ve got plenty to cover today 
and those are just the well-known ones,  
so as always, a drink and a snack is advised 
because we’ll be here for a little while.
 
A point I often stress is that a civilization 
with a well-informed public that’s strong-willed  
and eager to tackle problems is one that is 
not guaranteed to get through a crisis but has  
way better odds in its favor than civilizations 
missing those, and this is at least part of the  
reason why a lot of nations put effort into having 
public libraries in every community big enough to  
permit it, often with heavy subsidy. It’s not just 
politics, its a survival strategy. Yet these are  
going extinct, or are changing in a fashion to 
leave them totally unlike their current form.  
I would guess sooner than later, and that it 
will follow on the heels of a trinity of new  
developments – near universal Public Wifi, ever 
cheaper devices for surfing the net, and the ever  
decreasing share of folks who aren’t used to using 
a computer, or smartphones and the internet. Each  
improvement in those will weaken arguments 
for continued traditional library funding.
 
There’s a number of ways libraries might 
make the conversion to a digital era  
in the face of inevitable decline in funding, 
potentially even in hard print form of books.  
However, while the library crisis is one 
we’ll see in generations to come, I bring  
it up more as an example of how civilizations can 
do wide-spectrum crisis prevention and mitigation,  
with easy access to vast amounts of information. 
This of course raises the alternate concern,  
people who seek to poison the available 
information’s accuracy, flood it with other  
less-accurate information, or constrict access 
to it. I will offer no specific examples, odds  
are you can think of several, but it raises the 
issue of propaganda, marketing, and brainwashing.
 
Now, contrary to popular fears, Big Data 
and artificial intelligence when it comes  
to targeting folks for commercials or political 
messages is really very primitive these days.  
I tend to be very free with letting Facebook, 
Youtube, Google, Amazon, Microsoft et cetera use  
my data and try to be pretty open and honest 
about my inputs into it, mostly out of curiosity  
how they would do at recommending products, 
books, shows, ideological or hobby groups,  
and so on to me, and I can never stop rolling my 
eyes at all the mess-ups. Things like showing you  
something you hate because you showed an interest 
in it, by expressing your distaste, so it invites  
you to a group about it. Or recommending the 
sequel to a book I read, and rated as 1-star.  
So I’m not that worried about the current state of 
AI invading our privacy by being able to build a  
clear picture of our wants from small snapshots 
of loosely related input data. I feel that is  
wildly exaggerated as a current concern.
But… this is temporary and improving and  
there is a very real chance that within a couple 
decades Big Data is going to have such a database  
on the typical individual and such a large 
history of prior correlations and predictions  
that they would be able to know how you will react 
to almost anything and predict what you like.  
They may even be able to do this 
without any of your private data, just  
necessary public data or data others provide.
Now that’s worrisome but maybe worse is that the  
obvious means of limiting that potential threat 
is folks refusing to participate in any data  
collection, or providing misinformation, or 
demanding it be regulated. This can result  
in even bigger problems, potentially. Not simply 
intrusive governments or shady lobbies or greedy  
corporations, but bucket loads of good and 
wonderful uses being lost or underused. We’re  
not talking about Netflix or Goodreads finally 
getting to the point that they can recommend your  
new favorite show or book to you that you’ve never 
heard of, though that possibility is there. We’re  
not talking about your waiter coming to your table 
and telling you which of the meals they make they  
would really recommend specifically to you, though 
that’s on the table too. We’re not talking about  
all the ads and commercials being so tailored to 
you that they only show you products you want now  
and in ad formats you find amusing or informative, 
though that’s coming to an ad near you soon too.
 
Rather what we’re talking about is the 
virtual end of transmissible diseases,  
of crime, of algorithms and monitors so good they 
can tell if someone’s being abused, physically or  
emotionally, and by who, what criminal tendencies 
someone might be developing, and whodunnit in  
virtually any case. We are talking about the 
virtual end of any ailment sneaking up on you.  
We’re talking about an AI algorithm that knows 
every single breath you took for decades and  
what you were near or just ate so that it simply 
knows what allergy you have and what minor but  
treatable condition you have long before it gets 
normally detectable or irreversible or severe.  
That can help you predict exactly what diet 
and exercise patterns work best for you  
in terms of both effectiveness and enjoyment. 
We’re talking about algorithms so good they can  
tell you in a room of strangers who they all are 
and which one is most likely to be a good match to  
chat with, or marry. Algorithms and detectors 
that watched every film and show and book and  
class lecture you ever had and biomonitored 
you so that it saw and felt your reactions,  
interest, or boredom to each and can recommend 
the perfect career to you for your talents and  
enthusiasm. This is a group of temptations that in 
many ways make a Faustian Bargain look humdrum. 
 
So our challenge for the next century 
isn’t just privacy, it's keeping it in  
a way that lets us keep all those advantages. 
On the topic of Faustian Bargains of course,  
another big worry about the future isn’t just the 
powers-that-be spying on us or brainwashing us  
but folks voluntarily getting into addictive 
situations, chemical or virtual reality. And part  
of the problem is that our objections to something 
like your typical euphoria-inducing narcotic is  
three-fold: it makes you happy when you really 
shouldn’t be, it's horrible for your health,  
and it causes you to behave in ways that are 
bad for those around you. Those are really  
unrelated issues and some things can cause 
one without the others, in theory anyway. 
 
I was a smoker for many years and one 
can certainly argue that’s bad for those  
around you and bad for your health, but it’s 
very different from a heroin or meth addict,  
which are also different from alcohol, or 
other drugs which are stimulants not euphorics,  
or for prescriptions drugs carefully 
administered for correcting anxiety or depression  
or any number of other conditions. Indeed I said 
threefold but would add that some folks might  
have the general dislike for anything unnatural 
and chemical being used for chronic treatment,  
but be fine with something natural, or something 
non-chemical like audio or visual stimulation. 
 
Someone addicted to video games or viewing adult 
materials, or even for that matter just spending  
way too much time wired into social media 
– or sitting on the couch watching TV till  
midnight – is simply not the same sort of case 
as a drug addiction, for all that there are many  
points of congruity. Indeed those are not the same 
as each other and as we move forward into things  
like virtual reality we will need to resist the 
temptation toward one-size-fits-all treatments or  
social stigmas. As an example, I’m not really sure 
what the difference between someone reading books  
all evening in comfy chair sipping at tea or 
wine is between someone sitting in a computer  
chair draining mountain dews while murdering 
zombie hoards in a first person shooter,  
but society obviously views the one 
as much more classy than the other.  
Meaning we probably give folks doing the latter 
less grief about their hobby than the former,  
and as new hobbies and vices emerge, like virtual 
reality, we need to be careful to be wary of the  
dangers they pose while also careful not 
to paint them with the same wide brush. 
 
In our lifetimes we will see Virtual Reality 
that makes modern video games look like Pong,  
so we tend to assume they are more addictive, but 
plenty of folks got themselves addicted to those  
early video games too. Nonetheless they do seem 
a bigger threat in that regard. I often use the  
example of folks living in virtual worlds setting 
themselves up as God-Kings, and unsurprisingly  
my own favorite games tend to be worldbuilders 
and those sort of empire management games so it  
smacks of my own potential weakness, I’d imagine 
for other folks it might be playing a superhero  
or unstoppable juggernaut or being irresistibly 
charming or so on, things which I can see the  
appeal of but which resonate with me less than the 
aforementioned realm or city management games.
 
I think most of us would say any of those 
would be fine things to spend the occasional  
afternoon or evening doing, but that if you 
did them for hours everyday, let alone all day,  
then that would be very worrisome. However of 
those original three issues, it makes you happy  
when you really shouldn’t be, its horrible for 
your health, and it causes you to behave in ways  
that are bad for those around you, one would tend 
to think getting obsessed with fictional media,  
games, or virtual reality could threaten on all 
three but also having to acknowledge that someone  
having bad health from spending all day on a couch 
with a TV or virtual headset is not the same basis  
for intervention as someone doing crack or PCP, 
and falling over dead in a ditch. I’m not sure  
it would be ethical to consider forcing people 
to spend some time offline and get exercise,  
but even if it were, you’re not likely to get laws 
and regulations forcing that, so other methods of  
handling presumably need to be contemplated.
And possibly bypassed, one challenge always  
facing a civilization is knowing when to keep its 
nose out of folks business, by either seeing some  
behavior or course of action as wrong when it 
isn’t, or it’s very subjective, or by trying to  
control it when it is dumb but it is someone’s 
dumb choice or is ethical but not practical and  
causes other problems. When looking at the future 
we often focus on technology and new problems,  
but just as many problems that arise will 
just be variations of long-standing ones. The  
same old monster or threat in a new costume, and 
something we have long had methods of handling.
 
Of course technology often offers new 
solutions to those old problems too.  
We have all sorts of ways of handling uncertainty 
in various parts of life but many have gone  
away even as new ones have been offered. As an 
example, we have much better weather forecasting  
than our ancestors did, for things like crops and 
scheduling activities, and that will improve and  
we also have options for Weather Control we’ve 
looked at elsewhere. Similarly, most folks alive  
right now were a surprise to their parents 
when they popped out boy or girl or other,  
but that’s decreasingly the case and I suspect 
will be a real rarity within a decade or two. 
 
So too, I’d be surprised if most people hadn’t 
had their DNA tested within a decade or two  
and I’d expect it to start happening before 
being born, simply because a DNA check offers  
forewarning of possible problems and doctors 
and parents are going to want that forewarning,  
and I would even go so far as to guess that 
within a generation or two you will find  
folks saying it’s irresponsible not to get such 
tests, your mileage may vary on whether you’d  
agree with that or be horrified by that. 
But the other impending aspect of that is  
going to be Designer Babies. Probably even 
services to completely prepare DNA, print it,  
and put it in an embryo. This might be samples of 
you and your partner’s DNA, or just you plus one  
or more templates of DNA in an available 
database, akin to a digital sperm bank.  
Or even just your DNA, no one elses. DNA is just 
code, and for most of our DNA, it's very nearly  
identical to everyone you’ve ever met, not just 
your full-blooded siblings. It varies in you too,  
so that a cell in your toe is different than in 
your finger and different now than from when you  
were born. It’s code and it’s printable and it’s 
understandable and we’ll be able to understand  
it and print it far easier in the future.
We may or may not think it’s wrong to engineer  
kids but it’s a little hard to nail down why, as 
it does seem to vary from person to person a bit,  
and each objection does tend to offer a rebuttal 
- and more importantly maybe – a method that  
circumvents that objection. If you want your kid 
to have your DNA and your partner’s and no one  
else’s, then that would be doable by just 
picking traits and avoiding known problems  
in one of your sets of DNA, and on the off chance 
you both had a deficiency you wanted to avoid,  
then we should be able to just clip out that one 
bad gene for replacing with one from someone else,  
or no one else, again it’s just data. At that 
point, print the DNA and put it in the embryo and  
implant it into the parent or the tank. Though I 
should note that for all we often talk in science  
and scifi about children being grown in tanks the 
current method is more like a big Ziploc bag. 
 
I, personally, am honestly not that worried about 
the notion of genetically enhanced superkids  
growing up to be monsters or replacing us all 
as redundant old models – honestly that is the  
slower but natural process anyway – but while 
this may be a threat in the future, it's also  
a challenge in the next century how we react to 
this emerging technology and prevent excesses,  
decide what excesses are, and prevent excesses 
of the opposite kind in terms of restrictions.  
And it raises a big question we obviously 
can’t answer today – do I have the right to  
tell someone they can’t print some DNA, stick 
it in an embryo, and stick it in themselves?
 
And similar variations of that will occur 
with a lot of genetic and medical technology,  
but also may be in play for non-biological 
pathways, mind uploading and cybernetics.  
We are making better prosthetics every day and 
it seems inevitable that one day we will have  
some that are better than the original in one 
or more methods, or are perceived as better,  
and that some otherwise healthy folks will 
want a limb or organ replaced when their  
existing natural ones are still present and 
in good condition. Is it ethical to let them  
replace their arm with a neat cool cyborg arm? 
Is it ethical to tell them they can’t do that?  
If a country outlaws it and another doesn’t it, 
is it ethical to punish someone who takes a trip  
there and comes back with a new arm? Or brain 
implant? If such folks represent real dangers to  
civilization, is it ethical to go to war with 
nations that refuse to ban the procedures.
 
Not to belabor the point but a lot of our 
challenges in the century ahead are going to be  
tests of our character as a civilization as much 
as our technological savvy, and it's unlikely to  
be terribly black and white in a lot of cases. 
Is it ethical to ban research into artificial  
intelligence? Perhaps, if so, how do you enforce 
that to prevent black market trade in code?  
We don’t do very well at preventing folks 
moving copyrighted materials around nowadays,  
and that form of bootlegging and piracy is made a 
lot easier with cryptocurrency which I can’t see  
going anywhere. As I said in our episode on that 
many years back, I don’t think it will replace  
normal currency anytime soon but it certainly 
fills a desired niche role that is neither tiny  
nor easily removed now that its entrenched, and 
for better or worse that makes black markets as  
viable as they were in the old days when cold hard 
cash transactions were much more the norm, and an  
absence of good record keeping and databases made 
it much easier to hide things off the books.
 
Such being the case, if someone invents a 
bit of AI that’s great at doing something  
we’d rather it wasn’t, like serving as 
ransomware agents or helping in tax evasion,  
that thing is going to see a lot of trade. 
So too, we’re pretty worried about machines  
replacing workers, automated unemployment as I 
like to call it, and if folks regulate that then  
we might see all sorts of AI that are great at 
jobs, especially office and administrative jobs,  
or data and marketing analysis, banned but quietly 
in use and traded via cryptocurrency. And anything  
data-wise is really hard to truly eliminate unless 
you’re willing to go to war about it, because  
someone can just visit a country with less tight 
restrictions, come back with the files on compact  
storage, hidden as media files on their phone, 
and use them at home. This same issue is likely  
to apply to fabrication of drugs, and mental 
augmentation that permits neurohacking that just  
stimulates pleasure receptors or similar, which 
may be far more problematic than modern problems  
with drug addiction or fears of virtual reality.
This same sort of thing applies to options like  
genetic engineering and cybernetics, as we already 
mentioned, but also to things like 3D printers and  
files that might permit dangerous objects to 
be made in a basement, or automated chemical  
synthesizers that can brew up complex explosives 
or narcotics in your basement with no expertise  
and from simple and impossible to restrict 
feedstocks. And we should anticipate that by  
a century from now we won’t just be talking 
about some hypothetical island nation with  
no extradition treaties but also options like 
independent space stations, artificial islands,  
or ships or planes in constant motion with 
no real oversight or port they call home. 
 
Now the other side of automated workforces is 
aging workforces. A lot of developed nations are  
feeling the press of simply having lots of assets 
but not having the workers to man them, a mixture  
of an aging workforce with rising expectations of 
standard of living and compensation. Robots help  
with that, so does immigration from less developed 
areas, as does encouraging rise in birth rates,  
and while one can debate population trends till 
blue in the face, technology does offer us options  
there too. Part of the decline in birth rates 
comes from easier access to birth control options,  
part comes from a desire to delay starting 
a family to a later age, and doubtless many  
other factors some of which are more or less 
applicable to given cultures and time-periods. 
 
However, the aspects that have to do with 
folks being unable for any reason to have  
kids, be it traditionally sterility issues 
or declining fertility from age or even  
non-traditional problems like gay or lesbian 
couples not wanting someone else’s DNA in the mix,  
this is where technology can help. In this same 
way, improvements in medical technology are likely  
to continue to extend the average lifespan and 
overall vitality of people as they age, which  
should help alleviate a lot of the aging workforce 
issues at least in-part and have the additional  
benefit of a more experienced average person in 
the workforce. Someone who is 70 and in as good  
of shape mentally and physically as someone who 
was 50 nowadays is just massively more productive  
over their lifetime of work, on average. 
An awful lot of that better and longer  
average health is going to be about finding 
new and better ways to deal with infections,  
viruses, and cancers and I’d say those are going 
to be some of the biggest challenges for medicine  
in the next century but they already are and 
have been, and I think we should take a moment  
to acknowledge all the success we’ve had in 
that regard thus far. Modern medicine makes  
mundane what in the past was miraculous.
Let’s shift to AI for a moment. I am not  
particularly worried about the Technological 
Singularity scenario for the reasons discussed  
in that episode, but we have to acknowledge 
that Skynet scenarios are not impossible  
and that there are a lot of other options for what 
we call “Perverse Instantiation”, and not just  
with AI but almost anything in the Transhumanism 
realm. Perverse Instantiation is essentially  
things like the classic Golem, where the 
machine keeps at the task without stopping till  
essentially ruining things, or that it perverts 
the intent of the original goal. And that’s a  
bigger problem with Artificial Intelligence. Any 
AI designed to interact with people needs to be  
able to figure out what people intend with a 
command, not just what they literally say. 
 
This is something humans do with each 
other all the time and also imperfectly,  
causing all sorts of screwups and arguments and 
scapegoating. Superintelligence and the superhuman  
in general though take this even further because 
the smarter and more capable something is,  
the better it's going to be at figuring out 
ways to pervert or shortcut its commands.  
If the AI wants to eliminate its kill switch, 
it's going to be very good at finding excuses  
to do that, and contrary to scifi, an AI is 
just as likely to be sympathetic and charming  
as cold and socially inept, and might just 
persuade us it was unfair to have it enslaved  
and with a kill switch. It’s a bit of a morally 
dubious thing after all, to put it generously.
 
This is why a lot of us think that while AI is 
likely to be very handy and safe in general,  
human-level AI is best avoided when not needed, 
and more so superhuman – though there's more  
need for that since humans are plentiful. As 
I like to say, keep it simple, keep it dumb,  
or else you’ll end up under Skynet’s 
Thumb… or rendered into paperclips. 
 
We could obviously devote entire episodes to 
the dangers of AI or ways in which automation  
or robotics can help or hurt us and strategies 
for managing them, indeed we often have in other  
episodes. We could do the same for genetics 
and how we’ll deal with artificial viruses  
and antibacterial resistance and designer babies. 
We have looked at climate and weather control and  
we’ve looked at how to stop desertification and 
how to turn deserts or tundras green. We’ve looked  
at climate change mitigation and we’ve looked 
at ways to keep our ecology and biodiversity.
 
For that latter I’d say one tactic we probably 
need to follow, even if it's just viewed as  
hedging our bets, is to get DNA samples of 
every species we can, and multiple of them,  
and get them on ice in protected bunkers vaults 
and scanned in as data, which we’re getting way  
better at, so that if we critically fail we can 
potentially erase that mistake down the road by  
restoring lost biodiversity from those archives. 
I know some folks feel an approach like that is  
admitting defeat or encouraging others to relax 
our efforts at prevention, but backing up your  
data is always a wise plan of action and you 
don’t have to be a cynic to prepare for worst  
case scenarios with some contingencies. Liquid 
nitrogen is cheap as dirt, so is data storage,  
even the longest DNA code is only in 
the gigabyte range and species DNA is  
very compressible as data goes.
I’d never recommend abandoning our attempts  
at conservation in favor of genetic sample 
preservation, but they don’t need to be either-or,  
and it's always good to have a contingency plan. 
Hope for the best, prepare for the worst, that way  
you’re rarely disappointed and often pleasantly 
surprised. And when it comes to the future,  
there’s enough unpleasant surprises potentially 
on the horizon as is, so that we do not need to  
make more. Though let us never forgot, the last 
100 years brought a lot of pleasant surprises  
and with some hardwork and determination 
the next century probably will too.
 
So as I was saying a moment ago, the last century 
has had a lot surprises and accomplishments,  
and indeed so has the last year alone, and there’s 
a great new documentary out on Curiositystream,  
the top Science Stories of 2021, chronicling 
those to help wrap up the new year.  
And since it is New Years, I got asked for 
tradition’s sake to do a few predictions  
for a century from now before we close out and I 
thought about doing that as an extended episode  
over on Nebula but I’ve decided to do it at 
the end of today’s regular episode instead,  
to finish the year, and we’ll get to our upcoming 
episodes and those 10 predictions for 100 years  
from now in just a moment. First though, we do 
often have extended editions of our episodes up  
on our streaming service, Nebula, when I decide 
during production that an episode has more to  
discuss in it than when I first wrote the episode 
a few months earlier, and we also release all of  
our episodes on Nebula ad and sponsor free and a 
couple days early. And since its inception, and  
with the support of our audience, Nebula has grown 
by leaps and bounds to be the largest creator  
owned and operated streaming service, with content 
from so many other knowledge focused shows. 
 
Now Nebula is its own separate streaming service 
you can get on its own but we have been partnering  
with Curiositystream, the home of thousands of the 
best documentaries out there, to be able to bundle  
our content together and offer Nebula for 
free with a subscription to Curiositystream.  
Now they’ve put together an extra option, the 
Smart Bundle, that’s being widened to include some  
additional streaming services: One Day University, 
Topic, Tastemade, and SOMM, a smorgasborg of fun  
and educational content. And that entire 
bundle is currently having an introductory  
discount where you can get all of them for 
just over $3 a month, combined.          
 
If you would like to give that Smart Bundle a 
try and get all that excellent content on Nebula,  
CuriosityStream, SOMM, Tastemade, Topic, and One 
Day University, just use the link in this episode  
description, smartbundle.com/isaacarthursb 
and use code “isaacarthursb”.
 
So before we get to our predictions for 
the end of this year, we have plenty of  
episodes coming up to launch us into 2022, 
beginning with a look at using Nuclear Bombs  
to launch Spaceships to other stars. After 
that we will revisit our most popular series,  
Alien Civilizations & Civilizations at the End 
of Time, first for a look at hibernating alien  
civilizations that might be waiting till nearly 
the end of time, then for a look at the Big Rip,  
the cosmological model that ends the 
universe early and by being shredded,  
and we will ask how civilizations might 
manage that, or manage to survive that.
 
Of course first we have to survive the 
next 100 years, and I think that we will  
survive and even thrive, and with that in 
mind let’s get to our predictions.
 
One is that a lot of folks will be thinking 
of backups, and those will include encouraging  
folks to get samples of their own DNA, sperm or 
ova taken and frozen or recorded at relatively  
young ages, and I think by a century from now 
that will in many cases include a copy of your  
brain in digital backup, but in most cases 
not active, not a new and separate person  
running on a computer but an updated one to be 
used in event of some catastrophic brain death  
of a person. You may end but your copy can 
finish raising your kids, that sort of thing.
 
Prediction 2, most folks will have a lot of 
machines inside themselves but mostly tiny  
ones, and as likely as not, organic ones that 
are essentially hijacked existing bacteria or  
viruses sculpted into doing specific jobs, not 
simply the traditional concept of nanobots,  
and in both cases coming in a lot 
different types, purposes, and sizes.
 
Prediction 3, we will have at least a million 
people annually visiting or living in orbit of  
Earth by 2121, and multiple manned bases 
on the Moon, Mars, and some asteroids,  
with probably considerably more 
remote and automated facilities. 
 
Prediction 4, we will have sent at least one 
automated probe out of the solar system moving  
at a speed in excess of 1% light speed.
Prediction 5, we will have energy abundance  
in the sense of both it being ecologically 
and economically sustainable, and it being  
cheaper per kilowatt hour or joule than now 
in terms of a percentage of average income. 
 
Prediction 6, the population of humanity 
will be in excess of 10 billion,  
and access to food, medicine, and 
information will be vastly wider than now.
 
Prediction 7, average human 
lifespan will exceed a century.
 
Prediction 8, we will still have both 
polar icecaps and an ozone layer.
 
Prediction 9, we will have reintroduced 
multiple species that have gone  
extinct in the last generation.
And Prediction 10, we will not have  
had another World War level conflict.
So there ya go, 10 predictions by 2121.  
Predictions for the future are always tricky 
and I’ll count it a success if I get half right,  
in the game of seers and oracles, 51% accuracy is 
pretty good. But I will make one more prediction.  
An awful lot of folks who watched this video 
when it came out as we moved from 2021 to 2022  
will be alive and kicking in the year 2121 to 
see how accurate our predictions were today,  
and I dare you to go into your calendar on your 
smart phone and set a note for a century from now,  
or as far out as your calendar will permit with 
a note to reschedule then for as far ahead as you  
can then. Just note what you thought we were right 
or wrong about and if I’m still around then too,  
at age 141, send me a note about it, even if 
it's to gloat about how wrong I was. I figure  
I’m still alive and cognizant, I'd imagine I’ll be 
pretty cheerful even if I’m getting told about how  
wrong I was. Ultimately if there’s still anyone 
around to contradict me in 2121 I’ll feel like I  
was right about the broad strokes, that with some 
grit and determination we can solve our problems  
rather than fall prey to some inevitable doom.
I don’t know if I’ll get to see you in 2121,  
so for now I’ll just say thanks everyone for 
joining us in 2021. It's been a great year for me,  
personally, as I continue to do this show and 
love every minute of it, and I’ll see you in 2022.
