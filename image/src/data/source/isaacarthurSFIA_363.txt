This episode is sponsored by audible.
I think we can all agree, 2020 has been a
heck of year.
Hopefully the rest of the century will go
smoother, but if it doesn’t, 
how will we survive it?
Nuclear Weapons, Viruses, Artificial intelligence,
Technological Singularities, Asteroid impacts,
Earthquakes, Super-Volcanoes, 3D Printing,
Automated Factories, Grey Goo, Genetic Engineering,
Unemployment, Virtual Reality, Deforestation,
Desertification, Changing Climates, Invasive
Species, Antibiotic-resistant super-Bacteria,
Ultra-Addictive Designer Drugs, Solar Storms
and flares, Designer Babies, and Uplifted
Lions and Tigers and Bears, oh my... the future
is gonna be quite a challenge.
Welcome to Science and Futurism with Isaac
Arthur, and I am your aforementioned host,
Isaac Arthur.
In general I tend to be known for my optimism
about humanity’s future but a point I always
feel obliged to bring up when accused of being
optimistic is that it is not optimism that
arises from being unable to see all our problems
but from being able to see a lot of potential
solutions too, and that we can meet and overcome
these challenges.
We have a lot of challenges coming up in the
next century, many of which could cripple
or even obliterate us, and what we’re going
to do today is go through those, ask how we
can avoid the pitfalls, and how we can mitigate
the damage or recover if we still trip into
one of these potentially cataclysmic scenarios.
Of course normally the one thing guaranteed
about surviving the next century is that you,
personally, will not.
So we tend to mean our descendants, and as
such will but a special focus today on genetic
engineering of humans and children.
However it is also possible you and I might
still be alive and kicking in the year 2121,
from life extension technology, and that technology
offers both an obvious benefit and many challenges
we’ve looked at before in our Episodes on
Life Extension, but there is likely to be
many we probably can’t foresee.
It’s generally true that if you can foresee
a problem you can avoid it, or at least handle
it better.
There are some exceptions, but by and large,
forewarned is forearmed and that’s what
we’re doing in today’s episode.
However what often gets us is what seems obvious
in hindsight but was simply not predictable
in advance, what is often called a Black Swan
Event.
There are tons of examples of these, but unforeseen
uses and consequences of new technology tends
to provide the most common examples.
We could and did predict the internet, but
we couldn’t have predicted social media
and the exorbitant list of uses it has come
to fulfill, even though they seem obvious
now.
We foresaw folks using the future internet
to archive and pull data like from a library,
sending personal messages and files back and
forth, and getting their news from it.
But Smartphones, Mobile App Games, Selfies,
online commerce, or people walking in front
of cars while texting just weren’t what
was in mind when cell phones were invented.
These seem obvious in hindsight, but there
was simply no way anyone could have predicted
the myriad uses that the cell phone has come
to give us.
We examined this notion more deeply back in
our Black Swan Events episode.
We also looked at something called an Outside
Context Problem, or OCP, which is something
that an individual or a civilization simply
couldn’t even have conceived of, because
an OCP arrives unexpectedly and is, by definition,
something so far removed from what that the
individual or the civilization knows and understands--it’s
something so far removed from everyday life
that there is simply no possible way for anyone
to come close to considering it as a possibility.
As an example, most of us are aware of the
concept of a flying saucer landing, so we
really can’t consider the arrival of aliens
as an OCP; but if, for example, the million
or so mountains on Earth were to suddenly
start yawning and stretching and opening huge
pairs of eyes to start a new day in some mountainous
civilization, moving about the planet without
even noticing the humans that they keep crushing
underfoot...this would be an OCP.
We have absolutely no reason to believe or
expect the mountains on our planet to be living,
thinking beings and would be absolutely blown
away should such a bizarre thing happen.
Now to clarify, an OCP is not just something
out of the box and unpredictable, like going
to sip a cup of coffee and have the cup bite
you.
OCP’s are supposed to be civilization wrecking
events, and the implication tends to be that
the shocking thing that did it was something
in contradiction to your civilizations worldview.
So for instance, both Special Relativity and
Quantum Mechanics were OCPs, the notion that
space and time are connected and malleable
and that at the most basic level of matter
and energy there’s randomness and uncertainty
did give some major existential crises to
scientists and philosophers, but it didn’t
really impact civilization much.
Alternatively if you live on a small island
and your whole worldview is connected to the
idea that you’re a chosen people made by
a deity to live on this lone paradise island
in an infinite sea, and to leave the island
brings death, having folks arrive on a giant
ocean going vessel and say hello one afternoon
is going to obliterate that worldview and
fast.
Many of the things we’ll be looking at today
are OCPs, or would have been if the concept
had gone from brand new to fully developed
overnight, but not so now.
It’s typical for end-of-the-year videos,
articles, essays, and so on to make predictions
about the future, but that’s what we do
every week here on the show so I figured we
should emphasize instead how unpredictable
the future is.
We can only predict when we know what all
the variables are.
For instance I might say that in the next
decade we’ll see a big uptick in the use
of solar power, but if tomorrow someone figured
out how to make a very easy to build fusion
reactor that had far fewer maintenance costs
per kilowatt-hour than any existing power
source, solar power would be rendered into
a niche market, because with cheap enough
energy you can even suck CO2 and water up
and turn them into carbon neutral gasoline
to run your larger portable devices.
At that point solar is limited to very low-draw
power electronic devices, like calculators,
or fairly remote locations where it’s a
bigger pain to run power lines to the devices
than erect some solar panels.
Indeed, given that fusion probably lets you
run a lot of atom smashers or neutron bombardment
on the cheap, you might see a big uptick in
devices using radioisotope thermal generators.
On the flip side, if someone came out tomorrow
with a solar panel roofing tile that was competitive
in cost of production, installation, and maintenance
with normal roofing options, especially if
that came in tandem with better batteries,
then suddenly the future is a world where
almost every roof is covered in them, and
the solar roofing market sees a sudden boom,
and a lot of paint and house siding options
alter around nearly every roof being black.
What we tend to do on this show is ask what
the consequence of a given new piece of technology
would be, and try to go beyond just the obvious
ones.
Again, Forewarned is forearmed, and many of
threats facing us like asteroid impacts or
supervolcanoes are statistically improbable
in the next century or two, even more unlikely
to be of a magnitude that wiped us out beyond
rebuilding, and are subject to management
with higher technology.
Of course, that’s assuming those models
are reasonably correct.
When we get out in space, no terrestrial danger
will threaten extinction anymore, and developing
the technology to do that comes hand in hand
with improved technologies that are better
from both and ecological and economic perspective,
and you can see some of our episodes like
Climate Change Mitigation, Power Satellites,
or Asteroid Defense for some examples of that.
Fundamentally threats to humanity in the future
are those of our own making, from other humans,
or the machines we create.
As another example, I mentioned 3D Printing
near the beginning in our long list of potential
cataclysms, and that’s usually because a
very advanced 3D printer, something more akin
in speed and versatility to a Star Trek Replicator
than modern 3D printers, can potentially let
any lunatic make a doomsday device in their
basement.
We examined both some opportunities and some
of the challenges in making anything like
that in our episodes the Santa Claus Machine
and Self Replicating Machines, such as being
wiped out by Grey Goo, a host of tiny self-replicating
machines that disassemble everything, including
people and the ground they’re standing on,
to make more of themselves.
However, while that’s a potential cataclysm
for civilization, I’d be more worried about
the preemptive strike against that of a surveillance
state monitoring for improper usage of such
a technology or even signs of ownership.
Faced with a challenge to our civilization’s
survival, or an apparent one, we do tend to
react and those reactions are not always the
ones we might prefer.
Possibly the biggest potential threat or challenge
along these lines we will see in this next
century will be genetic engineering and eugenics.
Consider if gene therapy improved and we suddenly
could start making designer babies, one’s
who would grow up smarter and healthier than
the normal average and with the desired physical
characteristics the parents selected.
It’s possible this would be banned and have
a massive black market enterprise for doing
it, and the response to that might be random
DNA tests on kids to see if they had been
altered, potentially with severe punishments
for them or their parents.
Since such sanctions might still not be enough
in the long term to avoid those traits getting
into the gene pool, they might be forcibly
sterilized or even killed.
We have seen the dire scenarios for that in
science fiction almost as often as we see
the dire consequences of genetic engineering.
But let us consider a slow and more moderate
response, more akin to what we have often
seen in recent decades to disruptive technologies.
Parents by nature want the best for their
child, and if their resources permit they
generally will not hesitate to go to extreme
efforts to improve their offspring’s future.
We already do this a lot but most of the ways
for doing it are entirely embedded into our
culture, so we don’t accuse parents of cheating
or seeking advantage for sending their kids
to private schools, hiring a tutor, or buying
them every widget that alleges to improve
learning or health in some fashion.
It would never even cross our minds to accuse
someone of cheating for spending lots of time
with their kid teaching academics, sports,
social skills, or ethics to them.
We also aren’t likely to object to any type
of gene therapy or other medical procedure
that helps with a handicap, if a child has
lost an arm, been born blind or with diabetes,
or so on, I can’t see many of our current
civilizations trying to ban anything which
helped with that.
However it is debatable what is a handicap,
and it’s also a dubious ethical and legal
idea that someone can fix a deficit but not
seek an improvement.
I should note personally that I have no ethical
issue, in and of itself, with anyone taking
a pill or giving one to their child that suddenly
makes them smarter or stronger or similar,
at least if it is all inside the existing
human template.
My only issues are the potential side effects
and consequences.
Having a kid as smart as Einstein who could
also get a job as a star athlete or supermodel
does not harm anyone else except in very abstract
ways of denying an opportunity to another,
who got that opportunity by semi-random genetic
luck anyway, or by placing parents or cultures
under the pressure of having to do the same.
Outside the human template is another story
and more iffy, however as is often the case
with the ethics of any technology, we should
ask if we already have parallel cases in our
culture.
Now it's generally accepted that at a subconscious
level we tend to engage in mate selection
for good offspring, and that many of the traits
that are considered attractive, especially
cross-culturally, are those associated with
that goal.
So we already seek for better genetics, and
I’m not entirely sure what the difference
is between mate selection with that goal and
genetic engineering besides the latter being
more effective.
Ethically there is no difference between going
to some witch doctor for a love potion that
you believe will work and going to a lab for
a drug that actually does work except that
the former probably does not work and the
latter does.
You thought it worked when you made the decision
to acquire and use it, we’ll talk more about
designer drugs in a bit but it’s a parallel
to designer babies ethically, insofar as genetic
science is presumably seeking the same goal
as mate selection except that it is more effective
and definitely a conscious decision.
Which mate selection might be too, and we
have no law banning two people from seeking
to have children together specifically because
they think they have good genes to mix, indeed
that is the primary and conscious motivation
at things like sperm banks.
Ethically objecting to someone else advantaging
their child at no direct consequence to you
is essentially the same as complaining that
they sent them to the best school or took
time off from work and sacrificed luxuries
to focus on their kids education.
One can raise legitimate worries about opportunities
being denied to other folks, but that can
only go so far.
My wife and I were both homeschoolers with
strong backgrounds in educating folks, so
unsurprisingly we are planning to homeschool
our own kids if we have any and circumstances
permit.
There’s much to be said about egalitarianism
but if someone were to suggest to me it was
unfair that we do so they’d probably get
commentary out of me using many of the words,
tones, and phrases I’ve tried to eliminate
from my lexicon after leaving the military.
That which improves a person is arguably an
exception though, because someone in better
mental or physical health, so long as they’ve
been given a good ethical base and aren’t
prone to narcissism, is benefiting society
too.
If a culture suddenly has access to some technique
that results in many children having that
opportunity, they probably are going to soon
have both the ability and inclination to spread
that around.
I never like making blanket comments but I’ve
also never noticed a tendency of the intelligent
and educated to hoard knowledge, quite to
the contrary it tends to fairly often to result
in an obsession for increasing that knowledge
and spreading it around.
Same, it is pretty normal for athletes to
turn into coaches, because they want to share
their love for the game with others and believe
sports are good for the body and soul.
But all that said we obviously want to be
careful and probably fairly gradual about
things like genetic engineering of humans,
and I’d imagine that is the inevitable outcome
anyway just because society will tend to naturally
put roadblocks in the way of developing it
to make sure at a minimum that it is heavily
studied for problems and side effects, while
at the same time the legal and moral issues
of trying to tell people they can’t do it,
particularly if other people are, should result
in a gradual approach.
Remember it only takes one country saying
“Yes we’re going to allow this” and
then other countries either have to force
them to ban it, decrease their own bans, or
have to take some fairly difficult measures
to avoid a gradual spillover.
One caveat on it though is that you can make
a good case that any alterations to a human
that aren’t dealing with some major health
issue should not be allowed in favor of them
doing it as an adult, and the reality is that
while its harder to change the DNA in a trillion
cells of a baby or adult than in one embryo,
that sort of repetitive action is exactly
what we would be aiming to handle with something
like a tailored retrovirus or self-replicating
medical nanobot.
I could see laws banning messing with an embryo,
but anything you would apply to a child in
the womb or toddling around could be done
to an adult too so you can make a case for
waiting for that until they’re an adult.
However, I can’t see a culture where adult
genetic alteration was becoming normal and
wasn’t producing major crazy side effects
like a civilization of selfish supermen that
would long keep that from their kids, as they’d
probably come to view it as somewhat akin
to refusing to let a kid read a book or exercise
until they were an adult.
So I’m quite sure we will see a future,
and arguably already are in it, where we see
science and technology applied to enhancing
the human.
Definitely a source of concern and a thing
to watch warily for problems, but also worth
the reminder that our only examples of genetically
engineered supervillains are in fiction, and
that making folks in great mental and physical
condition has been our goal for a long time,
so assuming that too much of a good thing
would be bad, or the specific means of doing,
with a drug or retrovirus for instance, is
bad, doesn’t seem a strong argument.
Of course too much of a good thing has been
a constant worry where technology is concerned
and not without justification even if it's
often been a bit misaimed or exaggerated.
Designer Drugs and Virtual Reality both raise
that concern.
Drugs – in the context of recreationally
taken narcotics – is obviously always an
ethically tricky topic because it’s specifically
about too much of a good thing, a flawed source
of that good thing, or side effects – not
any specific one of them.
Obviously opinions vary about them, and I
tend to be off two minds on it myself, but
there’s clearly a middle ground.
Even the most ardent folks against them aren’t
likely to argue that coffee or chocolate should
be banned, while even those who favor legalizing
everything usually don’t think taking most
of them is an entirely safe and great idea,
and would tend to make exceptions for anything
that sends folks into homicidal or delusion
rages or so wildly addictive that being exposed
to it even once involuntarily makes you a
lifelong addict willing to do anything to
get that next fix.
Problem is, you probably could design something,
a lone drug or cocktail, that did exactly
that.
It might not even have any negative consequences,
akin to the Spice Melange of the Dune Franchise,
which is mostly problematic in that it has
a limited supply, but otherwise extends life
and good health though in large doses causes
prophetic foresight and turning into a spacetime
folding mutant.
For the most part it takes huge research groups,
giant budgets, and large sanctioned trials
to develop a new drug so we generally only
see it from major pharmaceutical companies
that are watchdogged and not encouraged to
try to come up with something that makes heroine,
cocaine, or LSD look mild, but I would guess
that as our knowledge of chemistry, biological
computer modeling, and neuroscience improve
in this next century that will get easier
to do and we probably will have folks develop
various superdrugs.
If you’ve got something that causes massive
euphoria that’s as cheap as dirt and virtually
impossible to prevent the spread of how to
fabricate it at home from easily obtained
materials then you’ve probably got yourself
a massive problem, especially if it has no
major side effects causing health issues or
criminal behavior.
The same applies to virtual reality, if you
can live in whatever realm your mind can imagine
and a programmer can make, a civilization
is faced with the issue of how to keep folks
from spending all their time in one.
That’s probably not made even a little bit
easier if you are unemployed because robots
and genetically enhanced youngsters are flooding
the production chains.
On the one hand they probably represent no
threat to the civilization, particularly considering
they are suffering from a lot of idle time
because overall productivity has skyrocketed,
so a big chunk of your population sitting
on a couch in drug or VR induced bliss represents
only an existential threat, it's not very
likely to get everyone and those it doesn’t
get are going to be very resistant to the
temptation as time goes on and multiple generations
grow up indoctrinated to loathe it, rightly
or wrongly.
Also while we will probably get better at
hacking our brain's pleasure centers, this
same effort is likely to produce powerful
treatments for addictive behaviors too.
This is that big one that really threatens
civilization in the next century though, not
just being replaced by automation but an ever-growing
feeling of not being useful to society while
having so many ways to live outside it and
maybe happier.
A prosperous society will generally seek to
help folks feel useful and to survive if or
until they can be, but how you do that is
clearly pretty tricky as history has shown
us.
I would also worry about good intentions and
subconscious bad ones a lot.
It’s very easy for me to imagine that the
folks most resistant to the lure of narcotic
or VR inspired euphoria are the ones who are
already addicted something else in this life,
like the game of life itself, and might subconsciously
be very glad to engage in policies that eliminate
competition.
An awful lot of the competitive and predatory
behavior of folks with a lot of money and
power is related to them essentially being
addicted to that particular game of life,
they play it to win, as they see it, and it’s
the game itself they enjoy playing.
So we can often show them real world consequence
to get them to ameliorate that behavior, which
is probably a lot harder if they can turn
around and just say “Hey, my labor and taxes
are personally paying for thousands of folks
to sit at home taking euphoria drugs and living
as kings in virtual reality”, which is a
lot harder to rebut than if the average person
is barely eking out an existence half starved
in some dilapidated shack.
I don’t think the big threat of a highly
automated post-scarcity civilization is that
everyone turns inward into hedonism so much
as society starts shrugging at how many people
do, partially because they wish them well
and partially because they wish them out of
the way.
Of course we might get pushed out of the way
ourselves.
We often worry about some super-intelligent
machine doing the trick, or superintelligent
genetically engineered people or even uplifted
animals, akin to the apes from the Planet
of the Apes Franchise.
That super-intelligent machine is more of
the concern, whether it aims to wipe us out
or simply decides to keep us as pets, and
is what we usually call a technological singularity.
Now a technological singularity can have a
few different meanings depending on whose
defining it.
The self-learning machine able to improve
itself and do it over and over, faster and
faster, is probably the most common usage
these days, but also not too realistic.
We examined that in detail in our Technological
Singularity episode but in short summary as
a near-term threat, humans have been trying
to make a smarter human for centuries, and
teaming up to do it, with limited success.
Assuming a machine we made and made just a
bit smarter than us could turn around the
next day and make one even smarter is stretching
plausibility a bit.
Assuming it could do that while its creators
looked on blindly is even more of a stretch.
They are experts on the topic who tend to
be the sorts of folks who have watched or
read a lot of fiction about runaway machine
intelligences.
It is possible, and over a long enough time
we will presumably get far smarter artificial
intelligences that are superhuman, but it’s
more likely we would have a gradual improvement
with many such machine intelligences and many
other parallel ones like genetically or cybernetically
enhanced humans too.
So ever-smarter machines, probably, but a
single runaway event, it versus everyone else
and unbeatable, that I would tend to doubt.
But the presence of any machine or person,
or machine person, with vastly better problem
solving and management concerns probably represents
our biggest existential threat in the next
century.
Not because it might wipe us out or replace
us, which is certainly possible, but because
it might replace us as in control, and again
not because it might seize control – which
is certainly possible too – but because
we might just tend to cede it more and more
power.
It’s very hard to say no to a piece of technology
that clearly does a better job, especially
when everyone benefits by doing so.
Indeed, I’m not even sure that we should,
and on many things we probably should not.
In the century to come, our better machines,
our better technologies, or better techniques,
pose both our greatest challenges to survival
and our greatest tools for surviving and prospering.
The real trick to surviving the next century
is going to be deciding what we should employ
and what we really mean by survival and prosperity.
So it’s time for our SFIA Audiobook of the
Month, and given that one of the best ways
to survive the next century, and the holiday
season, is with some good escapist fiction
happening on another world, this month’s
Audiobook award goes to Brandon Sanderson’s
Stormlight Archive series, book 4 of which,
Rhythm of War, was recently released.
I often get asked who my favorite author is,
and across all genres of current active authors,
it is Brandon Sanderson, he’s a rare talent
in that he does not only incredible worldbuilding
but magnificent characters, dialogue, and
plot.
He’s written dozens of books, plenty to
keep you entertained all winter long, and
you can find all his works over on Audible,
and try your first book out for free by visiting
the link in the episode description, Audible.com/Isaac,
or text “Isaac” to 500-500.
However, Audible has also recently launched
a new introductory plan for those thinking
of trying it out or giving it as a gift, Audible
Plus, for 4.95 a month for the first 6 months,
and that comes with unlimited access to select
audiobooks and Audible Originals, and they
add more every week, so it is a very good
way to get introduced to audiobooks and if
you’re doing a lot of driving and travel
this holiday season, or know someone who is,
Audible Plus gives you or a loved one access
to a massive treasure trove of fiction, as
well as podcasts, wellness programs, theatrical
performances, and more.
If you are already an audiobook enthusiast,
I’d recommend the Audible Premium Plus membership,
which gives you a free audiobook every month,
which more than pays for itself, and a 30%
discount on additional titles, and you still
get free access to everything on Audible Plus.
Again just visit the link in the episode description,
Audible.com/Isaac, or text “Isaac” to
500-500.
So winter is coming, and as we move into the
holiday season we’ve got a busy month.
Starting next week we’ll ask what it will
take for those colonies to grow from simple
outposts into genuine settlements and cities.
Then we’ll follow that up with a look at
how we’ll terraform these new worlds.
Then we’ll ask how we go out about getting
to them in Interstellar Navigation, how we
go about building our own solar system up
into a Kardashev-2 Civilization, and finally
we wrap the year up on December 31st with
Becoming an Interstellar Species.
If you want alerts when those and other episodes
come out, make sure to subscribe to the channel,
and if you’d like to help support future
episodes, you can donate to us on Patreon,
or our website, IsaacArthur.net, which are
linked in the episode description below, along
with all of our various social media forums
where you can get updates and chat with others
about the concepts in the episodes and many
other futuristic ideas.
Until next time, thanks for watching, and
have a great century!
